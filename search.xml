<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Solution Manual to Introduction to Applied Linear Algebra</title>
    <url>/iala-solution-manual.html</url>
    <content><![CDATA[<p>Below is the official solution manual of Introduction to Applied Linear Algebra (Vectors, Matrices, and Least Squares) by Stephen Boyd, Lieven Vandenberghe</p>
<a id="more"></a>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&OneJS=1&Operation=GetAdHtml&MarketPlace=US&source=ss&ref=as_ss_li_til&ad_type=product_link&tracking_id=linearalgeb0e-20&language=en_US&marketplace=amazon&region=US&placement=1316518965&asins=1316518965&linkId=5b547b0f446ebd6256527418fe0e2bde&show_border=true&link_opens_in_new_window=true"></iframe>

<p><a href="https://drive.google.com/file/d/1wBJMfbWsPL5lq6T6SA8m3iQeCVrbRkiQ/view?usp=sharing">Solution Manual to Introduction to Applied Linear Algebra via Google Drive</a></p>
<p><a href="https://drive.google.com/file/d/1wBJMfbWsPL5lq6T6SA8m3iQeCVrbRkiQ/view?usp=sharing">https://drive.google.com/file/d/1wBJMfbWsPL5lq6T6SA8m3iQeCVrbRkiQ/view?usp=sharing</a></p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Solution Manual</tag>
        <tag>Solution Content</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify a set with certain binary operation is an Abelian group</title>
    <url>/mml-exercise-2-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.1</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>a. We check conditions in Definition 2.7 and the commutativity. Note that \begin{equation}\label{2.1.2}a\star b=(a+1)(b+1)-1.\end{equation} (1) Closure of $\mathbb R\setminus \{-1\}$ under $\star$: if $a,b\in\mathbb R\setminus \{-1\}$, then $(a+1)(b+1)\ne 0$. Therefore $ab+a+b\ne -1$, which shows $a\star b\in \mathbb R\setminus \{-1\}$.</p>
<p>(2) Associativity: if $a,b,c\in\mathbb R\setminus \{-1\}$, then it follows from \eqref{2.1.2} that \begin{align*}(a\star b)\star c = &amp;\ ((a+1)(b+1)-1)\star c\\ =&amp; \ (a+1)(b+1)(c+1)-1\end{align*}and \begin{align*}a\star(b\star c)=&amp;\ a\star((b+1)(c+1)-1)\\ = &amp;\ (a+1)(b+1)(c+1)-1.\end{align*}Thus $(a\star b)\star c=a\star(b\star c)$.</p>
<p>(3) Neural element: if $a\in\mathbb R\setminus \{-1\}$, then $$a\star 0= a\cdot 0+a+0=a$$and $$0\star a=0\cdot a +0+a=a.$$ (4) Inverse element: if $a\in\mathbb R\setminus \{-1\}$, then $a+1\ne 0$ and we have $a^{-1}=\dfrac{1}{a+1}-1$. This can be checked directly using \eqref{2.1.2}.</p>
<p>(5) Commutativity: if $a,b\in\mathbb R\setminus \{-1\}$, it is clear from \eqref{2.1.2} that \begin{align*}a\star b= &amp;\ (a+1)(b+1)-1\\= &amp;\ (b+1)(a+1)-1=b\star a.\end{align*} b. Recall the computation from part a.(2), we have $$3\star x \star x = (3+1)(x+1)(x+1)-1.$$Hence we have to it reduces to solve $$4(x+1)^2=16,$$which gives $x+1=\pm 2$. We have $x=1$ or $x=-3$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Abelian Group</tag>
        <tag>Group</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis of the intersection of two solution spaces</title>
    <url>/mml-exercise-2-13.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.13</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>We can compute $\mathsf{rank}({A_1})=2$ and $\mathsf{rank}({A_2})=2$ also. Since both matrices map from $\mathbb{R}^3$ to $\mathbb{R}^4$, we must have that the nullity of both of the matrices is 1. Therefore, $U_1$ and $U_2$ both have dimension 1, since they $are$ the kernels of their respective maps.</p>
<p><strong>Part b</strong></p>
<p>Since the spaces have dimension 1, we are again simply looking for a non-zero vector in each space. Observe that $(1,1,-1)^{\mathsf{T}}$ lies in both spaces, so $\{ (1,1,-1)^{\mathsf{T}} \}$ is a basis for both.</p>
<p><strong>Part c</strong></p>
<p>From the previous part, we have that $U_1=U_2$, so $U_1\cap U_2 = U_1$ also, and again has $\{ (1,1,-1)^{\mathsf{T}} \}$ as a basis.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Basis</tag>
        <tag>Linear Equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis of the intersection of two solution spaces II</title>
    <url>/mml-exercise-2-14.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.14</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Observe that these matrices are the same as those used in the previous parts, except now our spaces $U_1$ and $U_2$ are different. We now have $\dim (U_1)=\mathsf{rank}(A_1)=2$ and $\dim(U_2) = \mathsf{rank} (A_2)=2$.</p>
<p><strong>Part b</strong></p>
<p>We are looking for two linearly independent columns in each of our matrices – we need two non-zero columns, and they can’t be a multiple of each other. For example, the first two columns of each matrix will do as a basis for each space.</p>
<p><strong>Part c</strong></p>
<p>Note that $\mathsf{rank}([A_1|A_2])=3$, i.e. $\dim(U_1+U_2)=3$ (Note that $[A_1|A_2]$ is just the $4\times 6$ matrix formed by concatenating $A_1$ and $A_2$.) This means that $$\dim (U_1\cap U_2) = \dim(U_1)+\dim(U_2)-\dim(U_1+U_2) = 2+2-3=1,$$ so again, to find a basis of $U_1\cap U_2$, we need only find a non-zero vector in the space. We proceed in a similar way to Question 2.12.</p>
<p>Firstly, we observe that we can write $v_3=v_1+v_2$ and $v_6=v_4+v_5$, so these two vectors can safely be ignored. Secondly, observe that $\left[v_1|v_2|v_5\right]$ has rank three, so (using the notation of Question 12) if we take $\alpha_4=1$, say, and solve then we have $\alpha_1=3$, $\alpha_2=1$, and $\alpha_5=0$. In other words, our non-zero vector is $3v_1+v_2 = v_4 = (3,1,7,3)^{\mathsf{T}}$, and our basis of $U_1\cap U_2$ is $\{ (3,1,7,3)^{\mathsf{T}} \}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Basis</tag>
        <tag>Linear Equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis of the intersection of two solution spaces III</title>
    <url>/mml-exercise-2-15.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.15</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Firstly, observe that $(0,0,0) \in F$, and $(0,0,0)\in G$ also. Next, we check that adding any two elements of the set does indeed get us another element of the set. Finally, if we multiply any element of the set by any real number, we again get another element of the required form. Thus $F$ and $G$ are subspaces indeed!</p>
<p><strong>Part b</strong></p>
<p>A vector in $F\cap G$ will satisfy both conditions in the sets, so if we put $G$’s condition into $F$’s, we find $$(a-b)+(a+b)-(a-3b) = 0,$$ from which we have $a=-3b$. Thus, $$F\cap G = \{ (-4b,-2b,-6b) : b\in \mathbb{R} \} = \mathsf{span}[ (2,1,3)].$$</p>
<p><strong>Part c</strong></p>
<p>Doing the same dimensional analysis as the previous three questions, we find that $F\cap G$ has dimension 1. We have $$F=\mathsf{span}[(1,0,1), (0,1,1)],$$ and $$G=\mathsf{span}[ (1,1,1),(-1,1,-3)].$$</p>
<p>Proceeding in the same way as <a href="/mml-exercise-2-12.html">Problem 2.12</a>, we find that $-4v_1-2v_2 = -3v_3+v_4$, and hence $\{(-4,-2,-6)\}$ is a basis of $F \cap G$, which agrees with Part b.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Basis</tag>
        <tag>Linear Equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Write a vector as a linear combination of other vectors</title>
    <url>/mml-exercise-2-11.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.11</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>Here, we need to solve the system of equations \begin{align*}\begin{cases}\alpha_1+\alpha_2+2\alpha_3 = 1,\\ \alpha_1+2\alpha_2-\alpha_3=-2, \\ \alpha_1+3\alpha_2+\alpha_3 = 5.\end{cases}\end{align*}</p>
<p>Performing Gaussian elimination in the usual way, we determine that $\alpha_1 = -6$, $\alpha_2 = 3$, and $\alpha_3 = 2$. That is to say, $$y=-6x_1+3x_2+2x_3.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Combination</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine if vectors are linearly independent</title>
    <url>/mml-exercise-2-10.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.10</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>If we form a matrix out of these three vectors and compute its determinant, we get zero. Thus, the vectors are not linearly independent.</p>
<p><strong>Part b</strong></p>
<p>Let’s form the equation $\alpha_1 x_1 + \alpha_2 x_2 + \alpha_3 x_3 = 0$. These three vectors are linearly independent if and only if the $only$ solution to this equation is $\alpha_1=\alpha_2=\alpha_3=0$.</p>
<p>Looking at the third component, we have that $\alpha_1\cdot 1 + \alpha_2 \cdot 0 + \alpha_3 \cdot 0 = 0$, that is to say, $\alpha_1 = 0$.</p>
<p>Next, look at the second component. We already know $\alpha_1 = 0$, so we have $\alpha_2 \cdot 1 + \alpha_3 \cdot 0 = 0$, that is to say $\alpha_2=0$ also.</p>
<p>Finally, look at the first component. We have that $\alpha_3 \cdot 1 = 0$, so all of the $\alpha_i$’s are zero. Therefore, our three vectors are linearly independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linearly Independent</tag>
      </tags>
  </entry>
  <entry>
    <title>Computations involving a linear mapping</title>
    <url>/mml-exercise-2-17.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.17</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>From the coefficients on the right, we have $A_\Phi = \begin{bmatrix} 3&amp;2&amp;1\\ 1&amp;1&amp;1\\ 1&amp;-3&amp;0\\ 2&amp;3&amp;1 \end{bmatrix}$.</p>
<p><strong>Part b</strong></p>
<p>Using Gaussian elimination, we can compute that $\mathsf{rank}(A_\Phi) = 3$. </p>
<p><strong>Part c</strong></p>
<p>From this we deduce that the kernel is trivial (i.e. only $(0,0,0)$), and clearly $$\mathsf{Im}(\Phi)= \{ (3x_1+2x_2+x_1,x_1+x_2+x_3,x_1-3x_2,2x_1+3x_2+x_3)^{\mathsf{T}} : x_1, x_2, x_3 \in \mathbb{R} \}.$$ We have $\dim(\ker(\Phi))=0$, and $\dim(\mathsf{Im}(\Phi))=\mathsf{rank}(A_\Phi)=3$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Map</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of automorphisms of vector space</title>
    <url>/mml-exercise-2-18.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.18</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>We have two automorphisms, which means they map linearly and bijectively from the space, $E$, to itself. The maps therefore both have kernel $\{0\}$ (by injectivity) and image $E$ (by surjectivity). From this, we immediately deduce that $\ker(f)\cap \mathsf{Im}(g) = \{0\}$, indeed. Similarly, we deduce that $g\circ f$ also has kernel $\{0\}$ and image $E$, as required. Note that we didn’t need the condition that $f\circ g = \mathsf{id}_E$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Map</tag>
        <tag>Automorphism</tag>
      </tags>
  </entry>
  <entry>
    <title>Computations of an automorphism of vector space</title>
    <url>/mml-exercise-2-19.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.19</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Note that $\mathsf{rank}(A_\Phi) = 3$, so $\ker(\Phi)=\{0\}$ and $\mathsf{Im}(\Phi)=\mathbb{R}^3$.</p>
<p><strong>Part b</strong></p>
<p>Let $P$ be the change of basis matrix from the standard basis of $B$ to $\mathbb{R}^3$. Then $$P=\begin{bmatrix} 1&amp;1&amp;1\\ 1&amp;2&amp;0\\ 1&amp;1&amp;0 \end{bmatrix}.$$</p>
<p>The matrix $\overline{A_\Phi}$ is given by $$P^{-1}A_\Phi P = \begin{bmatrix} 6&amp;9&amp;1\\-3&amp;-5&amp;0\\-1&amp;-1&amp;0 \end{bmatrix}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Map</tag>
        <tag>Automorphism</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify a set with certain binary operation is an Abelian group II</title>
    <url>/mml-exercise-2-2.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.2</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>The major thing we need to check here is whether the operation $\oplus$ is well-defined. That is to say, if we take two different representatives of the same congruence classes, do we definitely get the same answer at the end? Let’s take $a_1, a_2 \in \mathbb{Z} $ such that $\overline{a_1} = \overline{a_2}$, and similarly let $b_1, b_2 \in \mathbb{Z} $ such that $\overline{b_1} = \overline{b_2}$. We need to show that $\overline{a_1}\oplus \overline{b_1} = \overline{a_2} \oplus \overline{b_2}$. In other words, we need to show that $\overline{a_1+b_1} = \overline{a_2+b_2}$.</p>
<p>By the definition of the congruence class, two classes $\overline{a_1}$ and $\overline{a_2}$ are equal in $\mathbb{Z}_n$ if and only if $a_1 - a_2$ is a multiple of $n$. Let’s say $a_1 - a_2 = k_1 n$ and ${b_1 - b_2 = k_2 n}$, for some $k_1, k_2 \in \mathbb{Z}$. Observe then that $(a_1+b_1)-(a_2+b_2) = (k_1+k_2)n$, and so $\overline{a_1+b_1} = \overline{a_2+b_2}$ indeed!</p>
<p>From here, we use properties of addition in the integers to deduce that $(\mathbb{Z}_n,\oplus)$ is an abelian group. </p>
<p>First, it is closed under the operation, that is $$\overline{a}\oplus\overline{b} = \overline{a+b}\in \mathbb{Z}_n.$$</p>
<p>Then, we have the associativity, that is $$(\overline{a}\oplus \overline{b}) \oplus \overline{c} = \overline{a+b} \oplus \overline{c} = \overline{(a+b)+c} = \overline{a+(b+c)} = \overline{a} \oplus \overline{b+c} = \overline{a}\oplus (\overline{b} \oplus \overline{c}),$$ where the middle equality follows from the associativity of $\mathbb{Z}$.</p>
<p>Clearly, $\overline{0}$ is the neutral element, since $\overline{0} \oplus \overline{a} = \overline{0+a} = \overline{a}$, and similarly the other way round.</p>
<p>Given $\overline{a} \in \mathbb{Z}_n$, we have that $\overline{-a} = \overline {n-a}$ is the inverse element, since $\overline{a} \oplus \overline{-a} = \overline{a-a} = \overline{0}$, indeed.</p>
<p>Finally, $\overline{a}\oplus \overline{b} = \overline{a+b} = \overline{b+a} = \overline{b} \oplus \overline{a}$, so the group is abelian!</p>
<p><strong>Part b</strong></p>
<p>Observe that the neutral element is $\overline{1}$. For the inverses, we have $\overline{1}^{-1} = \overline{1}$, $\overline{2}^{-1} = \overline{3}$, $\overline{3}^{-1} = \overline{2}$, and $\overline{4}^{-1} = \overline{4}$. All the axioms are satisfied, so $(\mathbb{Z}_5\setminus\{\overline{0}\} , \otimes)$ is a group.</p>
<p><strong>Part c</strong></p>
<p>Observe that, for example, $\overline{2}\otimes \overline{4} = \overline{0}\notin \mathbb{Z}_8\setminus\{\overline{0}\}$, so the operation is not closed.</p>
<p><strong>Part d</strong></p>
<p>If $n$ is prime, then every integer from $1$ to $n-1$ will be relatively prime to $n$. Let $a$ be such an integer. Then, by Bezout’s theorem, there exist integers $u, v$ such that $au+nv=1$. If we take this identity mod $n$, we have $\overline{au} \oplus \overline{nv} = \overline{1}$. But $nv$ is a multiple of $n$, so $\overline{nv} = \overline{0}$, and this simplifies to $\overline{a} \otimes \overline{u} = \overline{1}$ – in other words, $\overline{u}$ is the inverse of $\overline{a}$. Also, if we take two integers $a$ and $b$, both of which are relatively prime to $n$, then the product $ab$ also cannot contain a factor of $n$, since $n$ is prime, so the operation is closed. The other properties follow immediately. This shows that we have a group. $\lozenge$</p>
<p>If $n$ is not prime, then we can say $n=ab$, where $a,b\in \mathbb{Z}$, with $1 &lt; a\leq b &lt; n$. But then $$\overline{a}\otimes \overline{b} = \overline{ab} = \overline{n} = \overline{0}\notin \mathbb{Z}_n\setminus\{\overline{0}\},$$ and so the operation is not closed.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Abelian Group</tag>
        <tag>Group</tag>
      </tags>
  </entry>
  <entry>
    <title>Computations of a linear mapping using two bases</title>
    <url>/mml-exercise-2-20.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.20</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Each set $B$ and $B’$ has the correct number of (clearly!) linearly independent vectors, so they are both bases of $\mathbb{R}^2$.</p>
<p><strong>Part b</strong></p>
<p>We write the old basis vectors ($B’$) in terms of the new ($B$), and then transpose the matrix of coefficients. We have $$b_1’ = 4 b_1 + 6 b_2, \quad b_2’ = 0b_1 -b_2.$$ Thus $P_1 = \begin{bmatrix} 4 &amp; 0\\ 6 &amp; -1 \end{bmatrix}$.</p>
<p><strong>Part c</strong></p>
<p>Let $M=[c_1|c_2|c_3]$, and observe that $\det M = 4 \neq 0$, so the vectors are linearly independent. Since $\mathbb{R}^3$ had dimension 3, and we have three linearly independent vectors, $C$ must indeed be a basis.</p>
<p>Indeed, such an $M$ is the change of basis matrix from $C$ to $C’$ (write the old vectors in terms of the new!) and this is thus the $P_2$ we require. Thus $$P_2 = \begin{bmatrix} 1&amp;0&amp;1\\ 2&amp;-1&amp;0\\-1&amp;2&amp;-1 \end{bmatrix}.$$</p>
<p><strong>Part d</strong></p>
<p>Observe that by adding the given results, we find that $$\Phi(b_1) = c_1 + 2c_3;$$ by subtracting, we have $$\Phi(b_2) = -c_1 +c_2 -c_3.$$ Then $A_\Phi$ is given by the transpose of the matrix of coefficients, so $$A_\Phi = \begin{bmatrix} 1&amp;-1\\ 0&amp;1\\ 2&amp;-1 \end{bmatrix}.$$</p>
<p><strong>Part e</strong></p>
<p>We first need to apply $P_1$ to change from basis $B’$ to $B$. Then $A_\Phi$ will map us to $(\mathbb{R}^3, C)$, before $P_2$ will take us to $C’$. Remember that matrices are acting like functions here, so they are applied to (column) vectors from right to left. Therefore the multiplication we require is $A’=P_2 A_\Phi P_1$. (This is what part f is asking us to recognise.)</p>
<p>We have $A’ = \begin{bmatrix} 0&amp;2\\-10&amp;3\\ 12&amp;-4 \end{bmatrix}$.</p>
<p><strong>Part f</strong></p>
<p>$$P_1 \begin{bmatrix}2\\3\end{bmatrix}=\begin{bmatrix}8\\9\end{bmatrix}.$$</p>
<p>$$A_\Phi \begin{bmatrix}8\\9\end{bmatrix}=\begin{bmatrix}-1\\9\\7\end{bmatrix}.$$</p>
<p>$$P_2 \begin{bmatrix}-1\\9\\7\end{bmatrix}=\begin{bmatrix}6\\-11\\12\end{bmatrix}.$$</p>
<p>And observe that $A’ \begin{bmatrix}2\\3\end{bmatrix}=\begin{bmatrix}6\\-11\\12\end{bmatrix}$, indeed!</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Basis</tag>
        <tag>Linear Map</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine if maps are linear mappings</title>
    <url>/mml-exercise-2-16.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.16</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Observe that \begin{align*}\Phi(f+g) = &amp; \ \int_a^b (f+g)(x) dx \\=&amp;\ \int_a^b f(x) + g(x) dx\\ =&amp;\ \int_a^bf(x) dx +\int_a^b g(x) dx = \Phi(f) + \Phi(g),\end{align*} and similarly $\Phi(\alpha f) = \alpha \Phi(f)$, for all real $\alpha$, so $\Phi$ (that is to say, definite integration) is indeed linear!</p>
<p><strong>Part b</strong></p>
<p>Similarly to the previous part, we know that differentiation is indeed linear.</p>
<p><strong>Part c</strong></p>
<p>This is not linear – $\Phi$ doesn’t even map 0 to 0, indeed!</p>
<p><strong>Part d</strong></p>
<p>We know from 2.7.1 that any matrix transformation like this is indeed linear. This comes from distributive properties of matrix multiplication.</p>
<p><strong>Part e</strong></p>
<p>As before, this mapping is also linear. Indeed, this represents a clockwise rotation by $\theta$ about the origin. (See 3.9.1)</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Map</tag>
        <tag>Function</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute products of Matrices</title>
    <url>/mml-exercise-2-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.4</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>The numbers of columns in the first matrix must equal the number of rows in the second, so this product is not defined.</p>
<p><strong>Part b</strong></p>
<p>$$\begin{bmatrix} 4&amp;3&amp;5\\ 10&amp;9&amp;11\\ 16&amp;15&amp;17 \end{bmatrix}$$</p>
<p><strong>Part c</strong></p>
<p>$$\begin{bmatrix} 5&amp;7&amp;9\\ 11&amp;13&amp;15\\ 8&amp;10&amp;12 \end{bmatrix}$$</p>
<p><strong>Part d</strong></p>
<p>$$\begin{bmatrix} 14&amp;6\\-21&amp;2 \end{bmatrix}$$</p>
<p><strong>Part e</strong></p>
<p>$$\begin{bmatrix} 12&amp;3&amp;-3&amp;-12\\-3&amp;1&amp;2&amp;6\\ 6&amp;5&amp;1&amp;0\\ 13&amp;12&amp;3&amp;2 \end{bmatrix}$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve systems of inhomogenous linear equations</title>
    <url>/mml-exercise-2-5.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.5</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Let’s do some Gaussian elimination. We start with $$\left[ \begin{array}{cccc|c} 1&amp;1&amp;-1&amp;-1&amp;1\\ 2&amp;5&amp;-7&amp;5&amp;-2\\ 2&amp;-1&amp;1&amp;3&amp;4\\ 5&amp;2&amp;-4&amp;2&amp;6 \end{array} \right].$$</p>
<p>Taking $r_2-2r_1$, $r_3-2r_1$ and $r_4-5r_1$, we have $$\left[ \begin{array}{cccc|c} 1&amp;1&amp;-1&amp;-1&amp;1\\ 0&amp;3&amp;-5&amp;-3&amp;-4\\ 0&amp;-3&amp;3&amp;5&amp;2\\ 0&amp;-3&amp;1&amp;7&amp;1 \end{array}\right] .$$</p>
<p>Now taking $r_3+r_2$ and $r_4+r_2$, we have $$\left[ \begin{array}{cccc|c} 1&amp;1&amp;-1&amp;-1&amp;1\\ 0&amp;3&amp;-5&amp;-3&amp;-4\\ 0&amp;0&amp;-2&amp;2&amp;-2\\ 0&amp;0&amp;-4&amp;4&amp;-3 \end{array} \right].$$</p>
<p>Finally, taking $r_4-2r_3$, we have $$\left[ \begin{array}{cccc|c} 1&amp;1&amp;-1&amp;-1&amp;1\\ 0&amp;3&amp;-5&amp;-3&amp;-4\\ 0&amp;0&amp;-2&amp;2&amp;-2\\ 0&amp;0&amp;0&amp;0&amp;1 \end{array} \right].$$</p>
<p>Observe that the rank of the augmented matrix is greater than the matrix of coefficients, so the solution set is empty.</p>
<p><strong>Part b</strong></p>
<p>We proceed with some more Gaussian elimination. From the start, we do $r_2-r_1$, $r_3-2r_1$, and $r_4+r_1$, to obtain $$\left[ \begin{array}{ccccc|c} 1&amp;-1&amp;0&amp;0&amp;1&amp;3\\ 0&amp;2&amp;0&amp;-3&amp;-1&amp;3\\ 0&amp;1&amp;0&amp;1&amp;-3&amp;-1\\ 0&amp;1&amp;0&amp;-2&amp;0&amp;2 \end{array} \right].$$</p>
<p>From here, do $r_2-2r_3$ and $r_4-r_3$ to obtain $$\left[ \begin{array}{ccccc|c} 1&amp;-1&amp;0&amp;0&amp;1&amp;3\\ 0&amp;0&amp;0&amp;-5&amp;5&amp;5\\ 0&amp;1&amp;0&amp;1&amp;-3&amp;-1\\ 0&amp;0&amp;0&amp;-3&amp;3&amp;3 \end{array} \right].$$</p>
<p>Next, if we divide $r_2$ by $-5$, and then do $r_4+3r_2$, we have $$\left[ \begin{array}{ccccc|c} 1&amp;-1&amp;0&amp;0&amp;1&amp;3\\ 0&amp;0&amp;0&amp;1&amp;-1&amp;-1\\ 0&amp;1&amp;0&amp;1&amp;-3&amp;-1\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0 \end{array} \right].$$</p>
<p>Now, we do $r_1+r_3$, then swap $r_2$ and $r_3$, to give $$\left[ \begin{array}{ccccc|c} 1&amp;0&amp;0&amp;1&amp;-2&amp;2\\ 0&amp;1&amp;0&amp;1&amp;-3&amp;-1\\ 0&amp;0&amp;0&amp;1&amp;-1&amp;-1\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0 \end{array} \right].$$</p>
<p>Finally, let’s do $r_1-r_3$ and $r_2-r_3$, to obtain $$\left[ \begin{array}{ccccc|c} 1&amp;0&amp;0&amp;0&amp;-1&amp;3\\ 0&amp;1&amp;0&amp;0&amp;-2&amp;0\\ 0&amp;0&amp;0&amp;1&amp;-1&amp;-1\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0 \end{array} \right].$$</p>
<p>Let’s turn these back into equations. We have $x_1-x_5=3$, $x_2-2x_5=0$ and $x_4-x_5=-1$. Thus we can take $x_3$ and $x_5$ to be arbitrary, and then the others are determined. This gives a solution set of $$\{ (\alpha+3, 2\alpha, \beta, \alpha-1, \alpha)^{\mathsf{T}} : \alpha, \beta \in \mathbb{R} \}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Linear Equations</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve systems of inhomogenous linear equations using Gaussian elimination</title>
    <url>/mml-exercise-2-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.6</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>We start with doing $r_3-r_1$, to give us $$\left[ \begin{array}{cccccc|c} 0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;2\\ 0&amp;0&amp;0&amp;1&amp;1&amp;0&amp;-1\\ 0&amp;0&amp;0&amp;0&amp;-1&amp;1&amp;-1 \end{array} \right].$$</p>
<p>Next, do $r_1+r_3$, $r+2+r_3$, and then multiply $r_3$ by $-1$. This gives $$\left[ \begin{array}{cccccc|c} 0&amp;1&amp;0&amp;0&amp;0&amp;1&amp;1\\ 0&amp;0&amp;0&amp;1&amp;0&amp;1&amp;-2\\ 0&amp;0&amp;0&amp;0&amp;1&amp;-1&amp;1 \end{array} \right].$$</p>
<p>This corresponds to the equations $x_2+x_6=1$, $x_4+x_6=-2$, and $x_5-x_6 = 1$. Now we can take $x_1$, $x_3$ and $x_6$ to be arbitrary, giving a solution set of $$\{ (\alpha, 1-\beta, \gamma, -2-\beta, 1+\beta, \beta)^{\mathsf{T}} : \alpha,\beta, \gamma \in \mathbb{R} \}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Linear Equations</tag>
        <tag>Matrix</tag>
        <tag>Gaussian elimination</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify a set with matrices is a group</title>
    <url>/mml-exercise-2-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.3</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>Let $A_1 = \begin{bmatrix} 1 &amp; x_1 &amp; y_1 \\ 0 &amp; 1 &amp; z_1 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}$ and $A_2 = \begin{bmatrix} 1 &amp; x_2 &amp; y_2 \\ 0 &amp; 1 &amp; z_2 \\ 0 &amp; 0 &amp; 1 \end{bmatrix} \in \mathcal{G}$.</p>
<p>Then $$A_1A_2 = \begin{bmatrix} 1 &amp; x_1+x_2 &amp; y_1+x_1z_2+y_2 \\ 0 &amp; 1 &amp; z_1+z_2 \\ 0 &amp; 0 &amp; 1 \end{bmatrix} \in\mathcal{G},$$ so we have closure.</p>
<p>Associativity follows from the associativity of standard matrix multiplication.</p>
<p>Letting $x=y=z=0$, observe that the identity is in $\mathcal{G}$.</p>
<p>Finally, if we take $x_2 = -x_1$, $z_2 = -z_1$, and $y_2 = -y_1-x_1z_2$, then observe that $A_1A_2 = I_3$, and thus inverses are of the required form! Therefore, $\mathcal{G} $ is a group.</p>
<p>The group is not abelian, e.g. take $x_1=z_2=1$ and everything else to be $0$. Then multiplying these matrices in the other order (i.e. $x_2=z_1=1$) gives a different answer.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Group</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the inverse of matrix</title>
    <url>/mml-exercise-2-8.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.8</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>Observe that $\det A = 2(24-25) -3(18-20) + 4(15-16) = -2+6-4=0$, so $A$ is not invertible.</p>
<p><strong>Part b</strong></p>
<p>We perform Gaussian elimination on $\left[ \begin{array}{cccc|cccc} 1&amp;&amp;1&amp;&amp;1&amp;&amp;&amp;\\ &amp;1&amp;1&amp;&amp;&amp;1&amp;&amp;\\ 1&amp;1&amp;&amp;1&amp;&amp;&amp;1&amp;\\ 1&amp;1&amp;1&amp;&amp;&amp;&amp;&amp;1 \end{array} \right]$, where a blank space denotes a 0.</p>
<p>Firstly, with $r_3-r_1$, $r_4-r_1$, $r_3-r_2$, and $r_4-r_2$, we have $$\left[ \begin{array}{cccc|cccc} 1&amp;&amp;1&amp;&amp;1&amp;&amp;&amp;\\ &amp;1&amp;1&amp;&amp;&amp;1&amp;&amp;\\ &amp;&amp;-2&amp;1&amp;-1&amp;-1&amp;1&amp;\\ &amp;&amp;-1&amp;&amp;-1&amp;-1&amp;&amp;1 \end{array} \right].$$</p>
<p>Then with $r_1+r_4$, $r_2+r_4$, and $r_3-2r_4$, we have $$\left[ \begin{array}{cccc|cccc} 1&amp;&amp;&amp;&amp;&amp;-1&amp;&amp;1\\ &amp;1&amp;&amp;&amp;-1&amp;&amp;&amp;1\\ &amp;&amp;&amp;1&amp;1&amp;1&amp;1&amp;-2\\ &amp;&amp;-1&amp;&amp;-1&amp;-1&amp;&amp;1 \end{array} \right].$$</p>
<p>Finally, swapping $r_3$ and $r_4$, then multiplying $r_3$ by $-1$, we have $$\left[ \begin{array}{cccc|cccc} 1&amp;&amp;&amp;&amp;&amp;-1&amp;&amp;1\\ &amp;1&amp;&amp;&amp;-1&amp;&amp;&amp;1\\ &amp;&amp;1&amp;&amp;1&amp;1&amp;&amp;-1\\ &amp;&amp;&amp;1&amp;1&amp;1&amp;1&amp;-2 \end{array} \right].$$</p>
<p>The matrix to the right of the vertical line is the inverse of $A$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Gaussian elimination</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve systems of homogenous linear equations</title>
    <url>/mml-exercise-2-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.7</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>The problem can be solved as follows:</p>
<ul>
<li>Find all solutions of the system of equations $Ax=12x$.</li>
<li>Find solutions such that $x_1+x_2+x_3=1$.</li>
</ul>
<p>We have that $$A-12I = \begin{bmatrix}-6&amp;4&amp;3\\ 6&amp;-12&amp;9\\ 0&amp;8&amp;-12 \end{bmatrix}.$$ It is easy to find that all solutions are of the form $(3\alpha,3\alpha,2\alpha)^{\mathsf{T}} \in \ker(A-12I)$. </p>
<p>Finally, to make $x_1+x_2+x_3=1$, we only need to divide the vector $(3\alpha,3\alpha,2\alpha)^{\mathsf{T}}$ by $3\alpha+3\alpha+2\alpha=8\alpha$. Here we should take nonzero $\alpha$. Hence we have only one solution to the problem, that is $$(3/8, 3/8, 1/4).$$</p>
<div class="note success flat"><p>The problem shows that 12 is an eigenvector of the matrix $A$ and the corresponding eigenvector is $(3/8, 3/8, 1/4)$.</p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Linear Equations</tag>
        <tag>Matrix</tag>
        <tag>Gaussian elimination</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify Inner Product by Direct Computation</title>
    <url>/mml-exercise-3-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.1</strong></p>
</div>

<a id="more"></a>

<p>Solution: We check it by definition.</p>
<p>Firstly, we check it is symmetric. Note that $$\langle \mathbf x,\mathbf y\rangle = x_1y_1-(x_1y_2+x_2y_1)+2(x_2y_2)$$ and $$\langle \mathbf y,\mathbf x\rangle = y_1x_1-(y_1x_2+y_2x_1)+2(y_2x_2),$$it is clear that $\langle \mathbf x,\mathbf y\rangle=\langle \mathbf y,\mathbf x\rangle$.</p>
<p>Secondly, we check it is bilinear. Let $\mathbf z=[z_1,z_2]^\top$, then for any real numbers $a,b$ we have\begin{align*}\langle a\mathbf x+b\mathbf y,\mathbf z\rangle=&amp;\ \langle [ax_1+by_1,ax_2+by_2]^\top,[z_1,z_2]^\top\rangle \\ =&amp;\ (ax_1+by_1)z_1-(ax_1+by_1)z_2-(ax_2+by_2)z_1+2(ax_2+by_2)z_2\\=&amp;\ (ax_1z_1-ax_1z_2-ax_2z_1+2ax_2z_2)+(by_1z_1-by_1z_2-by_2z_1+2by_2z_2)\\=&amp;\ a(x_1z_1-x_1z_2-x_2z_1+2x_2z_2)+b(y_1z_1-y_1z_2-y_2z_1+2y_2z_2)\\=&amp;\ a\langle \mathbf x,\mathbf z\rangle+b\langle \mathbf y,\mathbf z\rangle.\end{align*} Use the symmetry shown above, we have\begin{align*}\langle \mathbf x,a\mathbf y+b\mathbf z\rangle=&amp;\ \langle a\mathbf y+b\mathbf z,\mathbf x\rangle \\ = &amp;\ a\langle \mathbf y,\mathbf x\rangle + b\langle \mathbf z,\mathbf x\rangle \\ = &amp;\ a\langle \mathbf x,\mathbf y\rangle + b\langle \mathbf x,\mathbf z\rangle.\end{align*}In the second equality, we used the linearity shown above on the first component. The last equality comes from the symmetry of $\langle ,\rangle$.</p>
<p>Finally, we prove it is positive-definite. We have \begin{align*}\langle \mathbf x,\mathbf x\rangle=&amp;\ x_1x_1-(x_1x_2+x_2x_1)+2x_2x_2\\ = &amp;\ x_1^2-2x_1x_2+2x_2^2=(x_1-x_2)^2+x_2^2,\end{align*}which is always non-negative and can only be zero if $x_2=0$ and $x_1=x_2$. This confirms it is positive-definite.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine if a subset is a subspace</title>
    <url>/mml-exercise-2-9.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.9</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p><strong>Part a</strong></p>
<p>We can relabel $\mu^3$ as $\nu$, so $\nu$ can be any real number, and then we have $A = \{ (\lambda, \lambda+\nu, \lambda-\nu)^{\mathsf{T}} : \lambda, \nu \in \mathbb{R} \}$. This has a basis of $\{(1,1,1)^{\mathsf{T}}, (0,1,-1)^{\mathsf{T}}\}$ (obtained by taking $\lambda=1$, $\mu=0$ and $\lambda=0$, $\mu=1$ respectively), so it is a subspace of $\mathbb{R}^3$.</p>
<p><strong>Part b</strong></p>
<p>We cannot do the same trick as before, since the square of a real number is always at least zero. Clearly $(1,-1,0)^{\mathsf{T}}\in B$, but $-1$ times this vector, i.e. $(-1,1,0)^{\mathsf{T}}\notin B$, and thus $B$ is not a subspace.</p>
<p><strong>Part c</strong></p>
<p>We know that $(0,0,0)^{\mathsf{T}}$ is an element of every (three-dimensional!) subspace, so we can $C$ can only be a subspace if $\gamma = 0$. In this case, we can find a basis for $C$ (say $\{ (3,0,-1)^{\mathsf{T}},(0,3,2)^{\mathsf{T}} \}$), and conclude that it is indeed a subspace.</p>
<p><strong>Part d</strong></p>
<p>Again, this is not a subspace. Observe that $(0,1,0)^{\mathsf{T}}\in D$, so if $D$ were a subspace, then any (real!) multiple should be in $D$ also. However, $\frac12 (0,1,0)^{\mathsf{T}} \notin D$ because the second component is not an integer.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Check if a Bilinear form is an Inner Product</title>
    <url>/mml-exercise-3-2.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.2</strong></p>
</div>

<a id="more"></a>

<p>Solution: Let $\mathbf x=[x_1,x_2]^\top$, $\mathbf y=[y_1,y_2]^\top$. By direct computations, we have $$\langle \mathbf x,\mathbf y\rangle=2x_1y_1+x_2y_1+2x_2y_2$$ and $$\langle \mathbf y,\mathbf x\rangle=2x_1y_1+y_2x_1+2x_2y_2.$$Therefore, in general, we see that $\langle \mathbf x,\mathbf y\rangle \ne \langle \mathbf y,\mathbf x\rangle$. This implies that $\langle ,\rangle$ is not an inner product.</p>
<hr>
<p>In general, to be an inner, it requires $\langle \mathbf x,\mathbf y\rangle =\langle \mathbf y,\mathbf x\rangle$. That means $$\mathbf x^T\mathbf A\mathbf y=\mathbf y^T \mathbf A \mathbf x.$$Note that $x^T\mathbf A\mathbf y$ is a number and hence equal to its transpose $y^T\mathbf A^T\mathbf x$. Therefore, it suffices to make sure $$y^T\mathbf A^T\mathbf x=\mathbf y^T \mathbf A \mathbf x,$$ $$y^T (\mathbf A^T-\mathbf A)\mathbf x=0.$$Because of this, $A$ has to be symmetric. </p>
<p>In the complex situation, then we need $\bar{\mathbf{A}}^T=\mathbf A$ since $$\langle \mathbf x,\mathbf y\rangle =\overline{\langle \mathbf y,\mathbf x\rangle}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
      </tags>
  </entry>
  <entry>
    <title>Rotations of vectors by 30 degress on a plane</title>
    <url>/mml-exercise-3-10.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.10</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>We will assume we need to rotate these vectors anticlockwise. A rotation about an angle $\theta$ is given by the matrix $$\begin{bmatrix} \cos\theta&amp;-\sin\theta\\ \sin\theta&amp;\cos\theta \end{bmatrix}.$$ Thus for $\theta=30^\circ$, we have $$R=\begin{bmatrix} \frac{\sqrt{3}}{2}&amp;-\frac{1}{2}\\ \frac12 &amp; \frac{\sqrt3}{2} \end{bmatrix} = \frac12 \begin{bmatrix} \sqrt3 &amp; -1\\ 1&amp;\sqrt3 \end{bmatrix}.$$</p>
<p>Therefore, $$Rx_1 = \frac12 \begin{bmatrix} 2\sqrt3-3\\2+3\sqrt3 \end{bmatrix}$$ and $$Rx_2 = \frac12 \begin{bmatrix} 1\\-\sqrt3 \end{bmatrix}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Rotation</tag>
      </tags>
  </entry>
  <entry>
    <title>Angles between two vectors using difference inner products</title>
    <url>/mml-exercise-3-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.4</strong></p>
</div>

<a id="more"></a>

<p>Solution: We have to compute $\cos\theta =\dfrac{\langle \mathbf x,\mathbf y\rangle}{\sqrt{\langle \mathbf x,\mathbf x\rangle \cdot \langle \mathbf y,\mathbf y\rangle}}$ and then take $\arccos$ to get the angle $\theta$. </p>
<p>a. We have $$\langle \mathbf x,\mathbf y\rangle = 1\cdot (-1)+2\cdot (-1)=-3,$$ $$\langle \mathbf x,\mathbf x\rangle = 1\cdot 1+2\cdot 2=5,$$ $$\langle \mathbf y,\mathbf y\rangle = (-1)\cdot (-1)+(-1)\cdot (-1)=2.$$Hence $$\cos\theta =\dfrac{\langle \mathbf x,\mathbf y\rangle}{\sqrt{\langle \mathbf x,\mathbf x\rangle \cdot \langle \mathbf y,\mathbf y\rangle}}=\frac{-3}{\sqrt{2\cdot 5}}=\frac{-3}{\sqrt{10}}.$$Take inverse function $\arccos$, we get $$\theta =\arccos \dfrac{-3}{\sqrt{10}}\approx 2.82\,\mathrm{rad}.$$ b. We have \begin{align*}\langle \mathbf x,\mathbf y\rangle =&amp;\ \begin{bmatrix} 1 &amp; 2\end{bmatrix}\begin{bmatrix}2 &amp; 1\\ 1 &amp; 3\end{bmatrix}\begin{bmatrix} -1\\ -1\end{bmatrix}\\=&amp;\ \begin{bmatrix} 4 &amp; 7\end{bmatrix}\begin{bmatrix} -1\\ -1\end{bmatrix}=-11,\end{align*} \begin{align*}\langle \mathbf x,\mathbf x\rangle =&amp;\ \begin{bmatrix} 1 &amp; 2\end{bmatrix}\begin{bmatrix}2 &amp; 1\\ 1 &amp; 3\end{bmatrix}\begin{bmatrix} 1\\ 2\end{bmatrix}\\=&amp;\ \begin{bmatrix} 4 &amp; 7\end{bmatrix}\begin{bmatrix} 1\\ 2\end{bmatrix}=18,\end{align*} \begin{align*}\langle \mathbf y,\mathbf y\rangle =&amp;\ \begin{bmatrix} -1 &amp; -1\end{bmatrix}\begin{bmatrix}2 &amp; 1\\ 1 &amp; 3\end{bmatrix}\begin{bmatrix} -1\\ -1\end{bmatrix}\\=&amp;\ \begin{bmatrix} -3 &amp; -4\end{bmatrix}\begin{bmatrix} -1\\ -1\end{bmatrix}=7,\end{align*} Hence $$\cos\theta =\dfrac{\langle \mathbf x,\mathbf y\rangle}{\sqrt{\langle \mathbf x,\mathbf x\rangle \cdot \langle \mathbf y,\mathbf y\rangle}}=\frac{-11}{\sqrt{18\cdot 7}}=\frac{-11}{\sqrt{126}}.$$Take inverse function $\arccos$, we get $$\theta =\arccos \dfrac{-11}{\sqrt{126}}\approx 2.94\,\mathrm{rad}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Angle</tag>
      </tags>
  </entry>
  <entry>
    <title>Distances between two vectors using difference inner products</title>
    <url>/mml-exercise-3-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.3</strong></p>
</div>

<a id="more"></a>

<p>Solution: The distance between $\mathbf x$ and $\mathbf y$ is given by $\sqrt{\langle \mathbf x-\mathbf y,\mathbf x-\mathbf y\rangle }$ and we have $$\mathbf z:=\mathbf x-\mathbf y =\begin{bmatrix}2\\3\\3\end{bmatrix}$$ a. In this case, \begin{align*}\langle \mathbf z,\mathbf z\rangle =\mathbf z^\top \mathbf z=2^2+3^2+3^2=22.\end{align*}Hence the distance is $\sqrt{22}$. </p>
<p>b. In this case, \begin{align*}\langle \mathbf z,\mathbf z\rangle =&amp;\ \mathbf z^\top \mathbf A\mathbf z\\ =&amp;\ [2,3,3]\begin{bmatrix}2&amp;1&amp;0\\1&amp;3&amp;-1\\ 0&amp;-1&amp;2\end{bmatrix}\begin{bmatrix}2\\3\\3\end{bmatrix}\\=&amp;\ [7,8,3]\begin{bmatrix}2\\3\\3\end{bmatrix}=47.\end{align*}Hence the distance is $\sqrt{47}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Distance</tag>
      </tags>
  </entry>
  <entry>
    <title>Orthogonal projection and distance in Euclidean space II</title>
    <url>/mml-exercise-3-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.6</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>We require $\langle e_1, e_2-\pi_U(e_2)\rangle = 0$ and $\langle e_3, e_2-\pi_U(e_2)\rangle = 0$. That is to say, $$\left\langle \begin{bmatrix} 1\\0\\0 \end{bmatrix}, \begin{bmatrix}-\lambda_1\\1\\ -\lambda_2 \end{bmatrix} \right\rangle = 0,$$ and $$\left\langle \begin{bmatrix} 0\\0\\1 \end{bmatrix}, \begin{bmatrix}-\lambda_1\\1\\ -\lambda_2 \end{bmatrix} \right\rangle = 0.$$</p>
<p>Computing the first gives us $\lambda_1=\frac12$, while the second gives $\lambda_2 = -\frac12$.</p>
<p>Therefore, $\pi_U(e_2) = \begin{bmatrix} \frac12 \\ 0\\ -\frac12 \end{bmatrix}$.</p>
<p><strong>Part b</strong></p>
<p>We have $$d(e_2,U) = \lVert e_2-\pi_U(e_2) \rVert = \sqrt{\left\langle \begin{bmatrix}-\frac12 \\ 1\\ \frac12\end{bmatrix},\begin{bmatrix}-\frac12 \\ 1\\ \frac12\end{bmatrix}\right\rangle} = 1.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Orthogonal Projection</tag>
        <tag>Euclidean Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute Kernel and Image of identity minus a projection</title>
    <url>/mml-exercise-3-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.7</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>Let $x\in V$. Observe that $$((id-\pi)\circ(id-\pi))(x) = (id-\pi)(x-\pi(x)) = (x-\pi(x))-(\pi(x)-\pi^2(x)) = x-2\pi(x)+\pi^2(x).$$ Hence $(id -\pi)$ is a projection if and only if $$x-\pi(x) = x-2\pi(x)+\pi^2(x).$$ This happens if and only if $\pi(x) = \pi^2(x)$, that is to say, where $\pi$ is a projection.</p>
<p><strong>Part b</strong></p>
<p>We have $$Im(id-\pi) = \{(id-\pi)(x):x\in V\} = \{x-\pi(x):x\in V\}.$$ Observe that $\pi(x-\pi(x)) = \pi(x)-\pi^2(x) = 0$, since $\pi$ is a projection. Thus, $Im(id-\pi)\subseteq\ker\pi$.</p>
<p>Now, suppose $k\in \ker \pi$. Then $k-\pi(k)=k$, so $k\in Im(id-\pi)$. Thus $\ker\pi\subseteq Im(id-\pi)$. Therefore, we have that $$Im(id-\pi) = \ker\pi. \qquad \lozenge$$</p>
<hr>
<p>We have that $$\ker(id-\pi) = \{x\in V : (id-\pi)(x) = 0\} = \{x\in V : x=\pi(x)\}.$$ Clearly, $\ker(id-\pi)\subseteq Im\pi$.</p>
<p>Take $x\in Im\pi$. Then there exists some $y\in V$ such that $\pi(y)=x$. Observe that $$(id-\pi)(x) = x-\pi(x) = \pi(y)-\pi^2(y) = 0,$$ since $\pi$ is a projection. Hence $Im\pi\subseteq\ker(id-\pi)$. Therefore we have that $\ker(id-\pi) = Im\pi$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Projection</tag>
        <tag>Kernel</tag>
        <tag>Image</tag>
      </tags>
  </entry>
  <entry>
    <title>Computation using Gram-Schmidt method</title>
    <url>/mml-exercise-3-8.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.8</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>We will assume we use the standard dot product as our inner product. Firstly, let’s get an orthogonal basis, then we can simply divide by the magnitude of each vector to get our orthonormal basis.</p>
<p>Since $b_1$ is our first vector, there is nothing to do for now. To get the second vector in our basis, we need a vector, $b_2’$, perpendicular to $b_1$, such that $span(b_1,b_2) = span (b_1, b_2’)$. This is given by $b_2’ = b_2 - \pi_{span(b_1)}(b_2)$.</p>
<p>Now, $$\pi_{span(b_1)}(b_2) = \frac{b_1b_1^\mathsf{T}}{\lVert b_1 \rVert^2} b_2 = \frac{1}{3} \begin{bmatrix} 1&amp;1&amp;1\\ 1&amp;1&amp;1\\ 1&amp;1&amp;1 \end{bmatrix} \begin{bmatrix}-1\\2\\0 \end{bmatrix} = \frac{1}{3}\begin{bmatrix} 1\\1\\1 \end{bmatrix}.$$</p>
<p>Therefore, $$b_2’ = \begin{bmatrix}-\frac43 \\ \frac53 \\ -\frac13 \end{bmatrix}.$$</p>
<p>Hence, our orthonormal basis, $C$, is given by $$C=\left\{\frac{1}{\sqrt3}\begin{bmatrix} 1\\1\\1 \end{bmatrix} , \frac{1}{\sqrt42}\begin{bmatrix}-4\\5\\-1 \end{bmatrix}\right\}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Inner Product</tag>
        <tag>Gram-Schmidt</tag>
      </tags>
  </entry>
  <entry>
    <title>Orthogonal projection and distance in Euclidean space</title>
    <url>/mml-exercise-3-5.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.5</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>Let $v_1, \dots, v_4$ be the four vectors defined in the question. Observe that $$\mathsf{rank}[v_1|v_2|v_3|v_4]=3.$$ Moreover, $\mathsf{rank}[v_1|v_2|v_3]=3$, so these three vectors form a basis of $U$. Let $B$ be this matrix of basis vectors, i.e. $B=[v_1|v_2|v_3]$.</p>
<p>Now we compute $$B^{\mathsf{T}}B = \begin{bmatrix} 9&amp;9&amp;0\\ 9&amp;16&amp;-14\\ 0&amp;-14&amp;31 \end{bmatrix}$$ and $$B^{\mathsf{T}}x = \begin{bmatrix} 9\\23\\-25 \end{bmatrix}.$$</p>
<p>Next, we solve $B^{\mathsf{T}}B\lambda = B^{\mathsf{T}}x$ for $\lambda$. Using Gaussian elimination, we obtain $\lambda = \begin{bmatrix}-3\\ 4\\ 1 \end{bmatrix}$.</p>
<p>Finally, $\pi_U(x)$ is given by $$B\lambda = \begin{bmatrix} 1\\-5\\-1\\-2\\3 \end{bmatrix}.$$</p>
<p><strong>Part b</strong></p>
<p>By construction, $d(x,U) = d(x,\pi_U(x))$. This is given by $$\lVert x-\pi_U(x) \rVert = \begin{Vmatrix}-2\\-4\\0\\6\\-2 \end{Vmatrix}.$$</p>
<p>This norm is given by the square root of the dot product of the vector with itself, so $d(x,U) = \sqrt{60}=2\sqrt{15}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Orthogonal Projection</tag>
        <tag>Euclidean Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the determinant using Laplace expansion and Sarrus rule</title>
    <url>/mml-exercise-4-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.1</strong></p>
</div>

<a id="more"></a>

<p>Solution: By Laplace expansion using the first row, we have \begin{align*}\det(A)=&amp;\ 1\cdot \begin{vmatrix}4 &amp; 6\\ 2 &amp; 4\end{vmatrix}-3\cdot \begin{vmatrix}2 &amp; 6\\ 0 &amp; 4\end{vmatrix} + 5\cdot \begin{vmatrix}2 &amp; 4\\ 0 &amp; 2\end{vmatrix}\\=&amp;\ 1(4\cdot 4-6\cdot 2)-3\cdot(2\cdot 4-6\cdot 0)+5\cdot(2\cdot 2-4\cdot 0)\\ =&amp; \ 4-3\cdot 8+5\cdot 4=0.\end{align*}</p>
<p>Or by Sarrus rule, we have \begin{align*}\det(A)=&amp;\ 1\cdot 4\cdot 4+2\cdot 2\cdot 5+0\cdot 3\cdot 6-0\cdot 4\cdot 5-1\cdot 2\cdot 6-2\cdot 3\cdot 4\\=&amp;\ 16+20-12-24=0.\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Determinant</tag>
        <tag>Laplace Expansion</tag>
      </tags>
  </entry>
  <entry>
    <title>Naive applications of Cauchy-Schwarz inequality</title>
    <url>/mml-exercise-3-9.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 3 Exercise 3.9</strong></p>
</div>

<a id="more"></a>

<p>Solution:  </p>
<p>a. Let $\mathbf x=[x_1,\dots,x_n]^\top$ and $\mathbf y=[1,\dots,1]^\top \in\mathbb R^n$. Then $$\langle \mathbf x, \mathbf y\rangle=x_1+\dots+x_n=1,$$ $$\langle \mathbf x, \mathbf x\rangle = x_1^2+\dots+x_n^2,$$ $$\langle \mathbf y, \mathbf y\rangle = 1+\dots+1=n.$$Applying the Cauchy-Schwarz inequality, we have $$\langle \mathbf x, \mathbf x\rangle\langle \mathbf y, \mathbf y\rangle\geqslant (\langle \mathbf x, \mathbf y\rangle)^2,$$which implies that $$n\sum_{i=1}^n x_i^2\geqslant 1.$$Therefore, we obtain $\sum_{i=1}^n x_i^2\geqslant \frac{1}{n}$. </p>
<p>b. Let $\mathbf x=[\sqrt{x_1},\dots,\sqrt{x_n}]^\top$ and $\mathbf y=[1/\sqrt{x_1},\dots,1/\sqrt{x_n}]^\top \in\mathbb R^n$. Then $$\langle \mathbf x, \mathbf y\rangle = 1+\dots+1=n,$$ $$\langle \mathbf x, \mathbf x\rangle = x_1+\dots+x_n=1,$$ $$\langle \mathbf y, \mathbf y\rangle =\frac{1}{x_1}+\cdots+\frac{1}{x_n}.$$Applying the Cauchy-Schwarz inequality, we have $$\langle \mathbf x, \mathbf x\rangle\langle \mathbf y, \mathbf y\rangle\geqslant (\langle \mathbf x, \mathbf y\rangle)^2,$$which implies that $$1\sum_{i=1}^n\dfrac{1}{x_i}\geqslant n^2.$$Therefore, we obtain $\sum_{i=1}^n \frac{1}{x_i}\geqslant n^2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Cauchy-Schwarz inequality</tag>
      </tags>
  </entry>
  <entry>
    <title>$AA^T$ and $A^TA$ has the same nonzero eigenvalues</title>
    <url>/mml-exercise-4-11.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.11</strong></p>
</div>

<a id="more"></a>

<p>Solution: We start by showing that if $\lambda\neq 0$ is an eigenvalue of $\boldsymbol{A}\boldsymbol A^\top$ then it is also a non-zero eigenvalue of $\boldsymbol A^\top\boldsymbol A$. </p>
<p>Let $\lambda\neq 0$ be an eigenvalue of $\boldsymbol A\boldsymbol A^\top$ and $\vec q$ be a corresponding eigenvector, i.e., $(\boldsymbol A\boldsymbol A^\top)\vec q = \lambda\vec q$. Then </p>
<p>\begin{align*}<br>(\boldsymbol A^\top\boldsymbol A)\boldsymbol A^\top\vec q = \boldsymbol A^\top(\boldsymbol A\boldsymbol A^\top \vec q) = \boldsymbol A^\top(\lambda \vec q) = \lambda \boldsymbol A^\top\vec q.<br>\end{align*} </p>
<p><em>We now need to show that $\boldsymbol A^\top\vec q\neq 0$ before we can conclude that $\lambda$ is an eigenvalue of $\boldsymbol A^\top\boldsymbol A$.</em></p>
<p>Assume $\boldsymbol A^\top\vec q = \vec 0$. Then it would follow that $$\boldsymbol A\boldsymbol A^\top\vec q = \vec 0,$$ which contradicts $$\boldsymbol A\boldsymbol A^\top\vec q = \lambda\vec q\neq \vec 0$$ since $\vec q$ is an eigenvector of $\boldsymbol A\boldsymbol A^\top$ with associated eigenvalue $\lambda$. Therefore, $\vec q\neq \vec 0$, which implies that $\boldsymbol A^\top\vec q\neq \vec 0$. Therefore, $\lambda$ is an eigenvalue of $\boldsymbol A^\top\boldsymbol A$ with $\boldsymbol A^\top\vec q$ as the corresponding eigenvector.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title>The largest singular value of a matrix</title>
    <url>/mml-exercise-4-12.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.12</strong></p>
</div>

<a id="more"></a>

<p>Solution: By SVD (Singular Value Decomposition), we have $A=U\Sigma V^T$. Let $y=V^T x$, then \[\|y\|_2^2=y^Ty=(V^Tx)^TV^Tx=x^TVV^Tx=x^Tx=\|x\|_2^2.\]Then we have\begin{align*}\|A x\|_2^2=&amp;\ (Ax)^T(Ax)=x^TA^TAx\\ = &amp;\ x^T V \begin{bmatrix}\sigma_1^2 &amp; 0 &amp; 0\\ 0 &amp; \ddots &amp; 0\\ 0 &amp; 0 &amp;\sigma_n^2\end{bmatrix}V^Tx \\ =&amp;\ y^T \begin{bmatrix}\sigma_1^2 &amp; 0 &amp; 0\\ 0 &amp; \ddots &amp; 0\\ 0 &amp; 0 &amp;\sigma_n^2\end{bmatrix} y \\ = &amp;\ \sigma_1^2 y_1^2+\cdots+\sigma_n^2y_n^2 \\ \leqslant &amp;\ \sigma_1^2 y_1^2+\cdots+\sigma_1^2y_n^2\\ =&amp;\ \sigma_1^2(y_1^2+\cdots+y_n^2)\\ =&amp;\ \sigma_1^2 \|y\|_2^2= \sigma_1^2 \|x\|_2^2.\end{align*}Hence we have \[\max_{x\ne 0}\frac{\|Ax\|_2}{\|x\|_2}\leqslant \sigma_1^2.\]Moreover, it is possible to choose $x$ such that the inequality above becomes equality. Namely, setting $$x=V(1,0,\dots,0)^T,$$then $y=(1,0,\dots,0)^T$ and $$\|A x\|_2^2=\sigma_1^2,\quad \|x\|_2=1.$$Hence we proved Theorem 4.24.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the determinant of a 5 by 5 matrix</title>
    <url>/mml-exercise-4-2.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.2</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Perform Gaussian elimination to “fix” the first columns. I have used only the rule allowing us to add a multiple of a row to a different row, which doesn’t change the determinant. We have $$\begin{bmatrix} 2&amp;0&amp;1&amp;2&amp;0\\ 0&amp;-1&amp;-1&amp;-1&amp;1\\ 0&amp;0&amp;1&amp;0&amp;3\\ 0&amp;0&amp;3&amp;1&amp;2\\ 0&amp;0&amp;-1&amp;-1&amp;1 \end{bmatrix}.$$</p>
<p>From here, we can either continue with Gaussian elimination to get our matrix into upper triangular form, then multiply the entries on the diagonal together (remembering to take into account any elementary operations which would change the determinant!), or we can simply compute the determinant of the lower-right $3\times 3$ matrix, since this is quick to do by hand (it is $-3$). Thus the determinant of the overall matrix is $2\cdot -1\cdot -3 = 6$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Determinant</tag>
        <tag>Laplace Expansion</tag>
        <tag>Gaussian Elimination</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the eigenspaces of two by two matrices</title>
    <url>/mml-exercise-4-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.3</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>If we solve the equation $\det(A-\lambda I) = 0$ for $\lambda$, we obtain $\lambda = 1$ only. (Or, indeed, we can observe that $A$ is in lower triangular form, so the eigenvalues are the entries on the main diagonal.)</p>
<p>The eigenspace is $$E_1 = \{x\in \mathbb{R}^2 : (A-I)(x)=0\} = \mathrm{span}\{(0,1)\}.$$</p>
<p><strong>Part b</strong></p>
<p>Again, solving $\det(B-\lambda I ) = 0$, we find that $\lambda=2$ or $\lambda = -3$. We then have the eigenspaces $$E_2 = \mathrm{span}\{(1,2)\}$$ and $$E_{-3} = \mathrm{span}\{ (-2,1) \}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Determinant</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the eigenspaces of a 4 by 4 matrices</title>
    <url>/mml-exercise-4-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.4</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>If we take $\det(A-\lambda I)$ and simplify, we have $$(\lambda-2)(\lambda-1)(\lambda+1)^2.$$ So we have three eigenvalues. For $\lambda=2,1$, our eigenspace will certainly have dimension 1. For $\lambda = -1$, it could (at this stage!) have dimension 1 or 2.</p>
<p>Observe that $(1,0,1,1)$ is an eigenvector with eigenvalue 2, and $(1,1,1,1)$ is an eigenvector with eigenvalue 1. Thus $$E_2=\mathrm{span}\{(1,0,1,1)\}$$ and $$E_1 = \mathrm{span}\{(1,1,1,1)\}.$$</p>
<p>Now observe that $\mathrm{rank}(A+I)=3$, so there can only be one linearly independent eigenvector with eigenvalue -1. Note that $(0,1,1,0)$ will do. Hence $$E_{-1} = \mathrm{span}\{(0,1,1,0)\}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Determinant</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
      </tags>
  </entry>
  <entry>
    <title>Find the best rank-1 approximation of a matrix</title>
    <url>/mml-exercise-4-10.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.10</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Using our Singular value decomposition from <a href="/mml-exercise-4-8.html">Question 4.8</a>, we construct $$A_1 = \sigma_1 u_1 v_1^{\mathsf{T}} = 5 \begin{bmatrix} \frac{1}{\sqrt2}\\ \frac{1}{\sqrt2} \end{bmatrix} \begin{bmatrix} \frac{1}{\sqrt2}&amp;\frac{1}{\sqrt2}&amp;0 \end{bmatrix} = \frac52 \begin{bmatrix} 1&amp;1&amp;0\\ 1&amp;1&amp;0 \end{bmatrix},$$ and similarly $$A_2 = \frac12 \begin{bmatrix} 1&amp;-1&amp;4\\-1&amp;1&amp;-4 \end{bmatrix}.$$ Then $A_1$ and $A_2$ both have rank one, with $A=A_1+A_2$, as required.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>SVD</tag>
        <tag>Approximation</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute eigenspaces of matrices and determine if they are diagonalisable</title>
    <url>/mml-exercise-4-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.6</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>The characteristic polynomial is $(5-\lambda)(1-\lambda)^2$. </p>
<p>Now, $\mathrm{rank}(A-I) = 2$, so there is only one linearly independent eigenvector for $\lambda=1$. Hence $A$ is not diagonalisable.</p>
<p>We have $E_5 = \mathrm{span}\{(1,1,0)\}$, and $E_1=\mathrm{span}\{(-3,1,0)\}$.</p>
<p><strong>Part b</strong></p>
<p>The characteristic polynomial here is $-\lambda^3(1-\lambda)$, so the eigenvalues are 1, and 0 (with multiplicity 3). Observe that $$\mathrm{rank}(A-0I) = rank A = 1,$$ so there are three linearly independent eigenvectors for the eigenvalue 0. With the other eigenvector for $\lambda=1$, we will have a basis of eigenvectors, and hence $A$ will be diagonalisable.</p>
<p>We have $$E_1 = \mathrm{span}\{(1,0,0,0)\},$$ and $$E_0 = \mathrm{span}\{(1,-1,0,0),(0,0,1,0),(0,0,0,1)\}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>Diagonalisability</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalisability is unrelated to invertibility</title>
    <url>/mml-exercise-4-5.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.5</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Only the first two are diagonalisable – they are diagonal, so there is nothing to prove! The other two, however, are not diagonalisable – each only has exactly one eigenvalue. Moreover, the eigenspaces correspond to the eigenvalue are one-dimensional. However, we need there to exist a basis of eigenvectors to yield diagonalisability.</p>
<p>Only the first and third matrices are invertible – the determinants are non-zero, while the other two matrices have determinant zero.</p>
<p>This tells us that diagonalisability is indeed unrelated to invertibility!</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>Diagonalisability</tag>
        <tag>Invertibility</tag>
      </tags>
  </entry>
  <entry>
    <title>Find the singular value decomposition of a matrix</title>
    <url>/mml-exercise-4-8.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.8</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>First, we compute $$A^{\mathsf{T}}A = \begin{bmatrix} 13&amp;12&amp;2\\ 12&amp;13&amp;-2\\ 2&amp;-2&amp;8 \end{bmatrix}.$$ We can diagonalise this to find $$D = \begin{bmatrix} 25&amp;0&amp;0\\ 0&amp;9&amp;0\\ 0&amp;0&amp;0 \end{bmatrix}$$ and $$P = \begin{bmatrix} \frac{1}{\sqrt2}&amp;\frac{1}{\sqrt{18}}&amp;-\frac23\\ \frac{1}{\sqrt2}&amp;-\frac{1}{\sqrt{18}}&amp;\frac23\\ 0&amp;\frac{4}{\sqrt{18}}&amp;\frac13 \end{bmatrix}.$$</p>
<p>We take the square roots of the entries of $D$ to find $\Sigma = \begin{bmatrix} 5&amp;0&amp;0\\ 0&amp;3&amp;0 \end{bmatrix}$, with $V$ equalling our $P$ above.</p>
<p>From here, we compute $$u_1 = \frac1{\sigma_1}Av_1 = \frac15\begin{bmatrix} 3&amp;2&amp;2\\ 2&amp;3&amp;-2 \end{bmatrix} \begin{bmatrix} \frac{1}{\sqrt2}\\ \frac{1}{\sqrt2}\\ 0 \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt2}\\ \frac{1}{\sqrt2} \end{bmatrix},$$ and $$u_2 = \frac{1}{\sigma_2} A v_2 = \frac13 \begin{bmatrix} 3&amp;2&amp;2\\ 2&amp;3&amp;-2 \end{bmatrix} \begin{bmatrix} \frac{1}{\sqrt{18}}\\-\frac{1}{\sqrt{18}}\\ \frac{4}{\sqrt{18}} \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt2}\\-\frac{1}{\sqrt2} \end{bmatrix},$$ giving $U=\frac{1}{\sqrt2}\begin{bmatrix} 1&amp;1\\1&amp;-1 \end{bmatrix}$.</p>
<p>It can be checked that $A = U\Sigma V^{\mathsf{T}}$, indeed!</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine matrices if they are diagonalisable II</title>
    <url>/mml-exercise-4-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.7</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>If we form the characteristic polynomial, we have $\lambda^2-4\lambda +8$, which has no roots in $\mathbb{R}$. However, if we extend to $\mathbb{C}$, then we will be able to diagonalise the matrix.</p>
<p><strong>Part b</strong></p>
<p>This is a symmetric matrix, and is therefore diagonalisable. Its eigenvalues are $3$, and $0$ with multiplicity two, so its diagonal form is $$\begin{bmatrix} 3&amp;0&amp;0\\ 0&amp;0&amp;0\\ 0&amp;0&amp;0 \end{bmatrix},$$ and a basis of eigenvectors is $$\{(1,1,1),(1,-1,0),(1,0,-1)\}.$$</p>
<p><strong>Part c</strong></p>
<p>Here, we have three distinct eigenvalues, and $\lambda = 4$ has multiplicity two. However, $\mathrm{rank}(A-4I) = 3$, so there is only one linearly independent eigenvector, and this $A$ cannot have a basis of eigenvectors, so it is not diagonalisable.</p>
<p><strong>Part d</strong></p>
<p>Again here we have two eigenvectors – $\lambda=1$ with multiplicity one and $\lambda=2$ with multiplicity two. However, this time, observe that $\mathrm{rank}(A-2I)=1$, so there are indeed two linearly independent eigenvectors for this eigenvalue. Thus $A$ is diagonalisable, with diagonal form $$\begin{bmatrix} 1&amp;0&amp;0\\ 0&amp;2&amp;0\\ 0&amp;0&amp;2 \end{bmatrix},$$ with eigenvectors $$\{(3,-1,3),(2,1,0),(2,0,1)\}.$$</p>
<p>We have $$E_1 = \mathrm{span}\{(1,0,0,0)\},$$ and $$E_0 = \mathrm{span}\{(1,-1,0,0),(0,0,1,0),(0,0,0,1)\}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>Diagonalisability</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute derivative using product rule and chain rule</title>
    <url>/mml-exercise-5-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.1</strong></p>
</div>

<a id="more"></a>

<p>Solution: By Chain Rule (5.32), we have<br>$$ \big(\sin(x^3)\big)’=\cos(x^3)(x^3)’=3x^2\cos(x^3). $$<br>We also have<br>$$ \big(\log(x^4)\big)’=\big(4\log(x)\big)’=\frac{4}{x}=4x^{-1}. $$<br>Applying Product Rule (5.29), we obtain<br>\begin{align*} f’(x)=&amp;\ \log(x^4) \sin(x^3)\\=&amp;\ \big(\log(x^4)\big)’\sin(x^3)+\log(x^4)\big(\sin(x^3)\big)’\\=&amp;\ 4x^{-1}\sin(x^3)+\log(x^4)3x^2\cos(x^3)\\=&amp;\ 4x^{-1}\sin(x^3)+3x^2\log(x^4)\cos(x^3). \end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Product Rule</tag>
        <tag>Chain Rule</tag>
      </tags>
  </entry>
  <entry>
    <title>Find the singular value decomposition of a matrix II</title>
    <url>/mml-exercise-4-9.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 4 Exercise 4.9</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Observe that the eigenvalues of $A$ are complex, so we cannot simply find the eigendecomposition. Proceeding as in <a href="/mml-exercise-4-8.html">Question 4.8</a>, we have $A^{\mathsf{T}}A = \begin{bmatrix} 5&amp;3\\ 3&amp;5 \end{bmatrix}$, which when we perform the eigendecomposition on this new matrix, we obtain $$D = \begin{bmatrix} 8&amp;0\\ 0&amp;2 \end{bmatrix}\quad \text{and} \quad P=\frac{1}{\sqrt2}\begin{bmatrix} 1&amp;-1\\ 1&amp;1 \end{bmatrix}.$$ This $P$ is again our required $V$, and we have $\Sigma = \begin{bmatrix} 2\sqrt2 &amp; 0\\ 0&amp;\sqrt2 \end{bmatrix}$.</p>
<p>As before, we can now compute $$u_1 = \frac{1}{2\sqrt2}\begin{bmatrix} 2&amp;2\\-1&amp;1 \end{bmatrix} \begin{pmatrix} \frac{1}{\sqrt2}\\ \frac{1}{\sqrt2} \end{pmatrix} = \begin{bmatrix} 1\\0 \end{bmatrix},$$ and similarly $u_2 = \begin{bmatrix} 0\\1 \end{bmatrix}$. Hence, our $U$ turns out to be the identity matrix.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>SVD</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute derivative of the function defining normal distribution</title>
    <url>/mml-exercise-5-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.3</strong></p>
</div>

<a id="more"></a>

<p>Solution: Clearly, we have $$\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)’=-\frac{1}{2\sigma^2}2(x-\mu)=\frac{-(x-\mu)}{\sigma^2}.$$Therefore, by Chain rule (5.32), we have \begin{align*}f’(x)=&amp;\ \exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)\cdot \left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)’\\=&amp;\ \frac{-(x-\mu)}{\sigma^2}\cdot\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Chain Rule</tag>
        <tag>Normal Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the derivative of the logistic sigmoid</title>
    <url>/mml-exercise-5-2.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.2</strong></p>
</div>

<a id="more"></a>

<p>Solution: By Chain rule (5.32), we have $$(1+\exp(-x))’=0+\exp(-x)(-x)’=-\exp(-x).$$ By the Quotient rule (5.30), we have\begin{align*}f’(x)=&amp;\ \frac{(1)’(1+\exp(-x))-1(1+\exp(-x))’}{(1+\exp(-x))^2}\\=&amp;\ \frac{0(1+\exp(-x))-(-\exp(-x))}{(1+\exp(-x))^2}\\=&amp;\ \frac{\exp(-x)}{(1+\exp(-x))^2}.\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Chain Rule</tag>
        <tag>Quotient Rule</tag>
        <tag>Logistic</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the Jacobians of functions</title>
    <url>/mml-exercise-5-5.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.5</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>We can see below that $\dfrac{\partial f_1}{\partial x}$ has dimension $1\times2$; $\dfrac{\partial f_2}{\partial x}$ has dimension $1\times n$; and $\dfrac{\partial f_3}{\partial x}$ has dimension $n^2\times n$.</p>
<hr>
<p><strong>Part b</strong></p>
<p>We have $$\frac{\partial f_1}{\partial x} = \begin{bmatrix} \cos(x_1)\cos(x_2)&amp;-\sin(x_1)\sin(x_2) \end{bmatrix};$$ $$\frac{\partial f_2}{\partial x} = y^{\mathsf{T}}.$$ (Remember, $y$ is a column vector!)</p>
<hr>
<p><strong>Part c</strong></p>
<p>Note that $xx^{\mathsf{T}}$ is the matrix $$\begin{bmatrix} x_1^2 &amp; x_1x_2 &amp; \cdots &amp; x_1x_n \\ x_2x_1 &amp; x_2^2 &amp; \cdots &amp; x_2x_n \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_nx_1 &amp; x_nx_2 &amp; \cdots &amp; x_n^2 \end{bmatrix}.$$ Thus its derivative will be a higher-order tensor. However, if we consider the matrix to be an $n^2$-dimensional object in its own right, we can compute the Jacobian. Its first row consists of $$\begin{bmatrix} 2x_1 &amp; x_2 &amp; \cdots &amp; x_n | x _2 &amp; 0 &amp;\cdots &amp; 0 | \cdots | x_n&amp;0&amp;\cdots&amp;0 \end{bmatrix} ,$$ where I have inserted a vertical bar every $n$ columns, to aid readability.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Jacobian</tag>
      </tags>
  </entry>
  <entry>
    <title>Differentiate vector-valued functions with respect to vector-valued variables</title>
    <url>/mml-exercise-5-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.6</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>We have $$\frac{df}{dt} = \cos(\log(t^{\mathsf{T}}t))\cdot\frac1{t^{\mathsf{T}}t}\cdot \begin{bmatrix} 2t_1&amp;2t_2&amp;\cdots&amp;2t_D \end{bmatrix} = \cos(\log(t^{\mathsf{T}}t))\cdot\frac{2t^{\mathsf{T}}}{t^{\mathsf{T}}t}.$$</p>
<p>For $g$, if we explicitly compute $AXB$ and find its trace, we have that $$g(X) = \sum_{k=1}^D \sum_{j=1}^F \sum_{i=1}^E a_{ki}x_{ij}b_{jk}.$$ Thus we have, $$\frac{\partial g}{\partial x_{ij}} = \sum_{k=1}^D b_{jk}a_{ki},$$ and this is the $(i,j)$-th entry of the required derivative. Hence $$\frac{dg}{dX} = B^{\mathsf{T}}A^{\mathsf{T}}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Multivariable Calculus</tag>
      </tags>
  </entry>
  <entry>
    <title>Differentiate vector-valued functions with respect to vector-valued variables II</title>
    <url>/mml-exercise-5-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.7</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>The chain rule tells us that $$\frac{df}{dx} = \frac{df}{dz}\frac{dz}{dx},$$ where $\dfrac{df}{dz}$ has dimension $1\times 1$, and $\dfrac{dz}{dx}$ has dimension $1\times D$. We know $$\frac{dz}{dx}=2x^{\mathsf{T}}$$ from $f$ in <a href="/mml-exercise-5-6.html">Question 6</a>. Also, $\dfrac{df}{dz} = \dfrac{1}{1+z}$.</p>
<p>Therefore, $\dfrac{df}{dx} = \dfrac{2x^{\mathsf{T}}}{1+x^{\mathsf{T}}x}$.</p>
<hr>
<p><strong>Part b</strong></p>
<p>Here we have $\dfrac{df}{dz}$ is an $E\times E$ matrix, namely $$\begin{bmatrix} \cos z_1 &amp; 0 &amp; \cdots &amp; 0\\ 0 &amp; \cos z_2 &amp; \cdots &amp; 0\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 0&amp;\cdots&amp;\cos z_E \end{bmatrix}.$$</p>
<p>Also, $\dfrac{dz}{dx}$ is an $E\times D$-dimensional matrix, namely $A$ itself.</p>
<p>The overall derivative is obtained by multiplying these two matrices together, which will again give us an $E\times D$-dimensional matrix.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Multivariable Calculus</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the Taylor polynomials of trigonometric functions</title>
    <url>/mml-exercise-5-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.4</strong></p>
</div>

<a id="more"></a>

<p>Solution: By Definition 5.3, we have to compute $f(x_0)$, $f’(x_0)$, $f^{(2)}(x_0)$, $f^{(3)}(x_0)$, $f^{(4)}(x_0)$, $f^{(5)}(x_0)$. It is not hard to see that $$f’(x)=\cos x -\sin x,$$ $$f^{(2)}(x)=-\sin x-\cos x,$$ $$f^{(3)}(x)=-\cos x + \sin x,$$ $$f^{(4)}(x)=\sin x+\cos x,$$ $$f^{(5)}(x)=\cos x-\sin x.$$ Hence we get $$f(0)=f’(0)=f^{(4)}(0)=f^{(5)}(0)=1,$$ $$f^{(2)}(0)=f^{(3)}(0)=-1.$$Now it is easy to see that $$T_0=1,$$ $$T_1=x+1,$$ $$T_2=-\frac{1}{2}x^2+x+1,$$ $$T_3=-\frac{1}{6}x^3-\frac{1}{2}x^2+x+1$$ $$T_4=\frac{1}{24}x^4-\frac{1}{6}x^3-\frac{1}{2}x^2+x+1,$$ $$T_5=\frac{1}{120}x^5+\frac{1}{24}x^4-\frac{1}{6}x^3-\frac{1}{2}x^2+x+1.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Taylor Series</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the gradient for a multivariable function</title>
    <url>/mml-exercise-5-9.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.9</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Piecing this together, replacing $z$ with $t(\epsilon,\nu)$ throughout, we have that $$g(\nu) = \log(p(x,t(\epsilon,\nu))) - \log(q(t(\epsilon,\nu),\nu)).$$</p>
<p>Therefore, $$\frac{dg}{d\nu} = \frac{p’(x,t(\epsilon,\nu))\cdot t’(\epsilon,\nu) }{p(x,t(\epsilon,\nu))} - \frac{q’(t(\epsilon,\nu),\nu)\cdot t’(\epsilon,\nu)}{q(t(\epsilon,\nu),\nu)}.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Multivariable Calculus</tag>
      </tags>
  </entry>
  <entry>
    <title>Differentiate vector-valued functions with respect to vector-valued variables III</title>
    <url>/mml-exercise-5-8.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 5 Exercise 5.8</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>We have $\dfrac{df}{dz}$ has dimension $1\times 1$, and is simply $-\frac12 \exp(-\frac12 z)$.</p>
<p>Now, $\dfrac{dz}{dy}$ has dimension $1\times D$, and is given by $y^{\mathsf{T}}(S^{-1}+(S^{-1})^{\mathsf{T}})$.</p>
<p>Finally, $\dfrac{dy}{dx}$ has dimension $D\times D$, and is just the identity matrix.</p>
<p>Again, we multiply these all together to get our final derivative.</p>
<hr>
<p><strong>Part b</strong></p>
<p>If we explicitly write out $xx^{\mathsf{T}}+\sigma^2I$, and compute its trace, we find that $$f(x) = x_1^2 + \dots + x_n^2 + n\sigma^2.$$</p>
<p>Hence, $\dfrac{df}{dx} = 2x^{\mathsf{T}}$.</p>
<hr>
<p><strong>Part c</strong></p>
<p>Here, $$\frac{df}{dz} = \begin{bmatrix} \frac{1}{\cosh^2z_1}&amp;0&amp;\cdots&amp;0\\ 0&amp;\frac{1}{\cosh^2z_2}&amp;\cdots&amp;0\\ \vdots &amp; \vdots&amp;\ddots&amp;\vdots\\ 0&amp;0&amp;\cdots&amp;\frac{1}{\cosh^2z_M} \end{bmatrix},$$ while $\dfrac{dz}{dx} = A$, as in <a href="/mml-exercise-5-7.html">Question 7b</a>.</p>
<p>Finally, $\dfrac{df}{dx}$ is given by the product of these two matrices.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Real Analysis";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "402d8b59cc9faa66d8d6b3b1eef9c01e";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "bottom";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Multivariable Calculus</tag>
      </tags>
  </entry>
  <entry>
    <title>Express the Gaussian distributions as an exponential family distribution</title>
    <url>/mml-exercise-6-10.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.10</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>The two normal distributions are given by</p>
<p>$$ \mathcal{N}(\mathbf{x}|\mathbf{a}, \mathbf{A}) = (2\pi)^{-\frac{D}{2}}|\mathbf{A}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{a})^T\mathbf{A}^{-1}(\mathbf{x} - \mathbf{a})\right],$$ $$\mathcal{N}(\mathbf{x}|\mathbf{b}, \mathbf{B}) = (2\pi)^{-\frac{D}{2}}|\mathbf{B}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{b})^T\mathbf{B}^{-1}(\mathbf{x} - \mathbf{b})\right] $$</p>
<p>their product is</p>
<p>$$ \mathcal{N}(\mathbf{x}|\mathbf{a}, \mathbf{A}) \mathcal{N}(\mathbf{x}|\mathbf{b}, \mathbf{B}) = (2\pi)^{-D}|\mathbf{A}\mathbf{B}|^{-\frac{1}{2}} \exp\left\{-\frac{1}{2}\left[(\mathbf{x} - \mathbf{a})^T\mathbf{A}^{-1}(\mathbf{x} - \mathbf{a})+(\mathbf{x} - \mathbf{b})^T\mathbf{B}^{-1}(\mathbf{x} - \mathbf{b})\right]\right\} $$</p>
<p>The expression in the exponent can be written as</p>
<p>\begin{align*} \Phi =&amp;\ (\mathbf{x} - \mathbf{a})^T\mathbf{A}^{-1}(\mathbf{x} - \mathbf{a})+(\mathbf{x} - \mathbf{b})^T\mathbf{B}^{-1}(\mathbf{x} - \mathbf{b})\\=&amp;\ \mathbf{x}^T\mathbf{A}^{-1}\mathbf{x} - \mathbf{a}^T\mathbf{A}^{-1}\mathbf{x} - \mathbf{x}^T\mathbf{A}^{-1}\mathbf{a}+ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a}+ \mathbf{x}^T\mathbf{B}^{-1}\mathbf{x} - \mathbf{b}^T\mathbf{B}^{-1}\mathbf{x} - \mathbf{x}^T\mathbf{B}^{-1}\mathbf{b}+ \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b}\\=&amp;\ \mathbf{x}^T(\mathbf{A}^{-1}+\mathbf{B}^{-1})\mathbf{x}- (\mathbf{a}^T\mathbf{A}^{-1} + \mathbf{b}^T\mathbf{B}^{-1})\mathbf{x}- \mathbf{x}^T(\mathbf{A}^{-1}\mathbf{a} + \mathbf{B}^{-1}\mathbf{b})+ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b}<br>\end{align*}</p>
<p>we now introduce notation</p>
<p>$$ \mathbf{C}^{-1} = (\mathbf{A}^{-1}+\mathbf{B}^{-1}),$$  $$ \mathbf{c} = \mathbf{C}(\mathbf{A}^{-1}\mathbf{a} + \mathbf{B}^{-1}\mathbf{b}),$$ $$ \mathbf{c}^T = (\mathbf{a}^T\mathbf{A}^{-1} + \mathbf{b}^T\mathbf{B}^{-1})C.$$</p>
<p>(This can be checked by transposing the previous equation).</p>
<p>The expression in the exponent now takes form</p>
<p>\begin{align*} \Phi=&amp;\ \mathbf{x}^T\mathbf{C}^{-1}\mathbf{x} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{x} - \mathbf{x}^T\mathbf{C}^{-1}\mathbf{c}+ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b}\\=&amp;\ \mathbf{x}^T\mathbf{C}^{-1}\mathbf{x} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{x} - \mathbf{x}^T\mathbf{C}^{-1}\mathbf{c}+ \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c} + \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b}- \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c}\\=&amp;\ (\mathbf{x} - \mathbf{c})^T\mathbf{C}^{-1}(\mathbf{x} - \mathbf{c})+ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c}\end{align*}</p>
<p>where we have completed the square.</p>
<p>The product of the two probability distributions can be now written as</p>
<p>\begin{align*} &amp;\ \mathcal{N}(\mathbf{x}|\mathbf{a}, \mathbf{A}) \mathcal{N}(\mathbf{x}|\mathbf{b}, \mathbf{B}) \\=&amp;\ (2\pi)^{-D}|\mathbf{A}\mathbf{B}|^{-\frac{1}{2}} \exp\left\{-\frac{1}{2}\left[(\mathbf{x} - \mathbf{c})^T\mathbf{C}^{-1}(\mathbf{x} - \mathbf{c})+ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c} \right]\right\}\\=&amp;\ (2\pi)^{-\frac{D}{2}}|\mathbf{C}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{c})^T\mathbf{C}^{-1}(\mathbf{x} - \mathbf{c})\right] \times (2\pi)^{-\frac{D}{2}}\frac{|\mathbf{A}\mathbf{B}|^{-\frac{1}{2}}}{|\mathbf{C}|^{-\frac{1}{2}}} \exp\left\{-\frac{1}{2}\left[ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c} \right]\right\}\\=&amp;\ c\mathcal{N}(\mathbf{c}|\mathbf{c}, \mathbf{C}),\end{align*}</p>
<p>where we defined</p>
<p>$$ c = (2\pi)^{-\frac{D}{2}}\frac{|\mathbf{A}\mathbf{B}|^{-\frac{1}{2}}}{|\mathbf{C}|^{-\frac{1}{2}}} \exp\left\{-\frac{1}{2}\left[ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c} \right]\right\} $$</p>
<p>We now can used the properties that a) the determinant of a matrix product is product of the determinants, and b) determinant of a matrix inverse is the inverse of the determinant of this matrix, and write</p>
<p>$$ \frac{|\mathbf{A}||\mathbf{B}|}{|\mathbf{C}|}= |\mathbf{A}||\mathbf{C}^{-1}||\mathbf{B}|= |\mathbf{A}\mathbf{C}^{-1}\mathbf{B}|= |\mathbf{A}(\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{B}|= |\mathbf{A} + \mathbf{B}| $$</p>
<p>For the expression in the exponent we can write</p>
<p>\begin{align*} &amp;\ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \mathbf{c}^T\mathbf{C}^{-1}\mathbf{c}\\=&amp;\ \mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} + \mathbf{b}^T\mathbf{B}^{-1}\mathbf{b}- (\mathbf{a}^T\mathbf{A}^{-1} + \mathbf{b}^T\mathbf{B}^{-1})(\mathbf{A}^{-1} + \mathbf{B}^{-1})^{-1} (\mathbf{A}^{-1}\mathbf{a} + \mathbf{B}^{-1}\mathbf{b})\\=&amp;\ \mathbf{a}^T\left[\mathbf{A}^{-1} - \mathbf{A}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{A}^{-1}\right]\mathbf{a}+ \mathbf{b}^T\left[\mathbf{B}^{-1} - \mathbf{B}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{B}^{-1}\right]\mathbf{b}\\&amp; \qquad- \mathbf{a}^T\mathbf{A}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})^{-1} \mathbf{B}^{-1}\mathbf{b}- \mathbf{b}^T\mathbf{B}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})^{-1} \mathbf{A}^{-1}\mathbf{a} \end{align*}</p>
<p>Using the property $(\mathbf{A}\mathbf{B})^{-1} = \mathbf{B}^{-1}\mathbf{A}^{-1}$ we obtain</p>
<p>$$ \mathbf{A}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})^{-1} \mathbf{B}^{-1}= \left[\mathbf{B}(\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{A}\right]^{-1}= (\mathbf{A} + \mathbf{B})^{-1} $$</p>
<p>and</p>
<p>\begin{align*} &amp;\ \mathbf{A}^{-1} - \mathbf{A}^{-1}(\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{A}^{-1}=\mathbf{A}^{-1}\left[1 - (\mathbf{A}^{-1} + \mathbf{B}^{-1})\mathbf{A}^{-1}\right]\\=&amp;\ \mathbf{A}^{-1}\left[1 - \mathbf{B}(\mathbf{A} + \mathbf{B})^{-1}\mathbf{A}\mathbf{A}^{-1}\right]= \mathbf{A}^{-1}\left[1 - \mathbf{B}(\mathbf{A} + \mathbf{B})^{-1}\right]\\=&amp;\ \mathbf{A}^{-1}\left[(\mathbf{A} + \mathbf{B}) - \mathbf{B}\right](\mathbf{A} + \mathbf{B})^{-1}= (\mathbf{A} + \mathbf{B})^{-1} \end{align*}</p>
<p>we thus conclude that</p>
<p>$$ c = (2\pi)^{-\frac{D}{2}}|\mathbf{A}+\mathbf{B}|^{-\frac{1}{2}} \exp\left\{-\frac{1}{2}( \mathbf{a} - \mathbf{b})^T(\mathbf{A} + \mathbf{B})^{-1}(\mathbf{a} -\mathbf{b})\right\}= \mathcal{N}(\mathbf{b}|\mathbf{a}, \mathbf{A}+ \mathbf{B})= \mathcal{N}(\mathbf{a}|\mathbf{b}, \mathbf{A}+ \mathbf{B}). $$</p>
<hr>
<p><strong>Part b</strong></p>
<p>Multivariate normal distribution, $\mathcal{N}(\mathbf{x}|\mathbf{a},\mathbf{A})$ can be represented as a distribution from an exponential family:</p>
<p>\begin{align*} &amp;\ \mathcal{N}(\mathbf{x}|\mathbf{a},\mathbf{A}) = (2\pi)^{-\frac{D}{2}}|\mathbf{A}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{a})^T\mathbf{A}^{-1}(\mathbf{x} - \mathbf{a})\right]\\=&amp;\ (2\pi)^{-\frac{D}{2}} \exp\left[-\frac{1}{2}\text{tr}(\mathbf{A}^{-1}\mathbf{x}\mathbf{x}^T) + \mathbf{a}^T\mathbf{A}^{-1}\mathbf{x}- \frac{1}{2}\mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} - \frac{1}{2}\log|\mathbf{A}| \right],\end{align*} </p>
<p>where we used that $\mathbf{a}^T\mathbf{A}^{-1}\mathbf{x} = \mathbf{x}^T\mathbf{A}^{-1}\mathbf{a}$, and also write the first term as</p>
<p>$$ \mathbf{x}^T\mathbf{A}^{-1}\mathbf{x}= \sum_{i,j}x_i (\mathbf{A}^{-1})_{ij} x_j= \sum_{i,j}(\mathbf{A}^{-1})_{ij} x_j x_i= \sum_{i,j}(\mathbf{A}^{-1})_{ij} (\mathbf{x}\mathbf{x}^T)_{ji}= \text{tr}(\mathbf{A}^{-1}\mathbf{x}\mathbf{x}^T) $$</p>
<p>Representing $\mathcal{N}(\mathbf{x}|\mathbf{b},\mathbf{B})$ in a similar way and multiplying the two distributions we readily obtain</p>
<p>\begin{align*} &amp;\ \mathcal{N}(\mathbf{x}|\mathbf{a},\mathbf{A})\mathcal{N}(\mathbf{x}|\mathbf{b},\mathbf{B})\\=&amp;\ (2\pi)^{-D} \exp\left\{-\frac{1}{2}\text{tr}\left[(\mathbf{A}^{-1}+ \mathbf{B}^{-1})\mathbf{x}\mathbf{x}^T\right]+ (\mathbf{a}^T\mathbf{A}^{-1}+\mathbf{b}^T\mathbf{B}^{-1})\mathbf{x}\right.\\ &amp;\ \left. - \frac{1}{2}\mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} - \frac{1}{2}\log|\mathbf{A}|- \frac{1}{2}\mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \frac{1}{2}\log|\mathbf{B}| \right\}\\=&amp;\ c\mathcal{N}(\mathbf{x}|\mathbf{c},\mathbf{C}), \end{align*} </p>
<p>where we defined</p>
<p>$$ \mathbf{C}^{-1} = \mathbf{A}^{-1}+ \mathbf{B}^{-1},\quad \mathbf{c}^T\mathbf{C}^{-1} = \mathbf{a}^T\mathbf{A}^{-1}+\mathbf{b}^T\mathbf{B}^{-1},$$ $$ c = (2\pi)^{-\frac{D}{2}} \exp\left\{\frac{1}{2}\mathbf{c}^T\mathbf{C}^{-1}\mathbf{c} + \frac{1}{2}\log|\mathbf{C}|- \frac{1}{2}\mathbf{a}^T\mathbf{A}^{-1}\mathbf{a} - \frac{1}{2}\log|\mathbf{A}|- \frac{1}{2}\mathbf{b}^T\mathbf{B}^{-1}\mathbf{b} - \frac{1}{2}\log|\mathbf{B}| \right\} $$</p>
<p>Coefficient $c$ can now be reduced to the required form using the matrix transformations described in part a).</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Gaussian Distribution</tag>
        <tag>Distribution</tag>
        <tag>Probability</tag>
      </tags>
  </entry>
  <entry>
    <title>Computation involving iterated expectations and conditional probability</title>
    <url>/mml-exercise-6-11.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.11</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The expectation value and the conditional expectation value are given by</p>
<p>$$ \mathbb{E}_X[x] = \int x p(x) dx,\\ \mathbb{E}_Y[f(y)] = \int f(y) p(y) dy,\\ \mathbb{E}_X[x|y] = \int x p(x|y) dx $$</p>
<p>We then have</p>
<p>\begin{align*}\mathbb{E}_Y\left[\mathbb{E}_X[x|y]\right] =&amp;\ \int \mathbb{E}_X[x|y] p(y) dy = \int \left[\int xp(x|y)dx\right]p(y) dy \\=&amp;\ \int \int xp(x|y)p(y)dx dy = \int\int xp(x,y)dxdy\\ =&amp;\ \int x\left[\int p(x,y) dy\right] dx = \int x p(x) dx = \mathbb{E}_X[x], \end{align*}</p>
<p>where we used the definition fo the conditional probability density</p>
<p>$$ p(x|y)p(y) = p(x,y). $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Probability</tag>
        <tag>Expectation</tag>
        <tag>Random Variable</tag>
      </tags>
  </entry>
  <entry>
    <title>Manipulation of Gaussian Random Variables</title>
    <url>/mml-exercise-6-12.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.12</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>If $\mathbf{x}$ is fixed, then $\mathbf{y}$ has the same distribution as $\mathbf{w}$, but with the mean shifter by $\mathbf{A}\mathbf{x} + \mathbf{b}$, that is</p>
<p>$$ p(\mathbf{y}|\mathbf{x}) = \mathcal{N}(\mathbf{y}|\mathbf{A}\mathbf{x} + \mathbf{b}, \mathbf{Q}). $$</p>
<hr>
<p><strong>Part b</strong></p>
<p>Let us consider random variable $\mathbf{u} = \mathbf{A}\mathbf{x}$, it is distributed according to</p>
<p>$$ p(\mathbf{u}) = \mathcal{N}(\mathbf{u}|\mathbf{A}\mathbf{\mu}_x, \mathbf{A}\mathbf{\Sigma}_x\mathbf{A}^T). $$</p>
<p>Then $\mathbf{y}$ is a sum of two Gaussian random variables $\mathbf{u}$ and $\mathbf{w}$ with its mean additionally shifted by $\mathbf{b}$, that is</p>
<p>$$ p(\mathbf{y}) = \mathcal{N}(\mathbf{y}|\mathbf{A}\mathbf{\mu}_x + \mathbf{b}, \mathbf{A}\mathbf{\Sigma}_x\mathbf{A}^T + \mathbf{Q}), $$</p>
<p>that is</p>
<p>$$ \mathbf{\mu}_y = \mathbf{A}\mathbf{\mu}_x + \mathbf{b},\\ \mathbf{\Sigma}_y = \mathbf{A}\mathbf{\Sigma}_x\mathbf{A}^T + \mathbf{Q}. $$</p>
<hr>
<p><strong>Part c</strong></p>
<p>Like in b), assuming that $\mathbf{y}$ is fixed we obtain the conditional distribution</p>
<p>$$ p(\mathbf{z}|\mathbf{y}) = \mathcal{N}(\mathbf{z}|\mathbf{C}\mathbf{y}, \mathbf{R}) $$</p>
<p>Since $\mathbf{C}\mathbf{y}$ is a Gausssian random variable with distribution $\mathcal{N}(\mathbf{C}\mathbf{\mu}_y, \mathbf{C}\mathbf{\Sigma}_y\mathbf{C}^T)$ we obtain the distribution of $\mathbf{z}$ as that of a sum of two Gaussian random variables:</p>
<p>$$ p(\mathbf{z})= \mathcal{N}(\mathbf{z} |\mathbf{C}\mathbf{\mu}_y, \mathbf{C}\mathbf{\Sigma}_y\mathbf{C}^T + \mathbf{R})= \mathcal{N}(\mathbf{z} |\mathbf{C}(\mathbf{A}\mathbf{\mu}_x + \mathbf{b}), \mathbf{C}(\mathbf{A}\mathbf{\Sigma}_x\mathbf{A}^T + \mathbf{Q})\mathbf{C}^T + \mathbf{R}) $$</p>
<hr>
<p><strong>Part d</strong></p>
<p>The posterior distribution $p(\mathbf{x}|\mathbf{y})$ can be obtained by applying the Bayes’ theorem:</p>
<p>$$ p(\mathbf{x}|\mathbf{y})= \frac{p(\mathbf{y}|\mathbf{x})p(\mathbf{x})}{p(\mathbf{y})}= \frac{\mathcal{N}(\mathbf{y}|\mathbf{A}\mathbf{x} + \mathbf{b}, \mathbf{Q})\mathcal{N}(\mathbf{x}|\mathbf{\mu}_x,\mathbf{\Sigma}_x)} {\mathcal{N}(\mathbf{y}|\mathbf{A}\mathbf{\mu}_x + \mathbf{b}, \mathbf{A}\mathbf{\Sigma}_x\mathbf{A}^T + \mathbf{Q})}. $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Gaussian Distribution</tag>
        <tag>Distribution</tag>
        <tag>Probability</tag>
        <tag>Random Variable</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute marginal distributions and conditional distributions</title>
    <url>/mml-exercise-6-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.1</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>The marginal distributions are obtained by summing the probabilies over all the values of the variable being marginalized. Thus, to obtain $p(x)$ we sum over columns (i.e., over the values corresponding to different $y$):</p>
<p>\begin{align*}<br>p(x_1) &amp;= P(X = x_1) = P(X = x_1, Y = y_1) + P(X = x_1, Y = y_2) + P(X = x_1, Y = y_3)\\&amp; = 0.01 + 0.05 + 0.1 = 0.16<br>\end{align*} \begin{align*}<br>p(x_2) &amp;= P(X = x_2) = P(X = x_2, Y = y_1) + P(X = x_2, Y = y_2) + P(X = x_2, Y = y_3)\\&amp; = 0.02 + 0.1 + 0.05 = 0.17<br>\end{align*} \begin{align*}<br>p(x_3) &amp;= P(X = x_3) = P(X = x_3, Y = y_1) + P(X = x_3, Y = y_2) + P(X = x_3, Y = y_3)\\&amp; = 0.03 + 0.05 + 0.03 = 0.11<br>\end{align*} \begin{align*}<br>p(x_4) &amp;= P(X = x_4) = P(X = x_4, Y = y_1) + P(X = x_4, Y = y_2) + P(X = x_4, Y = y_3)\\&amp; = 0.1 + 0.07 + 0.05 = 0.22<br>\end{align*} \begin{align*}<br>p(x_5) &amp;= P(X = x_5) = P(X = x_5, Y = y_1) + P(X = x_5, Y = y_2) + P(X = x_5, Y = y_3)\\&amp; = 0.1 + 0.2 + 0.04 = 0.34<br>\end{align*} As a correctness check, note that this distribution satisfies the normalization condition, i.e. that sum of the probabilities is $1$:</p>
<p>$ \begin{equation} \sum_{i=1}^5 p(x_i) = 1 \end{equation} $</p>
<p>The marginal distribution $p(y)$ can be obtained in a similar way, by summing the matrix rows:</p>
<p>\begin{align*} p(y_1) &amp;= P(Y = y_1) = \sum_{i=1}^5 P(X = x_i, Y = y_1) = 0.01 + 0.02 + 0.03 + 0.1 + 0.1 = 0.26 \\ p(y_2) &amp;= P(Y = y_2) = \sum_{i=1}^5 P(X = x_i, Y = y_2) = 0.05 + 0.1 + 0.05 + 0.07 + 0.2 = 0.47 \\ p(y_3) &amp;= P(Y = y_3) = \sum_{i=1}^5 P(X = x_i, Y = y_3) = 0.1 + 0.05 + 0.03 + 0.05 + 0.04 = 0.27 \end{align*} We can again check that the normalization condition is satisfied: \begin{equation*} \sum_{i=1}^3p(y_i) = 1 \end{equation*}</p>
<hr>
<p><strong>Part b</strong></p>
<p>To determine conditional distributions we use the definition of the conditional probability:</p>
<p>$$ P(X = x , Y = y_1) = P(X = x | Y = y_1)P(Y = y_1) = p(x | Y = y_1) p(y_1). $$</p>
<p>Thus,</p>
<p>\begin{align*}<br>p(x_1 | Y = y_1) = \frac{P(X = x_1, Y = y_1)}{p(y_1)} = \frac{0.01}{0.26} \approx 0.038\\ p(x_2 | Y = y_1) = \frac{P(X = x_2, Y = y_1)}{p(y_1)} = \frac{0.02}{0.26} \approx 0.077\\ p(x_3 | Y = y_1) = \frac{P(X = x_3, Y = y_1)}{p(y_1)} = \frac{0.03}{0.26} \approx 0.115\\ p(x_4 | Y = y_1) = \frac{P(X = x_4, Y = y_1)}{p(y_1)} = \frac{0.1}{0.26} \approx 0.385\\ p(x_5 | Y = y_1) = \frac{P(X = x_5, Y = y_1)}{p(y_1)} = \frac{0.1}{0.26} \approx 0.385<br>\end{align*}</p>
<p>Likewise the conditional distribution $p(y | X = x_3)$ is given by</p>
<p>\begin{align*}<br>p(y_1 | X = y_3) = \frac{P(X = x_3, Y = y_1)}{p(x_3)} = \frac{0.03}{0.11} \approx 0.273\\ p(y_2 | X = y_3) = \frac{P(X = x_3, Y = y_2)}{p(x_3)} = \frac{0.05}{0.11} \approx 0.454\\ p(y_3 | X = y_3) = \frac{P(X = x_3, Y = y_3)}{p(x_3)} = \frac{0.03}{0.11} \approx 0.273<br>\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Random Variables</tag>
      </tags>
  </entry>
  <entry>
    <title>Computations ivolving a mixture of two Gaussian distributions</title>
    <url>/mml-exercise-6-2.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.2</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>We can write the probability density of the two-dimensional distribution as</p>
<p>$$ p(x,y)= 0.4\mathcal{N}\left(x, y|\begin{bmatrix} 10\\ 2\end{bmatrix}, \begin{bmatrix} 1&amp;0\\0&amp;1\end{bmatrix}\right)+ 0.6\mathcal{N}\left(x, y|\begin{bmatrix} 0\\ 0\end{bmatrix}, \begin{bmatrix} 8.4&amp;2.0\\2.0&amp;1.7\end{bmatrix}\right) $$</p>
<p>The marginal distribution of a weighted sum of distributions is given by the weighted sum of marginals, whereas the marginals of a bivariate normal distribution $\mathcal{N}(x,y|\mathbf{\mu},\mathbf{\Sigma})$ are obtained according to the rule</p>
<p>$$ \int \mathcal{N}(x,y|\mathbf{\mu},\mathbf{\Sigma})dy= \mathcal{N}(x|\mu_x, \Sigma_{xx}),$$  $$ \int \mathcal{N}(x,y|\mathbf{\mu},\mathbf{\Sigma})dx = \mathcal{N}(y|\mu_y, \Sigma_{yy}) $$</p>
<p>Thus, the marginals of the distribution of interest are</p>
<p>$$ p(x) = 0.4\mathcal{N}(x| 10, 1) + 0.6\mathcal{N}(x| 0, 8.4),$$ $$ p(y) = 0.4\mathcal{N}(x| 2, 1) + 0.6\mathcal{N}(x| 0, 1.7). $$</p>
<hr>
<p><strong>Part b</strong></p>
<p>The mean of a weighted sum of two distributions is the weighted sum of their averages</p>
<p>$$ \mathbb{E}_X[x] = 0.4*10 + 0.6*0 = 4,\\ \mathbb{E}_Y[y] = 0.4*2 + 0.6*0 = 0.8. $$</p>
<p>The mode of a continuous distribution is a point where this distribution has a peak. It can be determined by solving the extremum condition for each of the marginal distributions:</p>
<p>$$ \frac{dp(x)}{dx} = 0,\qquad \frac{dp(y)}{dy} = 0 $$</p>
<p>In the case of a mixture of normal distributions these equations are non-linear and can be solved only numerically. After finding all the solutions of these equations one has to verify for every solution that it is a peak rather than an inflection point, i.e. that at this point</p>
<p>$$ \frac{d^2p(x)}{dx^2} &lt; 0 \qquad \text{ or } \qquad \frac{d^2p(y)}{dy^2} &lt; 0 $$</p>
<p>The medians $m_x, m_y$ can be determined from the conditions</p>
<p>$$ \int_{-\infty}^{m}p(x)dx = \int^{+\infty}_{m}p(x)dx,$$ $$ \int_{-\infty}^{m}p(y)dy = \int^{+\infty}_{m}p(y)dy. $$</p>
<p>Again, these equations can be solved here only numerically.</p>
<hr>
<p><strong>Part c</strong></p>
<p>The mean of a two-dimensional distribution is a vector of means of the marginal distributions</p>
<p>$$ \mathbf{\mu} = \begin{bmatrix}4\\0.8\end{bmatrix}. $$</p>
<p>The mode of two dimensional distribution is obtained first by solving the extremum conditions</p>
<p>$$ \frac{\partial p(x,y)}{\partial x} = 0,\quad \frac{\partial p(x,y)}{\partial y} = 0. $$</p>
<p>and then verifying for every solution that it is indeed a peak, i.e.</p>
<p>$$ \frac{\partial^2 p(x,y)}{\partial x^2} &lt; 0,\quad \frac{\partial^2 p(x,y)}{\partial y^2} &lt; 0,$$ $$\det\left( \begin{bmatrix} \frac{\partial^2 p(x,y)}{\partial x^2} &amp; \frac{\partial^2 p(x,y)}{\partial x\partial y}\\ \frac{\partial^2 p(x,y)}{\partial x\partial y} &amp; \frac{\partial^2 p(x,y)}{\partial y^2} \end{bmatrix} \right) &gt; 0. $$</p>
<p>Again, these equations can be solved only numerically.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Gaussian Distribution</tag>
        <tag>Distribution</tag>
        <tag>Random Variables</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute the posterior distribution of a Bernoulli distribution</title>
    <url>/mml-exercise-6-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.3</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The conjugate prior to the Bernoulli distribution is the Beta distribution</p>
<p>$$ p(\mu | \alpha, \beta) =\frac{1}{\mathcal{B}(\alpha, \beta)} \mu^{\alpha -1}(1-\mu)^{\beta-1} \propto \mu^{\alpha -1}(1-\mu)^{\beta-1}, $$</p>
<p>where $\alpha,\beta$ are not necessarily integers and the normalization coefficient si the Beta function defined as</p>
<p>$$ \mathcal{B}(\alpha, \beta) = \int_0^1 t^{\alpha -1}(1-t)^{\beta-1}dt $$</p>
<p>The likelihood of observing data $\{x_1, x_2, …, x_N\}$ is</p>
<p>$$p(x_1, …, x_N|\mu) = \prod_{i=1}^Np(x_i|\mu) = \prod_{i=1}^N \mu^{x_i}(1-\mu)^{1-x_i} = \mu^{\sum_{i=1}^N x_i}(1-\mu)^{N-\sum_{i=1}^N x_i} $$</p>
<p>The posterior distribution is proportional to teh rpoduct of this likelihood with teh prior distribution (Bayes theorem):</p>
<p>$$ p(\mu |x_1, …, x_N) \propto p(x_1, …, x_N|\mu)p(\mu | \alpha, \beta) \propto \mu^{\sum_{i=1}^N x_i + \alpha -1}(1-\mu)^{N-\sum_{i=1}^N x_i +\beta -1} $$</p>
<p>This is also a Beta distribution, i.e. our choice of the gonjugate prior was correct. The normalization constant is readily determined:</p>
<p>$$ p(\mu |x_1, …, x_N) = \frac{1}{\mathcal{B}(\sum_{i=1}^N x_i + \alpha -1, N-\sum_{i=1}^N x_i +\beta -1)} \mu^{\sum_{i=1}^N x_i + \alpha -1}(1-\mu)^{N-\sum_{i=1}^N x_i +\beta -1} $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Random Variables</tag>
        <tag>Bernoulli Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>An application of Bayes’ theorem</title>
    <url>/mml-exercise-6-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.4</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The probabilities of picking a mango or an apple from teh first bag are given by</p>
<p>$$ p(mango |1) = \frac{4}{6} = \frac{2}{3}\\ p(apple |1) = \frac{2}{6} = \frac{1}{3} $$</p>
<p>The probabilities of picking a mango or an apple from teh second bag are </p>
<p>$$ p(mango |2) = \frac{4}{8} = \frac{1}{2}\\ p(apple |2) = \frac{4}{8} = \frac{1}{2} $$</p>
<p>The probability of picking the first or the second bag are equal to teh probabilities of head and tail respectively:</p>
<p>$$ p(1) = 0.6,\qquad p(2) = 0.4 $$</p>
<p>We now can obtain the probability that the mango was picked from the second bag using Bayes’ theorem:</p>
<p>$$ p(2 | mango) = \frac{p(mango | 2)p(2)}{p(mango)} = \frac{p(mango | 2)p(2)}{p(mango | 1)p(1) + p(mango | 2)p(2)} = \frac{\frac{1}{2}0.4}{\frac{2}{3}0.6 + \frac{1}{2}0.4} = \frac{1}{3} $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Probability</tag>
        <tag>Bayes’ Theorem</tag>
      </tags>
  </entry>
  <entry>
    <title>A time series model and Gaussian noise variable</title>
    <url>/mml-exercise-6-5.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.5</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>$\mathbf{x}_{t+1}$ is obtained from $\mathbf{x}_{t}$ by a linear transformation, $\mathbf{A}\mathbf{x}_{t}$ and adding a Gaussian random variabme $\mathbf{w}$. Initial distribution for $\mathbf{x}_{0}$ is a Gaussian distribution, a linear transformation of a Gaussian random variable is also a Gaussian random variable, whareas a sum of Gaussian random variables is a Gaussian random variable. Thus, the joint distribution $p(\mathbf{x}_{0}, \mathbf{x}_{1},…,\mathbf{x}_{T})$ is also a Gaussian distribution.</p>
<hr>
<p><strong>Part b (1)</strong></p>
<p>Let $\mathbf{z} = \mathbf{A}\mathbf{x}_{t+1}$. Since this is a linear transformation of a Gaussian random variable, $\mathbf{x}_t \sim \mathcal{N}(\mathbf{\mu}_t,\mathbf{\Sigma})$, then $\mathbf{z}$ is distributed as (see Eq. (6.88))</p>
<p>$$ \mathbf{z} \sim \mathcal{N}(\mathbf{A}\mathbf{\mu}_t, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T), $$</p>
<p>whereas the mean and the covariance of a sum of two Gaussian random variables are given by the sum of the means and the covariances of these variables, i.e.,</p>
<p>$$ \mathbf{x}_{t+1} = \mathbf{z} + \mathbf{w} \sim \mathcal{N}(\mathbf{A}\mathbf{\mu}_t, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q}), $$</p>
<p>That is</p>
<p>$$ p(\mathbf{x}_{t+1}|\mathbf{y}_1,…,\mathbf{y}_t)= \mathcal{N}(\mathbf{x}_{t+1}|\mathbf{A}\mathbf{\mu}_t, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q}). $$</p>
<hr>
<p><strong>Part b (2)</strong></p>
<p>If we assume that $\mathbf{x}_{t+1}$ is fixed, then $\mathbf{y}_{t+1} = \mathbf{C}\mathbf{x}_{t+1} + \mathbf{v}$ follows the same distribution as $\mathbf{v}$, but with the mean shifted by $\mathbf{C}\mathbf{x}_{t+1}$, i.e.</p>
<p>$$ p(\mathbf{y}_{t+1}|\mathbf{x}_{t+1}, \mathbf{y}_1,…,\mathbf{y}_t)= \mathcal{N}(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{x}_{t+1}, \mathbf{R}). $$</p>
<p>The the joint probability is obtained as</p>
<p>\begin{align*} p(\mathbf{y}_{t+1}, \mathbf{x}_{t+1}| \mathbf{y}_1,…,\mathbf{y}_t)=&amp;\ p(\mathbf{y}_{t+1}|\mathbf{x}_{t+1}, \mathbf{y}_1,…,\mathbf{y}_t) p(\mathbf{x}_{t+1}| \mathbf{y}_1,…,\mathbf{y}_t)\\=&amp;\ \mathcal{N}(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{x}_{t+1}, \mathbf{R}) \mathcal{N}(\mathbf{x}_{t+1}|\mathbf{A}\mathbf{\mu}_t, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q}). \end{align*}</p>
<p><strong>Part b (3)</strong></p>
<p>Let us introduce temporary notation</p>
<p>$$ \mathbf{\mu}_{t+1} = \mathbf{A}\mathbf{\mu}_t,$$ </p>
<p>$$ \mathbf{\Sigma}_{t+1} = \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q},$$</p>
<p>$$p(\mathbf{x}_{t+1}|\mathbf{y}_1,…,\mathbf{y}_t) = \mathcal{N}(\mathbf{\mu}_{t+1}, \mathbf{\Sigma}_{t+1}). $$</p>
<p>Then $\mathbf{y}_{t+1}$ is obtained in terms of the parameters of distribution $p(\mathbf{x}_{t+1}|\mathbf{y}_1,…,\mathbf{y}_t)$ following the same steps as question 1), with the result</p>
<p>$$ p(\mathbf{y}_{t+1}|\mathbf{y}_1,…,\mathbf{y}_t)= \mathcal{N}(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{\mu}_{t+1}, \mathbf{C}\mathbf{\Sigma}_{t+1}\mathbf{C}^T + \mathbf{R})= \mathcal{N}\left(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{A}\mathbf{\mu}_t, \mathbf{C}(\mathbf{A}\mathbf{\Sigma}\mathbf{A}^T+ \mathbf{Q})\mathbf{C}^T + \mathbf{R}\right). $$</p>
<p>The required conditional distribution is then obtained as</p>
<p>$$ p(\mathbf{x}_{t+1}|\mathbf{y}_1,…,\mathbf{y}_t, \mathbf{y}_{t+1})= \frac{p(\mathbf{y}_{t+1}, \mathbf{x}_{t+1}| \mathbf{y}_1,…,\mathbf{y}_t)} {p(\mathbf{y}_{t+1}| \mathbf{y}_1,…,\mathbf{y}_t)}= \frac{\mathcal{N}(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{x}_{t+1}, \mathbf{R}) \mathcal{N}(\mathbf{x}_{t+1}|\mathbf{A}\mathbf{\mu}_t, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q})} {\mathcal{N}\left(\mathbf{y}_{t+1}|\mathbf{C}\mathbf{A}\mathbf{\mu}_t, \mathbf{C}(\mathbf{A}\mathbf{\Sigma}\mathbf{A}^T + \mathbf{Q})\mathbf{C}^T + \mathbf{R}\right)}. $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Probability</tag>
        <tag>Random Variable</tag>
        <tag>Time Series</tag>
      </tags>
  </entry>
  <entry>
    <title>Express variance using expectation in a different form</title>
    <url>/mml-exercise-6-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.6</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The standard definition of variance is</p>
<p>$$ \mathbb{V}_X[x] = \mathbb{E}_X[(x-\mu)^2], $$</p>
<p>where</p>
<p>$$ \mu = \mathbb{E}_X[x]. $$</p>
<p>Using the properties of average we can write:</p>
<p>\begin{align*}<br>\mathbb{V}_X[x] = &amp;\ \mathbb{E}_X[(x-\mu)^2] = \mathbb{E}_X[x^2 - 2x\mu +\mu^2] \\ =&amp;\ \mathbb{E}_X[x^2] - \mathbb{E}_X[2x\mu] + \mathbb{E}_X[\mu^2]\\=&amp;\ \mathbb{E}_X[x^2] - 2\mu\mathbb{E}_X[x] + \mu^2\\ =&amp;\ \mathbb{E}_X[x^2] - 2\mu^2 + \mu^2 = \mathbb{E}_X[x^2] - \mu^2.<br>\end{align*}</p>
<p>By substituting to this equation the definition of $\mu$, we obtain the desired equation</p>
<p>$$ \mathbb{V}_X[x] = \mathbb{E}_X[(x-\mu)^2] = \mathbb{E}_X[x^2] - (\mathbb{E}_X[x])^2. $$</p>
<div class="note default flat"><p>In particular, it shows that the variance is always nonnegative. Moreover, $$ \mathbb{E}_X[x^2] \geqslant (\mathbb{E}_X[x])^2. $$</p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Probability</tag>
        <tag>Expectation</tag>
        <tag>Variance</tag>
      </tags>
  </entry>
  <entry>
    <title>An identity that can be used to show Cauchy-Schwarz inequality</title>
    <url>/mml-exercise-6-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.7</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Let us expand the square in the left-hand side of (6.45)</p>
<p>$$ \frac{1}{N^2}\sum_{i,j=1}^N(x_i - x_j)^2 = \frac{1}{N^2}\sum_{i,j=1}^N(x_i^2 - 2x_i x_j + x_j^2) = \frac{1}{N^2}\sum_{i,j=1}^N x_i^2 - 2\frac{1}{N^2}\sum_{i,j=1}^N x_i x_j + \frac{1}{N^2}\sum_{i,j=1}^Nx_j^2 $$</p>
<p>We see that the first and the last term differ only by the summation index, i.e. they are identical: $$ \frac{1}{N^2}\sum_{i,j=1}^N x_i^2 + \frac{1}{N^2}\sum_{i,j=1}^Nx_j^2= 2\frac{1}{N^2}\sum_{i,j=1}^N x_i^2 = 2\frac{1}{N}\sum_{i=1}^N x_i^2, $$</p>
<p>since summation over $j$ gives factor $N$.</p>
<p>The remaining term can be written as</p>
<p>$$ 2\frac{1}{N^2}\sum_{i,j=1}^N x_i x_j = 2\frac{1}{N^2}\sum_{i=1}^N x_i \sum_{i=1}^N x_j = 2\left(\frac{1}{N}\sum_{i=1}^N x_i\right)^2, $$</p>
<p>where we again used the fact that the sum is invariant to the index of summation.</p>
<p>We thus have proved the required relation that</p>
<p>$$ \frac{1}{N^2}\sum_{i,j=1}^N(x_i - x_j)^2 = 2\frac{1}{N}\sum_{i=1}^N x_i^2 - 2\left(\frac{1}{N}\sum_{i=1}^N x_i\right)^2 $$</p>
<div class="note default flat"><p>In particular, it shows that $$\frac{1}{N}\sum_{i=1}^N x_i^2 \geq  \left(\frac{1}{N}\sum_{i=1}^N x_i\right)^2$$</p>
</div>

<div class="note info flat"><p>A more general identity is the following,</p>
<p>$$<br>\Big(\sum_{i=1}^n a_i^2\Big)\Big(\sum_{i=1}^n b_i^2\Big)- \Big(\sum_{i=1}^n a_ib_i\Big)^2=\frac{1}{2}\sum_{i,j=1}^n (a_ib_j-a_jb_i)^2.<br>$$</p>
</div>

<p>This one can be proved in the same way. Moreover, this identity shows the classical Cauchy-Schwarz ineqaulity,</p>
<p>$$<br>\Big(\sum_{i=1}^n a_i^2\Big)\Big(\sum_{i=1}^n b_i^2\Big)\geq\Big(\sum_{i=1}^n a_ib_i\Big)^2.<br>$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Basic Identity</tag>
        <tag>Cauchy-Schwarz Inequality</tag>
      </tags>
  </entry>
  <entry>
    <title>Probability Integral Transformation and uniform distribution</title>
    <url>/mml-exercise-6-13.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.13</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Cdf is related to pdf as</p>
<p>$$ F_x(x) = \int_{-\infty}^xdx’ f_x(x’),\quad \frac{d}{dx} F_x(x) = f_x(x), $$</p>
<p>and changes in the interval $[0,1]$.</p>
<p>The pdf of variable $y=F_x(x)$ then can be defined as</p>
<p>$$ f_y(y) = f_x(x) \left|\frac{dx}{dy}\right| = \frac{f_x(x)}{\left|\frac{dy}{dx}\right|} = \frac{f_x(x)}{\left|\frac{dF_x(x)}{dx}\right|} = \frac{f_x(x)}{f_x(x)} = 1, $$</p>
<p>i.e. $y$ is uniformly distributed in interval $[0,1]$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Probability</tag>
        <tag>Random Variable</tag>
        <tag>Uniform Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>Express the Bernoulli distribution in the natural parameter form of the exponential family</title>
    <url>/mml-exercise-6-8.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.8</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>Bernoulli distribution is given by</p>
<p>$$ p(x|\mu) = \mu^x (1-\mu)^{1-x}. $$</p>
<p>We can use relation</p>
<p>$$ a^x = e^{x\log a} $$</p>
<p>to write the Bernoulli distribution as</p>
<p>$$ p(x|\mu) = e^{x\log\mu + (1-x)\log(1-\mu)}= e^{x\log\left(\frac{\mu}{1-\mu}\right) + \log(1-\mu)} = h(x)e^{\theta x - A(\theta)}, $$</p>
<p>where the last equation is the definition of a single-parameter distribution from the exponential family, in which</p>
<p>$$ h(x) = 1,\\ \theta = \log\left(\frac{\mu}{1-\mu}\right)$$ $$\leftrightarrow \mu = \frac{e^\theta}{1+e^\theta},\\ A(\theta) = -\log(1-\mu) = \log(1+e^\theta). $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Probability</tag>
        <tag>Bernoulli Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>Express the Binomial and Beta distributions as an exponential family distribution</title>
    <url>/mml-exercise-6-9.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 6 Exercise 6.9</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The binomial distribution can be transformed as</p>
<p>\begin{align*} p(x|N,\mu) =&amp;\ {N\choose x} \mu^x (1-\mu)^{N-x} = {N \choose x} e^{x\log\mu + (N-x)\log(1-\mu)}\\ =&amp;\ {N \choose x}e^{x\log\left(\frac{\mu}{1-\mu}\right) +N\log(1-\mu)} = h(x)e^{x\theta - A(\theta)}<br>\end{align*}</p>
<p>where</p>
<p>$$ h(x) = {N \choose x},\\ \theta = \log\left(\frac{\mu}{1-\mu}\right),$$ </p>
<p>$$ A(\theta) = -N\log(1-\mu) = N\log(1+e^\theta), $$</p>
<p>i.e., the binomial distribution can be represented as an exponential family distribution (only $\mu$ is treated here as a parameter, since the number of trials $N$ is fixed.)</p>
<p>Similarly, the beta distribution can be transoformed as</p>
<p>\begin{align*} p(x |\alpha, \beta) = &amp;\ \frac{1}{\mathcal{B}(\alpha,\beta)} x^{\alpha-1}(1-x)^{\beta-1} \\=&amp;\ e^{(\alpha -1)\log x + (\beta -1)\log(1-x) - \log(\mathcal{B}(\alpha,\beta))}\\ =&amp;\ h(x)e^{\theta_1\phi_1(x) + \theta_2\phi_2(x) -A(\theta_1, \theta_2)}<br>\end{align*}</p>
<p>where</p>
<p>$$ h(x) = 1,\\ \theta_1 = \alpha-1, \theta_2 = \beta-1,$$ $$\phi_1(x) = \log x, \phi_2(x) = \log(1-x),$$ $$A(\theta_1, \theta_2) = \log(\mathcal{B}(\alpha,\beta)) = \log(\mathcal{B}(1+\theta_1,1 + \theta_2)) $$</p>
<p>i.e. this is a distribution form the exponential family.</p>
<p>The product of the two distributions is then given by</p>
<p>\begin{align*} p(x|N,\mu) p(x|\alpha, \beta)=&amp;\ {N \choose x}e^{x\log\left(\frac{\mu}{1-\mu}\right) + (\alpha-1)\log x + (\beta -1)\log(1-x) + N\log(1-\mu) - \log(\mathcal{B}(\alpha,\beta))}\\ =&amp;\ h(x) e^{\theta_1 \phi_1(x) + \theta_2 \phi_2(x) + \theta_3\phi_3(x) - A(\theta_1, \theta_2, \theta_3)},<br>\end{align*}</p>
<p>where</p>
<p>$$ h(x) = {N \choose x},\qquad \theta_1 = \alpha-1, \theta_2 = \beta-1,\theta_3 = \log\left(\frac{\mu}{1-\mu}\right)$$</p>
<p>$$ \phi_1(x) = \log x, \phi_2(x) = \log(1-x), $$</p>
<p>$$\phi_3(x) = x\\ A(\theta_1, \theta_2, \theta_3) = \log(\mathcal{B}(\alpha,\beta)) -N\log(1-\mu) = \log(\mathcal{B}(1+\theta_1,1 + \theta_2)) + N\log(1+e^\theta_3). $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Statistics";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "a1702ca86c77f1a4b0df1c05cdf77dce";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Statistics</category>
      </categories>
      <tags>
        <tag>Distribution</tag>
        <tag>Probability</tag>
        <tag>Bernoulli Distribution</tag>
        <tag>Beta Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>Find stationary points and determine their types</title>
    <url>/mml-exercise-7-1.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 7 Exercise 7.1</strong></p>
</div>

<a id="more"></a>

<p>Solution: First, we compute the derivative of $f(x)$, $$f’(x)=3x^2+12x-3=3(x^2+4x-1).$$Its stationary points (also known as <em>critical points</em>) are the zeros of derivative. Hence by quadratic formula, we see that the stationary points are $$x_1=-2+\sqrt{5},\quad x_2=-2-\sqrt{5}.$$To determine the local extreme values, we have find the signs of the derivative on some intervals. Since we know that the graph of the derivative is an open-upward parabola with $x$-intercepts $-2\pm \sqrt 5$, it is clear that the function $f’(x)$ is positive on $(-\infty,-2-\sqrt 5)$ and $(-2+\sqrt 5,\infty)$ and negative on $(-2-\sqrt 5,-2+\sqrt 5)$. Below is the graph of the derivative.</p>
<p><img src="https://cdn.jsdelivr.net/gh/MathPage/gitalk/img/mml7-1-1-1.gif" alt="Solution to Mathematics for Machine Learning Exercise 7.1"></p>
<p>Hence by the first derivative test, we see that the original function has local maximum at $x_2=-2-\sqrt{5}$ and local minimum at $x=-2+\sqrt{5}$. There is no global maximum or global minimum since $f(-\infty)=-\infty$ and $f(\infty)=\infty$. Here is the graph of the original function.</p>
<p><img src="https://cdn.jsdelivr.net/gh/MathPage/gitalk/img/mml7-1-2-1.gif" alt="Solution to Mathematics for Machine Learning Exercise 7.1"></p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Calculus";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "f4d7cee51e59d583948f31cc8ab6b79a";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Function</tag>
        <tag>Extreme Value</tag>
        <tag>Calculus</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of operations on convex sets</title>
    <url>/mml-exercise-7-3.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 7 Exercise 7.3</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>Solution: True. Let $\mathcal C_1$ and $\mathcal C_2$ be two convex sets. We would like to show that $\mathcal C_1\cap \mathcal C_2$ is convex.</p>
<p>If $\mathcal C_1\cap \mathcal C_2$ is empty then we are done. Suppose $\mathcal C_1\cap \mathcal C_2$ is nonempty. By definition 7.2, we would like to show that for any $x, y\in \mathcal C_1\cap \mathcal C_2$, we have $$\theta x +(1-\theta)y\in \mathcal C_1\cap \mathcal C_2$$for all $\theta\in [0,1]$.</p>
<p>Since $x, y\in \mathcal C_1\cap \mathcal C_2$, we have $x, y\in \mathcal C_1$. By definition 7.2 we have \begin{equation}\label{mml7.3.1}\theta x +(1-\theta)y\in \mathcal C_1\end{equation}for all $\theta\in [0,1]$. Similarly, we have \begin{equation}\label{mml7.3.2}\theta x +(1-\theta)y\in \mathcal C_2\end{equation}for all $\theta\in [0,1]$. Therefore, combining \eqref{mml7.3.1} and \eqref{mml7.3.2}, we have$$\theta x +(1-\theta)y\in \mathcal C_1\cap \mathcal C_2$$for all $\theta\in [0,1]$. Hence the statement is true.</p>
<p>Remark: The intersection of any convex sets (not necessarily finitely many) is convex.</p>
<hr>
<p><strong>Part b</strong></p>
<p>Solution: False. Definition 7.2 can be restated as follows: A set is convex if and only if the segment connecting any two points in this set is again contained in this set. Here is a counterexample. Take two disks which are non-intersecting. Clearly, a disk is convex. But they are union is not. Because the blue segment is not contained in the union of the two disks.</p>
<p><img src="https://cdn.jsdelivr.net/gh/MathPage/gitalk/img/IMG_355652056C03-1.jpeg" alt="Solution to Mathematics for Machine Learning Exercise 7.3"></p>
<hr>
<p><strong>Part c</strong></p>
<p>Solution: False. Take a big disk and removing a smaller disk inside of it. See the picture below. Then the new set shaded in green color is not convex because the purple segment is not contained in the new set.</p>
<p><img src="https://cdn.jsdelivr.net/gh/MathPage/gitalk/img/IMG_52CBCB79387F-1.jpeg" alt="Solution to Mathematics for Machine Learning Exercise 7.3"></p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Calculus";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "f4d7cee51e59d583948f31cc8ab6b79a";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Convex Set</tag>
        <tag>Intersection</tag>
        <tag>Union</tag>
        <tag>Difference</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of operations on convex functions</title>
    <url>/mml-exercise-7-4.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 7 Exercise 7.4</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p><strong>Part a</strong></p>
<p>Solution: True. Let $f_1(\mathbf x)$ and $f_2(\mathbf x)$ be two convex functions. Suppose their domains are $\mathcal C_1$ and $\mathcal C_2$, respectively. Then $\mathcal C_1$ and $\mathcal C_2$ are convex sets, by Definition 7.3. Hence by Exercise 7.3 (a), the intersection $\mathcal C_1\cap \mathcal C_2$ is also convex. Note that $\mathcal C_1\cap \mathcal C_2$ is also the domain of $f_1+f_2$. Hence the domain of $f_1+f_2$ is convex. Now we only need to check the condition (7.30) in the textbook.</p>
<p>For any $\mathbf x,\mathbf y$ in $\mathcal C_1\cap \mathcal C_2$ and $0\leq \theta \leq 1$, we have\begin{align*}&amp;\ (f_1+f_2)(\theta \mathbf x+(1-\theta)\mathbf y) \\ = &amp;\ f_1((\theta \mathbf x+(1-\theta)\mathbf y))+f_2((\theta \mathbf x+(1-\theta)\mathbf y))\\ \leq &amp;\ \theta f_1(\mathbf x)+(1-\theta)f_1(\mathbf y) +\theta f_2(\mathbf x)+(1-\theta)f_2(\mathbf y)\\ = &amp;\ \theta f_1(\mathbf x) +\theta f_2(\mathbf x)+(1-\theta)f_1(\mathbf y) +(1-\theta)f_2(\mathbf y)\\ = &amp;\ \theta (f_1+f_2)(\mathbf x)+(1-\theta)(f_1+f_2)(\mathbf y).\end{align*}In the inequality, we used equation (7.30) for $f_1$ and $f_2$ as they are convex. Therefore, $f_1+f_2$ is also convex.</p>
<hr>
<p><strong>Part b</strong></p>
<p>I will use the following well-known fact.</p>
<div class="note info flat"><p>If $f’’(x)\geq 0$ holds for all $x$ in the domain (assumed to be convex) of $f$, then $f(x)$ is convex.</p>
</div>

<p>Solution: False. For example, let $f_1(x)=x^2$ and $f_2(x)=2x^2$. Then $f_1$ and $f_2(x)$ are convex, but $$(f_1-f_2)(x)=f_1(x)-f_2(x)=-x^2$$ is not convex. Please fill the details.</p>
<hr>
<p><strong>Part c</strong></p>
<p>Solution: False. Let $f_1(x)=x^2$ and $f_2(x)=x$. Then $f_1$ and $f_2(x)$ are convex, but $$(f_1f_2)(x)=f_1(x)f_2(x)=-x^3$$ is not convex. Please fill the details, e.g. use $\theta=1/2$, $x=-1$ and $y=0$ to get a counterexample.</p>
<hr>
<p><strong>Part d</strong></p>
<p>Solution: True. Let $f_1(\mathbf x)$ and $f_2(\mathbf x)$ be two convex functions. Let $f(x):=\max\{f_1(x),f_2(x)\}$ be the maximum of them. Suppose their domains are $\mathcal C_1$ and $\mathcal C_2$, respectively. Then $\mathcal C_1$ and $\mathcal C_2$ are convex sets, by Definition 7.3. Hence by Exercise 7.3 (a), the intersection $\mathcal C_1\cap \mathcal C_2$ is also convex. Note that $\mathcal C_1\cap \mathcal C_2$ is also the domain of $f(x)$. Hence the domain of $f(x)$ is convex. Now we only need to check the condition (7.30) in the textbook.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Calculus";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "f4d7cee51e59d583948f31cc8ab6b79a";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Intersection</tag>
        <tag>Union</tag>
        <tag>Difference</tag>
        <tag>Convex Function</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis of the intersection of two vector spaces</title>
    <url>/mml-exercise-2-12.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 2 Exercise 2.12</strong></p>
</div>

<a id="more"></a>

<p>Solution:</p>
<p>We write the given vectors as $v_1, \dots v_6$ from left to right. Firstly, observe that $\dim(U_1)=2$ and $\dim(U_2)=2$ (compute the rank of $\left[v_1|v_2|v_3\right]$, then $\left[v_4|v_5|v_6\right]$). Since we can write $$v_3= \frac13 (v_1-2v_2)\quad\text{and}\quad v_6=-v_4-2v_5,$$ we need not consider $v_3$ and $v_6$ any further.</p>
<p>Now, if we find the rank of $\left[v_1|v_2|v_4|v_5\right]$, we get 3, so $\dim(U_1+U_2)=3$. Therefore, $$\dim(U_1\cap U_2) = 2+2-3=1.$$ Hence, to find a basis of $U_1 \cap U_2$, we need only find any non-zero vector in the space.</p>
<p>Let $0\neq v \in U_1\cap U_2$. Then we can write $v=\alpha_1v_1 + \alpha_2v_2$, and $v=\alpha_4v_4 + \alpha_5v_5$. Subtracting these equations, we have $$0=\alpha_1v_1 + \alpha_2v_2 -\alpha_4v_4 - \alpha_5v_5.$$ Remember we want a non-zero solution for $v$, and observe that the rank of $\left[v_1|v_2|v_4\right]$ is 3 (i.e. these three vectors are linearly independent). Hence we can take $\alpha_5=9$, say (this means we don’t have fractions later, but there’s no way to know this a priori!), and solve for the other $\alpha_i$’s. Using Gaussian elimination, we obtain $\alpha_1=4$, $\alpha_2=10$ and $\alpha_4 = -6$. Thus $$\begin{equation*} v=4v_1+10v_2 = -6v_4+9v_5 = \begin{bmatrix} 24\\-6\\-12\\-6 \end{bmatrix}. \end{equation*}$$</p>
<p>Finally, we can write our basis of $U_1\cap U_2$ as just $\{ v \}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>Derive the dual linear program using Lagrange duality</title>
    <url>/mml-exercise-7-6.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 7 Exercise 7.6</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>We use (7.43) on Page 239 directly. Note that in this case, see (7.39), we have $$\boldsymbol  c=-\left[\begin{array}{l}<br>5 \\<br>3<br>\end{array}\right],\quad \boldsymbol b=\left[\begin{array}{c}<br>33 \\<br>8 \\<br>5 \\<br>-1 \\<br>8<br>\end{array}\right],$$ $$\boldsymbol A=\left[\begin{array}{cc}<br>2 &amp; 2 \\<br>2 &amp; -4 \\<br>-2 &amp; 1 \\<br>0 &amp; -1 \\<br>0 &amp; 1<br>\end{array}\right].$$By (7.43), the dual linear program is $$<br>\max _{\boldsymbol{\lambda} \in \mathbb{R}^{5}}\quad -\left[\begin{array}{c}<br>33 \\<br>8 \\<br>5 \\<br>-1 \\<br>8<br>\end{array}\right]^{\top}\left[\begin{array}{c}<br>\lambda_{1} \\<br>\lambda_{2} \\<br>\lambda_{3} \\<br>\lambda_{4} \\<br>\lambda_{5}<br>\end{array}\right]<br>$$ $$<br>\text { subject to } \quad -\left[\begin{array}{l}<br>5 \\<br>3<br>\end{array}\right]+\left[\begin{array}{cc}<br>2 &amp; 2 \\<br>2 &amp; -4 \\<br>-2 &amp; 1 \\<br>0 &amp; -1 \\<br>0 &amp; 1<br>\end{array}\right]^\top \left[\begin{array}{c}<br>\lambda_{1} \\<br>\lambda_{2} \\<br>\lambda_{3} \\<br>\lambda_{4} \\<br>\lambda_{5}<br>\end{array}\right]=0<br>$$ $$\left[\begin{array}{c}<br>\lambda_{1} \\<br>\lambda_{2} \\<br>\lambda_{3} \\<br>\lambda_{4} \\<br>\lambda_{5}<br>\end{array}\right]\geqslant 0.$$</p>
<hr>
<div class="note info flat"><p>If you are interested in more detail, see below.</p>
</div>

<p>Let us define $\mathbf{c} = (-5, -3)^T$, $\mathbf{b} = (33, 8, 5, -1, 8)^T$ and</p>
<p>$$ \mathbf{A}= \begin{bmatrix} 2 &amp; 2\\ 2 &amp; -4\\-2 &amp; 1\\ 0 &amp; -1\\ 0 &amp; 1 \end{bmatrix} $$</p>
<p>The linear program is then written as</p>
<p>$$ \min_{\mathbf{x} \in \mathbb{R}^2} \mathbf{c}^T\mathbf{x}$$ $$\text{subject to } \mathbf{A}\mathbf{x} \leq \mathbf{b} $$</p>
<p>The Lagrangian of this problem is</p>
<p>$$ \mathcal{L}(\mathbf{x},\mathbf{\lambda}) = \mathbf{c}^T\mathbf{x} + \mathbf{\lambda}^T(\mathbf{A}\mathbf{x} - \mathbf{b})= (\mathbf{c}^T\mathbf{x} + \mathbf{\lambda}^T\mathbf{A})\mathbf{x} - \mathbf{\lambda}^T\mathbf{b}= (\mathbf{c}\mathbf{x} + \mathbf{A}^T\mathbf{\lambda})^T\mathbf{x} - \mathbf{\lambda}^T\mathbf{b} $$</p>
<p>Taking gradient in respect to $\mathbf{x}$ and setting it to zero we obtain the extremum condition</p>
<p>$$ \mathbf{c}\mathbf{x} + \mathbf{A}^T\mathbf{\lambda} = 0, $$</p>
<p>that is</p>
<p>$$ \mathcal{D}(\mathbf{\lambda}) = \min_{\mathbf{x} \in \mathbb{R}^2} \mathcal{L}(\mathbf{x},\mathbf{\lambda}) = - \mathbf{\lambda}^T\mathbf{b} $$</p>
<p>that is the dual problem is given by</p>
<p>$$ \max_{\mathbf{\lambda} \in \mathbb{R}^5} - \mathbf{b}^T\mathbf{\lambda}$$ $$\text{subject to } \mathbf{c}\mathbf{x} + \mathbf{A}^T\mathbf{\lambda} = 0$$ $$\text{ and } \mathbf{\lambda} \geq 0 $$</p>
<p>In terms of the original values of the parameters it can be thus written as</p>
<p>$$ \max_{\mathbf{\lambda} \in \mathbb{R}^5} - \begin{bmatrix} 33 \\ 8 \\ 5 \\ -1 \\ 8 \end{bmatrix}^T \begin{bmatrix} \lambda_1 \\ \lambda_2 \\ \lambda_3 \\ \lambda_4 \\ \lambda_5 \end{bmatrix}$$ $$\text{subject to } - \begin{bmatrix} 5 \\ 3 \end{bmatrix}+ \begin{bmatrix} 2 &amp; 2 &amp; -2 &amp; 0 &amp; 0\\ 2 &amp; -4 &amp; 1 &amp; -1 &amp; 1 \end{bmatrix} \begin{bmatrix} \lambda_1 \\ \lambda_2 \\ \lambda_3 \\ \lambda_4 \\ \lambda_5 \end{bmatrix} = 0$$ $$\text{and } \begin{bmatrix} \lambda_1 \\ \lambda_2 \\ \lambda_3 \\ \lambda_4 \\ \lambda_5 \end{bmatrix} \geq 0 $$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Calculus";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "f4d7cee51e59d583948f31cc8ab6b79a";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
        <tag>Lagrange Duality</tag>
        <tag>Linear Program</tag>
      </tags>
  </entry>
  <entry>
    <title>Derive the dual linear program using Lagrange duality II</title>
    <url>/mml-exercise-7-7.html</url>
    <content><![CDATA[<div class="note info flat"><p><strong><a href="/mml-solution-manual.html">Solution to Mathematics for Machine learning</a> Chapter 7 Exercise 7.7</strong></p>
</div>

<a id="more"></a>

<p>Solution: </p>
<p>The process is already in Chapter 7.3.2. I will give the answer directly from (7.52) on page 242.</p>
<p>The dual quadratic program is $$<br>\min _{\boldsymbol{\lambda} \in \mathbb{R}^{4}}\ -\frac{1}{14}\left(\left[\begin{array}{l}<br>5 \\<br>3<br>\end{array}\right]+\left[\begin{array}{cc}<br>1 &amp; 0 \\<br>-1 &amp; 0 \\<br>0 &amp; 1 \\<br>0 &amp; -1<br>\end{array}\right]^\top\left[\begin{array}{c}<br>\lambda_1 \\<br>\lambda_2 \\<br>\lambda_3 \\<br>\lambda_4<br>\end{array}\right]\right)^\top\left[\begin{array}{ll}<br>4 &amp; -1 \\<br>-1 &amp; 2<br>\end{array}\right] \left(\left[\begin{array}{l}<br>5 \\<br>3<br>\end{array}\right]+\left[\begin{array}{cc}<br>1 &amp; 0 \\<br>-1 &amp; 0 \\<br>0 &amp; 1 \\<br>0 &amp; -1<br>\end{array}\right]^\top\left[\begin{array}{c}<br>\lambda_1 \\<br>\lambda_2 \\<br>\lambda_3 \\<br>\lambda_4<br>\end{array}\right]\right)-\left[\begin{array}{c}<br>\lambda_1 \\<br>\lambda_2 \\<br>\lambda_3 \\<br>\lambda_4<br>\end{array}\right]^\top \left[\begin{array}{c}<br>1 \\<br>1 \\<br>1 \\<br>1<br>\end{array}\right]<br>$$ $$<br>\text { subject to }\quad\left[\begin{array}{c}<br>\lambda_1 \\<br>\lambda_2 \\<br>\lambda_3 \\<br>\lambda_4<br>\end{array}\right]\geqslant 0.<br>$$</p>
<hr>
<div class="note info flat"><p>If you are interested in more detail, see below.</p>
</div>

<p>We introduce $\mathbf{Q} = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 4 \end{bmatrix}$, $\mathbf{c} = \begin{bmatrix} 5\\3\end{bmatrix}$, $ \mathbf{A} = \begin{bmatrix} 1 &amp; 0\\-1 &amp; 0\\ 0 &amp; 1\\ 0 &amp; -1 \end{bmatrix} $ and $ \mathbf{b}= \begin{bmatrix} 1\\1\\1\\1 \end{bmatrix} $</p>
<p>Then the quadratic problem takes form</p>
<p>$$ \min_{\mathbf{x} \in \mathbb{R}^2} \frac{1}{2}\mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x}$$ $$\text{subject to } \mathbf{A}\mathbf{x} \leq \mathbf{b} $$</p>
<p>The Lagrangian corresponding to this problem is</p>
<p>$$ \mathcal{L}(\mathbf{x},\mathbf{\lambda}) = \frac{1}{2}\mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x} + \mathbf{\lambda}^T(\mathbf{A}\mathbf{x} - \mathbf{b})= \frac{1}{2}\mathbf{x}^T\mathbf{Q}\mathbf{x} + (\mathbf{c}^T+\mathbf{A}^T\mathbf{\lambda})^T\mathbf{x} - \mathbf{\lambda}^T\mathbf{b} $$</p>
<p>where $\mathbf{\lambda} = \begin{bmatrix}\lambda_1\\\lambda_2\\\lambda_3\\\lambda_4\end{bmatrix}$ We minimize the Lagrangian by setting its gradient to zero, which results in</p>
<p>$$ \mathbf{Q}\mathbf{x} + \mathbf{c}+\mathbf{A}^T\mathbf{\lambda} = 0 \Rightarrow \mathbf{x} = -\mathbf{Q}^{-1}(\mathbf{c}+\mathbf{A}^T\mathbf{\lambda}) $$</p>
<p>Substituting this back into the Lagrangian we obtain</p>
<p>$$ \mathcal{D}(\mathbf{\lambda})= \min_{\mathbf{x} \in \mathbb{R}^2} \mathcal{L}(\mathbf{x},\mathbf{\lambda}) =-(\mathbf{c}+\mathbf{A}^T\mathbf{\lambda})^T\mathbf{Q}^{-1}(\mathbf{c}+\mathbf{A}^T\mathbf{\lambda})- \mathbf{\lambda}^T\mathbf{b} $$</p>
<p>The dual problem is now</p>
<p>$$ \max_{\mathbf{\lambda} \in \mathbb{R}^4} -(\mathbf{c}+\mathbf{A}^T\mathbf{\lambda})^T\mathbf{Q}^{-1}(\mathbf{c}+\mathbf{A}^T\mathbf{\lambda})- \mathbf{\lambda}^T\mathbf{b}$$ $$\text{subject to } \mathbf{\lambda} \geq 0, $$ where the parameter vectors and matrices are defined above.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Calculus";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "f4d7cee51e59d583948f31cc8ab6b79a";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
        <category>Calculus</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
        <tag>Lagrange Duality</tag>
        <tag>Linear Program</tag>
      </tags>
  </entry>
  <entry>
    <title>Mathematics for Machine learning Solution Manual</title>
    <url>/mml-solution-manual.html</url>
    <content><![CDATA[<div class="note info flat"><p><a href="https://amzn.to/3aeqKqE">Mathematics for Machine Learning</a> by Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong</p>
</div>

<p>ISBN:9781108569323, 1108569323</p>
<a id="more"></a>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&OneJS=1&Operation=GetAdHtml&MarketPlace=US&source=ss&ref=as_ss_li_til&ad_type=product_link&tracking_id=linearalgeb0e-20&language=en_US&marketplace=amazon&region=US&placement=B083M7DBP6&asins=B083M7DBP6&linkId=937bbc3ea679bccdaf2d9de9b38b7643&show_border=true&link_opens_in_new_window=true"></iframe>

<h3 id="Chapter-2-Linear-Algebra"><a href="#Chapter-2-Linear-Algebra" class="headerlink" title="Chapter 2 Linear Algebra"></a>Chapter 2 Linear Algebra</h3><p><a href="/mml-exercise-2-1.html">#2.1</a>, <a href="/mml-exercise-2-2.html">#2.2</a>, <a href="/mml-exercise-2-3.html">#2.3</a>, <a href="/mml-exercise-2-4.html">#2.4</a>, <a href="/mml-exercise-2-5.html">#2.5</a>, <a href="/mml-exercise-2-6.html">#2.6</a>, <a href="/mml-exercise-2-7.html">#2.7</a>, <a href="/mml-exercise-2-8.html">#2.8</a>, <a href="/mml-exercise-2-9.html">#2.9</a>, <a href="/mml-exercise-2-10.html">#2.10</a>, <a href="/mml-exercise-2-11.html">#2.11</a>, <a href="/mml-exercise-2-12.html">#2.12</a>, <a href="/mml-exercise-2-13.html">#2.13</a>, <a href="/mml-exercise-2-14.html">#2.14</a>, <a href="/mml-exercise-2-15.html">#2.15</a>, <a href="/mml-exercise-2-16.html">#2.16</a>, <a href="/mml-exercise-2-17.html">#2.17</a>, <a href="/mml-exercise-2-18.html">#2.18</a>, <a href="/mml-exercise-2-19.html">#2.19</a>, <a href="/mml-exercise-2-20.html">#2.20</a></p>
<h3 id="Chapter-3-Analytic-Geometry"><a href="#Chapter-3-Analytic-Geometry" class="headerlink" title="Chapter 3 Analytic Geometry"></a>Chapter 3 Analytic Geometry</h3><p><a href="/mml-exercise-3-1.html">#3.1</a>, <a href="/mml-exercise-3-2.html">#3.2</a>, <a href="/mml-exercise-3-3.html">#3.3</a>, <a href="/mml-exercise-3-4.html">#3.4</a>, <a href="/mml-exercise-3-5.html">#3.5</a>, <a href="/mml-exercise-3-6.html">#3.6</a>, <a href="/mml-exercise-3-7.html">#3.7</a>, <a href="/mml-exercise-3-8.html">#3.8</a>, <a href="/mml-exercise-3-9.html">#3.9</a>, <a href="/mml-exercise-3-10.html">#3.10</a></p>
<h3 id="Chapter-4-Matrix-Decompositions"><a href="#Chapter-4-Matrix-Decompositions" class="headerlink" title="Chapter 4 Matrix Decompositions"></a>Chapter 4 Matrix Decompositions</h3><p><a href="/mml-exercise-4-1.html">#4.1</a>, <a href="/mml-exercise-4-2.html">#4.2</a>, <a href="/mml-exercise-4-3.html">#4.3</a>, <a href="/mml-exercise-4-4.html">#4.4</a>, <a href="/mml-exercise-4-5.html">#4.5</a>, <a href="/mml-exercise-4-6.html">#4.6</a>, <a href="/mml-exercise-4-7.html">#4.7</a>, <a href="/mml-exercise-4-8.html">#4.8</a>, <a href="/mml-exercise-4-9.html">#4.9</a>, <a href="/mml-exercise-4-10.html">#4.10</a>, <a href="/mml-exercise-4-11.html">#4.11</a>, <a href="/mml-exercise-4-12.html">#4.12</a></p>
<h3 id="Chapter-5-Vector-Calculus"><a href="#Chapter-5-Vector-Calculus" class="headerlink" title="Chapter 5 Vector Calculus"></a>Chapter 5 Vector Calculus</h3><p><a href="/mml-exercise-5-1.html">#5.1</a>, <a href="/mml-exercise-5-2.html">#5.2</a>, <a href="/mml-exercise-5-3.html">#5.3</a>, <a href="/mml-exercise-5-4.html">#5.4</a>, <a href="/mml-exercise-5-5.html">#5.5</a>, <a href="/mml-exercise-5-6.html">#5.6</a>, <a href="/mml-exercise-5-7.html">#5.7</a>, <a href="/mml-exercise-5-8.html">#5.8</a>, <a href="/mml-exercise-5-9.html">#5.9</a></p>
<h3 id="Chapter-6-Probability-and-Distributions"><a href="#Chapter-6-Probability-and-Distributions" class="headerlink" title="Chapter 6 Probability and Distributions"></a>Chapter 6 Probability and Distributions</h3><p><a href="/mml-exercise-6-1.html">#6.1</a>, <a href="/mml-exercise-6-2.html">#6.2</a>, <a href="/mml-exercise-6-3.html">#6.3</a>, <a href="/mml-exercise-6-4.html">#6.4</a>, <a href="/mml-exercise-6-5.html">#6.5</a>, <a href="/mml-exercise-6-6.html">#6.6</a>, <a href="/mml-exercise-6-7.html">#6.7</a>, <a href="/mml-exercise-6-8.html">#6.8</a>, <a href="/mml-exercise-6-9.html">#6.9</a>, <a href="/mml-exercise-6-10.html">#6.10</a>, <a href="/mml-exercise-6-11.html">#6.11</a>, <a href="/mml-exercise-6-12.html">#6.12</a>, <a href="/mml-exercise-6-13.html">#6.13</a></p>
<h3 id="Chapter-7-Continuous-Optimazation"><a href="#Chapter-7-Continuous-Optimazation" class="headerlink" title="Chapter 7 Continuous Optimazation"></a>Chapter 7 Continuous Optimazation</h3><p><a href="/mml-exercise-7-1.html">#7.1</a>, #7.2, <a href="/mml-exercise-7-3.html">#7.3</a>, <a href="/mml-exercise-7-4.html">#7.4</a>, #7.5, <a href="/mml-exercise-7-6.html">#7.6</a>, <a href="/mml-exercise-7-7.html">#7.7</a>, #7.8, #7.9, #7.10, #7.11</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Solution Manual</tag>
        <tag>Solution Content</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify that the set of complex numbers is a subfield of $\mathbb C$</title>
    <url>/lahk/linear-algebra-exercise-1-2-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.1</strong></p>
<p>Verify that the set of complex numbers described in Example 4 is a subfield of $\mathbb C$.<a id="more"></a></p>
<hr>
<p>Solution: Let $F=\{x+y\sqrt{2}\mid x,y\in\mathbb Q\}$. Then we must show six things:</p>
<ol>
<li> $0$ is in $F$</li>
<li> $1$ is in $F$</li>
<li> If $x$ and $y$ are in $F$ then so is $x+y$</li>
<li> If $x$ is in $F$ then so is $-x$</li>
<li> If $x$ and $y$ are in $F$ then so is $xy$</li>
<li> If $x\not=0$ is in $F$ then so is $x^{-1}$</li>
</ol>
<p>For 1, take $x=y=0$.</p>
<p>For 2, take $x=1$, $y=0$.</p>
<p>For 3, suppose $x=a+b\sqrt{2}$ and $y=c+d\sqrt{2}$. Then $x+y=(a+c)+(b+d)\sqrt{2}\in F$.</p>
<p>For 4, suppose $x=a+b\sqrt{2}$. Then $-x=(-a)+(-b)\sqrt{2}\in F$.</p>
<p>For 5, suppose $x=a+b\sqrt{2}$ and $y=c+d\sqrt{2}$. Then $$xy=(a+b\sqrt{2})(c+d\sqrt{2})=(ac+ 2bd) + (ad+bc)\sqrt{2}\in F.$$For 6, suppose $x=a+b\sqrt{2}$ where at least one of $a$ or $b$ is not zero. Let $n=a^2-2b^2$. Since $\sqrt{2}$ is not rational, we have $n\ne 0$. Let $y=a/n + (-b/n)\sqrt{2}\in F$. Then $$xy=\frac1n(a+b\sqrt{2})(a-b\sqrt{2})=\frac1n(a^2-2b^2)=1.$$ Thus $y=x^{-1}$ and $y\in F$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Field</tag>
      </tags>
  </entry>
  <entry>
    <title>Are the following two systems of linear equations equivalent (1)</title>
    <url>/lahk/linear-algebra-exercise-1-2-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.2</strong></p>
<p>Let $F$ be the field of complex numbers. Are the following two systems of linear equations equivalent? If so, express each equation in each system as a linear combination of the equations in the other system.<a id="more"></a></p>
<p>\begin{alignat*}{2}<br>&amp; x_1-x_2=0, \quad &amp; 3x_1+x_2=0 \\<br>&amp; 2x_1+x_2=0, \quad &amp; x_1+x_2=0<br>\end{alignat*}</p>
<hr>
<p>Solution: Yes the two systems are equivalent. We show this by writing each equation of the first system in terms of the second, and conversely.  </p>
<p>On one hand, we have<br>\begin{alignat*}{2}<br>3x_1+x_2&amp;=\frac13(x_1-x_2)+\frac43(2x_1+x_2)\\<br>x_1+x_2 &amp;= \frac{-1}3(x_1-x_2)+\frac23(2x_1+x_2)<br>\end{alignat*}</p>
<p>On the other hand, we have</p>
<p>\begin{alignat*}{2}<br>x_1-x_2 &amp;= (3x_1+x_2)-2(x_1+x_2)\\<br>2x_1+x_2&amp;=\frac12(3x_1+x_2)+\frac12(x_1+x_2)<br>\end{alignat*}</p>
<p>Hence they are equivalent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Are the following two systems of linear equations equivalent (2)</title>
    <url>/lahk/linear-algebra-exercise-1-2-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.3</strong></p>
<p>Test the following systems of equations as in <a href="/hoffman-kunze/linear-algebra-exercise-1-2-2.html">Exercise 2</a>.<br>\begin{alignat*}{6}<br>-x_1 &amp;+ x_2 &amp;+ 4x_3 &amp;=0\quad\quad x_1 &amp; &amp;-x_3 &amp;=0\\<br>x_1 &amp;+ 3x_2 &amp;+ 8x_3 &amp;=0 &amp; x_2 &amp;+ x_3 &amp;=0\\<br>{\scriptstyle \frac12}x_1 &amp;+ x_2 &amp;+{\scriptstyle\frac52} x_3 &amp;=0 &amp; &amp; &amp;<br>\end{alignat*}<a id="more"></a></p>
<hr>
<p>Solution: Yes the two systems are equivalent. We show this by writing each equation of the first system in terms of the second, and conversely.  </p>
<p>On one hand, we have<br>\begin{alignat*}{1}<br>x_1-x_3 &amp;= {\frac{-3}4}(-x_1+x_2+4x_3) + {\frac14}(x_1+3x_3+8x_3)\\<br>x_2+3x_3&amp;={\frac14}(-x_1+x_2+4x_3) + {\frac14}(x_1+3x_3+8x_3)<br>\end{alignat*}<br>On the other hand, we have<br>\begin{alignat*}{1}<br>-x_1+x_2+4x_3 &amp;= -(x_1-x_3) + (x_2+3x_3)\\<br>x_1+3x_2+8x_3&amp;= (x_1-x_3) + 3(x_2+3x_3)\\<br>{\frac12}x_1+x_2+{\frac52}x_3&amp;= {\frac12}(x_1-x_3) + (x_2+3x_3)<br>\end{alignat*}<br>Hence they are equivalent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Are the following two systems of linear equations equivalent (3)</title>
    <url>/lahk/linear-algebra-exercise-1-2-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.4</strong></p>
<p>Test the following systems as in <a href="/hoffman-kunze/linear-algebra-exercise-1-2-2.html">Exercise 2</a>.<br>\begin{alignat*}{8}<br>2x_1 &amp;+ (-1+i) x_2 &amp; &amp;+ x_4 =0 \quad\quad (1+{\scriptstyle\frac{i}2})x_1&amp;+8x_2 &amp;-ix_3 &amp;-x_4 &amp;=0\\<br>&amp; &amp; 3x_2 – 2ix_3 &amp;+5x_4 =0\quad\quad {\scriptstyle\frac23}x_1 &amp;-{\scriptstyle\frac12}x_2 &amp;+ x_3 &amp;+ 7x_4 &amp;=0<br>\end{alignat*}<a id="more"></a></p>
<hr>
<p>Solution: These systems are not equivalent.</p>
<p>Call the two equations in the first system $E_1$ and $E_2$ and the equations in the second system $E’_1$ and $E’_2$. Then if $E’_2=aE_1+bE_2$ since $E_2$ does not have $x_1$ we must have $a=1/3$. But then to get the coefficient of $x_4$ we’d need $$7x_4=\dfrac13x_4+5bx_4.$$ That forces $b=\dfrac43$. But if $a=\dfrac13$ and $b=\dfrac43$ then the coefficient of $x_3$ would have to be $-2i\dfrac43$ which does not equal $1$. Therefore the systems cannot be equivalent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify the set with addition and multiplication is a field</title>
    <url>/lahk/linear-algebra-exercise-1-2-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.5</strong></p>
<p>Let $F$ be a set which contains exactly two elements, $0$ and $1$. Define an addition and multiplication by the tables:<br>$$\begin{array}{c|cc}<br>+ &amp; 0 &amp; 1\\ \hline<br>0 &amp; 0 &amp; 1\\<br>1 &amp; 1 &amp; 0<br>\end{array}<br>\quad\quad<br>\begin{array}{c|cc}<br>\cdot &amp; 0 &amp; 1\\ \hline<br>0 &amp; 0 &amp; 0\\<br>0 &amp; 0 &amp; 1<br>\end{array}<br>$$</p>
<a id="more"></a>
<hr>
<p>Solution: We must check the nine conditions on pages 1-2:</p>
<p><strong>1.</strong>  An operation is commutative if the table is symmetric across the diagonal that goes from the top left to the bottom right. This is true for the addition table so addition is commutative.</p>
<p><strong>2.</strong>  There are eight cases. But if $x=y=z=0$ or $x=y=z=1$ then it is obvious. So there are six non-trivial cases. If there’s exactly one $1$ and two $0$’s then both sides equal $1$. If there are exactly two $1$’s and one $0$ then both sides equal $0$. So addition is associative.</p>
<p><strong>3.</strong>  By inspection of the addition table, the element called $0$ indeed acts like a zero, it has no effect when added to another element.</p>
<p><strong>4.</strong>  $1+1=0$ so the additive inverse of $1$ is $1$. And $0+0=0$ so the additive inverse of $0$ is $0$. In other words $-1=1$ and $-0=0$. So every element has an additive inverse.</p>
<p><strong>5.</strong>  As stated in 1, an operation is commutative if the table is symmetric across the diagonal that goes from the top left to the bottom right. This is true for the multiplication table so multiplication is commutative.</p>
<p><strong>6.</strong>  As with addition, there are eight cases. If $x=y=z=1$ then it is obvious. Otherwise at least one of $x$, $y$ or $z$ must equal $0$. In this case both $x(yz)$ and $(xy)z$ equal zero. Thus multiplication is associative.</p>
<p><strong>7.</strong>  By inspection of the multiplication table, the element called $1$ indeed acts like a one, it has no effect when multiplied to another element.</p>
<p><strong>8.</strong>  There is only one non-zero element, $1$. And $1\cdot1=1$. So $1$ has a multiplicative inverse. In other words $1^{-1}=1$.</p>
<p><strong>9.</strong>  There are eight cases. If $x=0$ then clearly both sides equal zero. That takes care of four cases. If all three $x=y=z=1$ then it is obvious. So we are down to three cases. If $x=1$ and $y=z=0$ then both sides are zero. So we’re down to the two cases where $x=1$ and one of $y$ or $z$ equals $1$ and the other equals $0$. In this case both sides equal $1$. So $x(y+z)=(x+y)z$ in all eight cases.</p>
<blockquote>
<p>If you are familiar with basic field theory. This field is $\mathbb Z_2$.</p>
</blockquote>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Field</tag>
      </tags>
  </entry>
  <entry>
    <title>Homogeneous systems of linear equations in two unknowns with the same solutions are equivalent</title>
    <url>/lahk/linear-algebra-exercise-1-2-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.6</strong></p>
<p>Prove that if two homogeneous systems of linear equations in two unknowns have the same solutions, then they are equivalent.<a id="more"></a></p>
<hr>
<p>Solution: Write the two systems as follows:<br>$$<br>\begin{array}{c}<br>a_{11}x+a_{12}y=0\\<br>a_{21}x+a_{22}y=0\\<br>\vdots\\<br>a_{m1}x+a_{m2}y=0<br>\end{array}<br>\quad\quad<br>\begin{array}{c}<br>b_{11}x+b_{12}y=0\\<br>b_{21}x+b_{22}y=0\\<br>\vdots\\<br>b_{n1}x+b_{n2}y=0<br>\end{array}<br>$$ Each system consists of a set of lines through the origin $(0,0)$ in the $x$-$y$ plane. Thus there are 3 possible cases for the solution set of the two systems. Namely, they either both have $(0,0)$ as their only solution or if both have a single line $ux+vy=0$ as their common solution or if both have the whole $x$-$y$ plane as solutions. </p>
<p>If the whole $x$-$y$ plane is the solution set, then all $a_{ij}$ and $b_{kl}$ are zero. Of course, they are equivalent.</p>
<p>In the middle case all equations are simply multiples of the same line, so clearly the two systems are equivalent (proportional to each other if not completely zero). </p>
<p>So assume that both systems have $(0,0)$ as their only solution. Assume without loss of generality that the first two equations in the first system give different lines. Then<br>\begin{equation}<br>\frac{a_{11}}{a_{12}}\not=\frac{a_{21}}{a_{22}}<br>\label{eq1}<br>\end{equation} We need to show that there’s a $(u,v)$ which solves the following system:<br>$$\begin{array}{c}<br>a_{11}u+a_{12}v=b_{i1}\\<br>a_{21}u+a_{22}v=b_{i2}<br>\end{array}$$ Solving for $u$ and $v$ we get<br>$$u=\frac{a_{22}b_{i1}-a_{12}b_{i2}}{a_{11}a_{22}-a_{12}a_{21}}$$ $$v=\frac{a_{11}b_{i2}-a_{21}b_{i1}}{a_{11}a_{22}-a_{12}a_{12}}$$ By (\ref{eq1}) $a_{11}a_{22}-a_{12}a_{21}\not=0$. Thus both $u$ and $v$ are well defined. So we can write any equation in the second system as a combination of equations in the first. Analogously we can write any equation in the first system in terms of the second.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Each subfield of the field of complex numbers contains every rational number</title>
    <url>/lahk/linear-algebra-exercise-1-2-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.7</strong></p>
<p>Prove that each subfield of the field of complex numbers contains every rational number.<a id="more"></a></p>
<hr>
<p>Solution: Every subfield of $\mathbb C$ has characterisitc zero since if $\mathbb F$ is a subfield then $1\in \mathbb F$ and $n\cdot 1=0$ in $\mathbb F$ implies $n\cdot1=0$ in $\mathbb C$. But we know $n\cdot1=0$ in $\mathbb C$ implies $n=0$. So $1,2,3,\dots$ are all distinct elements of $\mathbb F$. And since $\mathbb F$ has additive inverses $-1,-2,-3,\dots$ are also in $\mathbb F$. And since $\mathbb F$ is a field also $0\in \mathbb F$. Thus $\mathbb Z\subseteq \mathbb F$.</p>
<p>Now $\mathbb F$ has multiplicative inverses so $\pm\frac1n\in \mathbb F$ for all natural numbers $n$. Now let $\frac mn$ be any element of $\mathbb Q$. Then we have shown that $m$ and $\frac1n$ are in $\mathbb F$. Thus their product $m\cdot\frac1n$ is in $\mathbb F$. Thus $\frac mn\in \mathbb F$. Thus we have shown all elements of $\mathbb Q$ are in $\mathbb F$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Field</tag>
        <tag>Rational Field</tag>
      </tags>
  </entry>
  <entry>
    <title>Each field of characteristic zero contains a copy of the rational number field</title>
    <url>/lahk/linear-algebra-exercise-1-2-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.2 Exercise 1.2.8</strong></p>
<p>Prove that each field of characteristic zero contains a copy of the rational number field.<a id="more"></a></p>
<hr>
<p>Solution: Call the additive and multiplicative identities of $\mathbb F$ $0_{\mathbb F}$ and $1_{\mathbb F}$ respectively. Because ${\mathbb F}$ has characteristic zero, we have $0_{\mathbb F}\ne 1_{\mathbb F}$. Define $n_{\mathbb F}$ to be the sum of $n$ $1_{\mathbb F}$’s. So $$n_{\mathbb F}=1_{\mathbb F}+1_{\mathbb F}+\cdots+1_{\mathbb F}$$ ($n$ copies of $1_{\mathbb F}$).</p>
<p>Define $-n_{\mathbb F}$ to be the additive inverse of $n_{\mathbb F}$. Since ${\mathbb F}$ has characteristic zero, if $n\not=m$ then $n_{\mathbb F}\not=m_{\mathbb F}$.</p>
<p>For $m,n\in\mathbb Z$, $n\not=0$, let $\left(\dfrac{m}{n}\right)_{\mathbb F}=m_{\mathbb F}\cdot n_{\mathbb F}^{-1}$. Since ${\mathbb F}$ has characteristic zero, if $\dfrac{m}{n}\not=\dfrac{m’}{n’}$ then $$\left(\dfrac{m}{n}\right)_{\mathbb F}\not=\left(\dfrac{m’}{n’}\right)_{\mathbb F}.$$ Therefore the map $\dfrac mn\mapsto\left(\dfrac{m}{n}\right)_{\mathbb F}$ gives a one-to-one map from $\mathbb Q$ to $\mathbb F$.</p>
<p>Call this map $h$. Then $h(0)=0_{\mathbb F}$, $h(1)=1_{\mathbb F}$ and in general $h(x+y)=h(x)+h(y)$ and $h(xy)=h(x)h(y)$. Thus we have found a subset of $\mathbb F$ that is in one-to-one correspondence to $\mathbb Q$ and which has the same field structure as $\mathbb Q$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Field</tag>
        <tag>Rational Field</tag>
      </tags>
  </entry>
  <entry>
    <title>Find all solutions to the systems of equations by row-reducing (1)</title>
    <url>/lahk/linear-algebra-exercise-1-3-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.1</strong></p>
<p>Find all solutions to the systems of equations \begin{alignat*}{1} (1-i)x_1-ix_2 &amp;= 0\\ 2x_1 + (1-i)x_2 &amp;= 0. \end{alignat*}</p>
<a id="more"></a>
<hr>
<p>Solution: The matrix of coefficients is<br>$$\left[\begin{array}{cc}1-i&amp;-i\\2&amp;1-i\end{array}\right].$$Row reducing<br>$$\rightarrow \left[\begin{array}{cc}2&amp;1-i\\1-i&amp;-i\end{array}\right]\rightarrow\left[\begin{array}{cc}2&amp;1-i\\0&amp;0\end{array}\right]<br>$$Thus $2x_1+(1-i)x_2=0$. Thus for any $x_2\in\mathbb C$, $$\left(\frac12(i-1)x_2,x_2\right)$$ is a solution and these are all solutions.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Find all solutions to the systems of equations by row-reducing (2)</title>
    <url>/lahk/linear-algebra-exercise-1-3-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.2</strong></p>
<p>If $$A=\left[\begin{array}{ccc}3&amp;-1&amp;2\\2&amp;1&amp;1\\1&amp;-3&amp;0\end{array}\right]$$ find all solutions of $AX=0$ by row-reducing $A$.</p>
<a id="more"></a>
<hr>
<p>Solution: We have$$\rightarrow\left[\begin{array}{ccc}1&amp;-3&amp;0\\2&amp;1&amp;1\\3&amp;-1&amp;2\end{array}\right]\rightarrow\left[\begin{array}{ccc}1&amp;-3&amp;0\\0&amp;7&amp;1\\0&amp;8&amp;2\end{array}\right]\rightarrow\left[\begin{array}{ccc}1&amp;-3&amp;0\\0&amp;1&amp;1/7\\0&amp;8&amp;2\end{array}\right]$$ $$\rightarrow\left[\begin{array}{ccc}1&amp;0&amp;3/7\\0&amp;1&amp;1/7\\0&amp;0&amp;6/7\end{array}\right]\rightarrow\left[\begin{array}{ccc}1&amp;0&amp;3/7\\0&amp;1&amp;1/7\\0&amp;0&amp;1\end{array}\right]\rightarrow\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;1&amp;10\\0&amp;0&amp;1\end{array}\right].$$Thus $A$ is row-equivalent to the identity matrix. It follows that the only solution to the system is $(0,0,0)$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Find all solutions to the systems of equations by row-reducing (3)</title>
    <url>/lahk/linear-algebra-exercise-1-3-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.3</strong></p>
<p>If $$A=\left[\begin{array}{ccc}6&amp;-4&amp;0\\4&amp;-2&amp;0\\-1&amp;0&amp;3\end{array}\right]$$ find all solutions of $AX=2X$ and all solutions of $AX=3X$. (The symbol $cX$ denotes the matrix each entry of which is $c$ times the corresponding entry of $X$.)</p>
<a id="more"></a>
<hr>
<p>Solution: The system $AX=2X$ is<br>$$\left[\begin{array}{ccc}6&amp;-4&amp;0\\4&amp;-2&amp;0\\-1&amp;0&amp;3\end{array}\right]\left[\begin{array}{c}x\\y\\z\end{array}\right]=2\left[\begin{array}{c}x\\y\\z\end{array}\right]$$which is the same as<br>\begin{alignat*}{1}<br>6x-4y&amp;=2x\\<br>4x-2y&amp;=2y\\<br>-x+3z&amp;=2z<br>\end{alignat*}which is equivalent to<br>\begin{alignat*}{1}<br>4x-4y&amp;=0\\<br>4x-4y&amp;=0\\<br>-x+z&amp;=0<br>\end{alignat*}The matrix of coefficients is<br>$$\left[\begin{array}{ccc}4&amp;-4&amp;0\\4&amp;-4&amp;0\\-1&amp;0&amp;1\end{array}\right]$$which row-reduces to<br>$$\left[\begin{array}{ccc}1&amp;0&amp;-1\\0&amp;1&amp;-1\\0&amp;0&amp;0\end{array}\right]$$Thus the solutions are all elements of $F^3$ of the form $(x,x,x)$ where $x\in F$.</p>
<p>The system $AX=3X$ is<br>$$\left[\begin{array}{ccc}6&amp;-4&amp;0\\4&amp;-2&amp;0\\-1&amp;0&amp;3\end{array}\right]\left[\begin{array}{c}x\\y\\z\end{array}\right]=3\left[\begin{array}{c}x\\y\\z\end{array}\right]$$which is the same as<br>\begin{alignat*}{1}<br>6x-4y &amp;=3x\\<br>4x-2y&amp;=3y\\<br>-x+3z&amp;=3z<br>\end{alignat*}<br>which is equivalent to<br>\begin{alignat*}{1}<br>3x-4y&amp;=0\\<br>x-2y&amp;=0\\<br>-x&amp;=0<br>\end{alignat*}The matrix of coefficients is<br>$$\left[\begin{array}{ccc}3&amp;-4&amp;0\\1&amp;-2&amp;0\\-1&amp;0&amp;0\end{array}\right]$$which row-reduces to$$\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;0\end{array}\right]$$Thus the solutions are all elements of $F^3$ of the form $(0,0,z)$ where $z\in F$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a row-reduced matrix to the given one</title>
    <url>/lahk/linear-algebra-exercise-1-3-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.4</strong></p>
<p>Find a row-reduced matrix which is row-equivalent to $$A=\left[\begin{array}{ccc} i &amp; -(1+i) &amp; 0\\ 1 &amp; -2 &amp; 1\\ 1 &amp; 2i &amp; -1 \end{array}\right].$$</p>
<a id="more"></a>
<hr>
<p>Solution: We have $$A\rightarrow\left[\begin{array}{ccc}<br>1 &amp; -2 &amp; 1\\<br>i &amp; -(1+i) &amp; 0\\<br>1 &amp; 2i &amp; -1<br>\end{array}\right]$$ $$\rightarrow<br>\left[\begin{array}{ccc}<br>1 &amp; -2 &amp; 1\\<br>0 &amp; -1+i &amp; -i\\<br>0 &amp; 2+2i &amp; -2<br>\end{array}\right]\rightarrow<br>\left[\begin{array}{ccc}<br>1 &amp; -2 &amp; 1\\<br>0 &amp; 1 &amp; \frac{1-i}2\\<br>0 &amp;2+ 2i &amp; -2<br>\end{array}\right]<br>$$ $$\rightarrow<br>\left[\begin{array}{ccc}<br>1 &amp; -2 &amp; 1\\<br>0 &amp; 1 &amp; \frac{i-1}2\\<br>0 &amp; 0 &amp; 0<br>\end{array}\right]\rightarrow<br>\left[\begin{array}{ccc}<br>1 &amp; 0 &amp; i\\<br>0 &amp; 1 &amp; \frac{i-1}2\\<br>0 &amp; 0 &amp; 0<br>\end{array}\right].<br>$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Row-reduced Matrix</tag>
        <tag>Row-equivalent</tag>
      </tags>
  </entry>
  <entry>
    <title>Prove that the following two matrices are not row-equivalent</title>
    <url>/lahk/linear-algebra-exercise-1-3-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.5</strong></p>
<p>Prove that the following two matrices are <em>not</em> row-equivalent: $$\left[\begin{array}{ccc} 2 &amp; 0 &amp; 0\\ a &amp; -1 &amp; 0\\ b &amp; c &amp; 3 \end{array}\right] \quad \left[\begin{array}{ccc} 1 &amp; 1 &amp; 2\\ -2 &amp; 0 &amp; -1\\ 1 &amp; 3 &amp; 5 \end{array}\right]. $$</p>
<a id="more"></a>
<hr>
<p>Solution: Call the first matrix $A$ and the second matrix $B$. </p>
<p>The matrix $A$ is row-equivalent to $$A’=\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{array}\right]$$ and the matrix $B$ is row-equivalent to $$B’=\left[\begin{array}{ccc}1&amp;0&amp;1/2\\0&amp;1&amp;3/2\\0&amp;0&amp;0\end{array}\right].$$<br>By Theorem 3 page 7 $AX=0$ and $A’X=0$ have the same solutions. </p>
<p>Similarly $BX=0$ and $B’X=0$ have the same solutions. Now if $A$ and $B$ are row-equivalent then $A’$ and $B’$ are row equivalent. Thus if $A$ and $B$ are row equivalent then $A’X=0$ and $B’X=0$ must have the same solutions. But $B’X=0$ has infinitely many solutions and $A’X=0$ has only the trivial solution $(0,0,0)$. Thus $A$ and $B$ cannot be row-equivalent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Row-equivalent</tag>
      </tags>
  </entry>
  <entry>
    <title>$2\times 2$ Row-reduced Matrix</title>
    <url>/lahk/linear-algebra-exercise-1-3-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.6</strong></p>
<p>Let $$A=\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right]$$ be a $2\times2$ matrix with complex entries. Suppose that $A$ is row-reduced and also that $a+b+c+d=0$. Prove that there are exactly three such matrices.</p>
<a id="more"></a>
<hr>
<p>Solution: Case $a\not=0$: Then to be in row-reduced form it must be that $a=1$ and $A=\left[\begin{array}{cc}1&amp;b\\c&amp;d\end{array}\right]$ which implies $c=0$, so $A=\left[\begin{array}{cc}1&amp;b\\0&amp;d\end{array}\right]$. Suppose $d\not=0$. Then to be in row-reduced form it must be that $d=1$ and $b=0$, so $A=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]$ which implies $a+b+c+d\not=0$. So it must be that $d=0$, and then it follows that $b=-1$. So $a\not=0$ $\Rightarrow$ $A=\left[\begin{array}{cc}1&amp;-1\\0&amp;0\end{array}\right]$.</p>
<p>Case $a=0$: Then $A=\left[\begin{array}{cc}0&amp;b\\c&amp;d\end{array}\right]$. If $b\not=0$ then $b$ must equal $1$ and $A=\left[\begin{array}{cc}0&amp;1\\c&amp;d\end{array}\right]$ which forces $d=0$. So $A=\left[\begin{array}{cc}0&amp;1\\c&amp;0\end{array}\right]$ which implies (since $a+b+c+d=0$) that $c=-1$. But $c$ cannot be $-1$ in row-reduced form. So it must be that $b=0$. So $A=\left[\begin{array}{cc}0&amp;0\\c&amp;d\end{array}\right]$. If $c\not=0$ then $c=1$, $d=-1$ and $A=\left[\begin{array}{cc}0&amp;0\\1&amp;-1\end{array}\right]$. Otherwise $c=0$ and $A=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$.</p>
<p>Thus the three possibilities are:<br>$$\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right],\quad\left[\begin{array}{cc}1&amp;-1\\0&amp;0\end{array}\right],\quad\left[\begin{array}{cc}0&amp;0\\1&amp;-1\end{array}\right].$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Row-reduced Matrix</tag>
        <tag>Row-equivalent</tag>
      </tags>
  </entry>
  <entry>
    <title>Interchange of two rows can be accomplished by elementary row operations of other types</title>
    <url>/lahk/linear-algebra-exercise-1-3-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.7</strong></p>
<p>Prove that the interchange of two rows of a matrix can be accomplished by a finite sequence of elementary row operations of the other two types.</p>
<a id="more"></a>
<hr>
<p>Solution: Write the matrix as<br>$$\left[\begin{array}{c}<br>R_1\\<br>R_2\\<br>R_3\\<br>\vdots\\<br>R_n<br>\end{array}\right].$$ WLOG we’ll show how to exchange rows $R_1$ and $R_2$. </p>
<p>First add $R_2$ to $R_1$:<br>$$\left[\begin{array}{c}<br>R_1+R_2\\<br>R_2\\<br>R_3\\<br>\vdots\\<br>R_n<br>\end{array}\right].$$ Next subtract row one from row two:<br>$$\left[\begin{array}{c}<br>R_1+R_2\\<br>-R_1\\<br>R_3\\<br>\vdots\\<br>R_n<br>\end{array}\right].$$ Next add row two to row one again<br>$$\left[\begin{array}{c}<br>R_2\\<br>-R_1\\<br>R_3\\<br>\vdots\\<br>R_n<br>\end{array}\right].$$ Finally multiply row two by $-1$:<br>$$\left[\begin{array}{c}<br>R_2\\<br>R_1\\<br>R_3\\<br>\vdots\\<br>R_n<br>\end{array}\right].$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Row Operation</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve general linear equations with $2\times 2$ matrix</title>
    <url>/lahk/linear-algebra-exercise-1-3-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 1.3 Exercise 1.3.8</strong></p>
<p>Consider the system of equations $AX=0$ where $$A=\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right]$$ is a $2\times2$ matrix over the field $F$. Prove the following: </p>
<p>(a) If every entry of $A$ is $0$, then every pair $(x_1,x_2)$ is a solution of $AX=0$. <a id="more"></a></p>
<p>(b) If $ad-bc\not=0$, the system $AX=0$ has only the trivial solution $x_1=x_2=0$. </p>
<p>(c) If $ad-bc=0$ and some entry of $A$ is different from $0$, then there is a solution $(x_1^0,x_2^0)$ such that $(x_1,x_2)$ is a solution if and only if there is a scalar $y$ such that $x_1=yx_1^0$, $x_2=yx_2^0$.</p>
<hr>
<p>Solution:</p>
<p>(a) In this case the system of equations is<br>\begin{alignat*}{1}<br>0\cdot x_1 + 0\cdot x_2 &amp;= 0\\<br>0\cdot x_1 + 0\cdot x_2 &amp;= 0<br>\end{alignat*}Clearly any $(x_1,x_2)$ satisfies this system since $0\cdot x=0$ $\forall$ $x\in F$.</p>
<p>(b) Let $(u,v)\in F^2$. Consider the system:<br>\begin{alignat*}{1}<br>a\cdot x_1 + b\cdot x_2 &amp;= u\\<br>c\cdot x_1 + d\cdot x_2 &amp;= v<br>\end{alignat*}If $ad-bc\not=0$ then we can solve for $x_1$ and $x_2$ explicitly as<br>$$<br>x_1=\frac{du-bv}{ad-bc}\quad x_2=\frac{av-cu}{ad-bc}.$$Thus there’s a unique solution for all $(u,v)$ and in partucular when $(u,v)=(0,0)$.</p>
<p>(c) Assume WLOG that $a\not=0$. Then $ad-bc=0$ $\Rightarrow$ $d=\frac{cb}{a}$. Thus if we multiply the first equation by $\frac ca$ we get the second equation. Thus the two equations are redundant and we can just consider the first one $a x_1+bx_2=0$. Then any solution is of the form $(-\frac bay,y)$ for arbitrary $y\in F$. Thus letting $y=1$ we get the solution $(-b/a,1)$ and the arbitrary solution is of the form $y(-b/a,1)$ as desired.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify that $F^n$ is a vector space over the field $F$</title>
    <url>/lahk/linear-algebra-exercise-2-1-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.1</strong></p>
<p>If $F$ is a field, verify that $F^n$ (as defined in Example 1) is a vector space over the field $F$.</p>
<a id="more"></a>
<hr>
<p>Example 1 starts with any field and defines the objects, the addition rule and the scalar multiplication rule. We must show the set of $n$-tuples satisfies the eight properties required in the definition.</p>
<p>(1) Addition is commutative. Let $\alpha=(x_1,\dots,x_n)$ and $\beta=(y_1,\dots,y_n)$ be two $n$-tuples. Then $$\alpha+\beta = (x_1+y_1,\dots,x_n+y_n).$$ And since $F$ is commutative this equals $(y_1+x_1,\dots,y_n+x_n)$, which equals $\beta+\alpha$. Thus $\alpha+\beta=\beta+\alpha$.</p>
<p>(2) Addition is associative. Let $\alpha=(x_1,\dots,x_n)$, $\beta=(y_1,\dots,y_n)$ and $\gamma=(z_1,\dots,z_n)$ be three $n$-tuples. Then $$(\alpha+\beta)+\gamma=((x_1+y_1)+z_1,\dots,(x_n+y_n)+z_n).$$ And since $F$ is associative this equals<br>$$(x_1+(y_1+z_1),\dots,x_n+(y_n+z_n)),$$ which equals $\alpha+(\beta+\gamma)$.</p>
<p>(3) We must show there is a unique vector $0$ in $V$ such that $\alpha+0=\alpha$ $\forall$ $\alpha\in V$. Consider $(0_F,\dots,0_F)$ the vector of all $0$’s of length $n$, where $0_F$ is the zero element of $F$. Then this vector satisfies the property that $$(0_F,\dots,0_F)+(x_1,\dots,x_n)=(0_F+x_1,\dots,0_F+x_n)=(x_1,\dots,x_n)$$ since $0_F+x=x$ for all $x\in F$. Thus $(0_F,\dots,0_F)+\alpha=\alpha$ $\forall \alpha\in V$. We must just show this vector is unique with respect to this property. Suppose $\beta=(x_1,\dots,x_n)$ also satisfies the property that $\beta+\alpha=\alpha$ for all $\alpha\in V$. Let $\alpha=(0_F,\dots,0_F)$. Then $$(x_1,\dots,x_n)=(x_1+0_F,\dots,x_n+0_F)=(x_1,\dots,x_n)+(0_F,\dots,0_F)$$ and by definition of $\beta$ this equals $(0_F,\dots,0_F)$. Thus $(x_1,\dots,x_n)=(0_F,\dots,0_F)$. Thus $\beta=\alpha$ and the zero element is unique.</p>
<p>(4) We must show for each vector $\alpha$ there is a unique vector $\beta$ such that $\alpha+\beta=0$. Suppose $\alpha=(x_1,\dots,x_n)$. Let $\beta=(-x_1,\dots,-x_n)$. Then $\beta$ has the required property $\alpha+\beta=0$. We must show $\beta$ is unique with respect to this property. Suppose also $\beta’=(x’_1,\dots,x’_n)$ also has this property. Then $\alpha+\beta=0$ and $\alpha+\beta’=0$. So $$\beta=\beta+0=\beta+(\alpha+\beta’)=(\beta+\alpha)+\beta’=0+\beta’=\beta’.$$</p>
<p>(5) Let $1_F$ be the multiplicative identity in $F$. Then $1_F \cdot(x_1,\dots,x_n)=(1\cdot x_1,\dots,1\cdot x_n)=(x_1,\dots,x_n)$ since $1_F\cdot x=x$ $\forall$ $x\in F$. Thus $1_F\alpha=\alpha$, for all $\alpha\in V$.</p>
<p>(6) Let $\alpha=(x_1,\dots,x_n)$. Then $(c_1c_2)\alpha=((c_1c_2)x_1,\dots, (c_1c_2)x_n)$ and since multiplication in $F$ is associative this equals $$(c_1(c_2x_1),\dots,c_1(c_2x_n))=c_1(c_2x_1,\dots c_2x_n)=c_1\cdot(c_2\alpha).$$</p>
<p>(7) Let $\alpha=(x_1,\dots,x_n)$ and $\beta=(y_1,\dots,y_n)$. Then $$c(\alpha+\beta)=c(x_1+ y_1,\dots,x_n+y_n)=(c(x_1+y_1),\dots,c(x_n+y_n))$$ and since multiplication is distributive over addition in $F$ this equals $(cx_1+cy_1,\dots,cx_n+xy_n)$. This then equals $$(cx_1,\dots,cx_n)+(cy_1,\dots,cy_n)=c(x_1,\dots,x_n)+c(y_1,\dots,y_n)=c\alpha+c\beta.$$ Thus $c(\alpha+\beta)=c\alpha+c\beta$.</p>
<p>(8) Let $\alpha=(x_1,\dots,x_n)$. Then $(c_1+c_2)\alpha=((c_1+c_2)x_1,\dots,(c_1+c_2)x_n)$ and since multiplication distributes over addition in $F$ this equals \begin{align*}&amp;\ (c_1x_1+c_2x_1,\dots, c_1x_n+c_2x_n)\\=&amp;\ (c_1x_1,\dots,c_1x_n)+(c_2x_1,\dots,c_2x_n)\\=&amp;\ c_1(x_1,\dots,x_n)+c_2(x_1,\dots,x_n)\\=&amp;\ c_1\alpha+c_2\alpha.\end{align*} Thus $(c_1+c_2)\alpha=c_1\alpha+c_2\alpha$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify identity using associativity and commutativity of vector space</title>
    <url>/lahk/linear-algebra-exercise-2-1-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.2</strong></p>
<p>If $V$ is a vector space over the field $F$, verify that $$(\alpha_1+\alpha_2)+(\alpha_3+\alpha_4)=[\alpha_2+(\alpha_3+\alpha_1)]+\alpha_4$$ for all vectors $\alpha_1,\alpha_2,\alpha_3$, and $\alpha_4$ in $V$.</p>
<a id="more"></a>
<hr>
<p>Solution: This follows associativity and commutativity properties of $V$:\begin{align*}&amp;\ (\alpha_1+\alpha_2)+(\alpha_3+\alpha_4)\\ =&amp;\ (\alpha_2+\alpha_1)+(\alpha_3+\alpha_4)\\ =&amp;\ \alpha_2+[\alpha_1+(\alpha_3+\alpha_4)]\\ =&amp;\ \alpha_2+[(\alpha_1+\alpha_3)+\alpha_4]\\=&amp;\ [\alpha_2+(\alpha_1+\alpha_3)]+\alpha_4\\=&amp;\ [\alpha_2+(\alpha_3+\alpha_1)]+\alpha_4.\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>All possible linear combinations of three vectors</title>
    <url>/lahk/linear-algebra-exercise-2-1-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.3</strong></p>
<p>If $\mathbb C$ is the field of complex numbers, which vectors in $\mathbb C^3$ are linear combinations of $(1,0,-1)$, $(0,1,1)$, and $(1,1,1)$?</p>
<a id="more"></a>
<hr>
<p>Solution: If we make a matrix out of these three vectors<br>$$A=\left[\begin{array}{ccc}1&amp;0&amp;1\\0&amp;1&amp;1\\-1&amp;1&amp;1\end{array}\right]$$then if we row-reduce the augmented matrix<br>$$\left[\begin{array}{ccc|ccc}1&amp;0&amp;1&amp;1&amp;0&amp;0\\0&amp;1&amp;1&amp;0&amp;1&amp;0\\-1&amp;1&amp;1&amp;0&amp;0&amp;1\end{array}\right]$$we get<br>$$\left[\begin{array}{ccc|ccc}1&amp;0&amp;0&amp;0&amp;1&amp;-1\\0&amp;1&amp;0&amp;-1&amp;2&amp;-1\\0&amp;0&amp;1&amp;1&amp;-1&amp;1\end{array}\right].$$Therefore the matrix is invertible and $AX=Y$ has a solution $X=A^{-1}Y$ for any $Y$. Thus any vector $Y\in\mathbb C^3$ can be written as a linear combination of the three vectors.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify if $F^2$ is a vector space with newly defined operations</title>
    <url>/lahk/linear-algebra-exercise-2-1-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.4</strong></p>
<p>Let $V$ be the set of all pairs $(x,y)$ of real numbers, and let $F$ be the field of real numbers. Define $$(x,y)+(x_1,y_1)=(x+x_1,y+y_1)$$ $$c(x,y)=(cx,y).$$ Is $V$, with these operations, a vector space over the field of real numbers?</p>
<a id="more"></a>
<hr>
<p>Solution: No, it is not a vector space because $$(0,2)=(0,1)+(0,1)=2(0,1)=(2\cdot0,1)=(0,1).$$ Thus we must have $(0,2)=(0,1)$ which implies $1=2$ which is a contradiction in the field of real numbers.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Axioms for a vector space are satisfied by newly defined operations</title>
    <url>/lahk/linear-algebra-exercise-2-1-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.5</strong></p>
<p>On $\mathbb R^n$, define two operations $$\alpha\oplus \beta=\alpha-\beta$$ $$c\cdot \alpha = -c\alpha.$$ The operations on the right are the usual ones. Which of the axioms for a vector space are satisfied by $(\mathbb R^n,\oplus,\cdot)$.</p>
<a id="more"></a>
<hr>
<p>Solution:</p>
<p>(1) $\oplus$ is not commutative since $$(0,\dots,0)\oplus(1,\dots,1)=(-1,\dots,-1)$$ while $$(1,\dots,1)\oplus(0,\dots,0)=(1,\dots,1).$$ And $(1,\dots,1)\not=(-1,\dots,-1)$.</p>
<p>(2) $\oplus$ is not associative since $$((1,\dots,1)\oplus(1,\dots,1))\oplus(2,\dots,2)=(0,\dots,0)\oplus(2,\dots,2)=(-2,\dots,-2)$$ while $$(1,\dots,1)\oplus((1,\dots,1)\oplus(2,\dots,2))=(1,\dots,1)\oplus(-1,\dots,-1)=(2,\dots,2).$$</p>
<p>(3) There does exist a right additive identity, i.e. a vector $0$ that satisfies $\alpha+0=\alpha$ for all $\alpha$. The vector $\beta=(0,\dots,0)$ satisfies $\alpha+\beta=\alpha$ for all $\alpha$. And if $\beta’=(b_1,\dots,b_n)$ also satisfies $$(x_1,\dots,x_n)+\beta’=(x_1,\dots,x_n)$$ then $x_i-b_i=x_i$ for all $i$ and thus $b_i=0$ for all $i$. Thus $\beta=(0,\dots,0)$ is unique with respect to the property $\alpha+\beta=\alpha$ for all $\alpha$.</p>
<p>(4) There do exist right additive inverses. For the vector $\alpha=(x_1,\dots,x_n)$ clearly only $\alpha$ itself satisfies $\alpha\oplus\alpha=(0,\dots,0)$.</p>
<p>(5) The element $1$ does not satisfy $1\cdot\alpha=\alpha$ for any non-zero $\alpha$ since otherwise we would have $$1\cdot(x_1,\dots,x_n)=(-x_1,\dots,-x_n)=(x_1,\dots,x_n)$$ only if $x_i=0$ for all $i$.</p>
<p>(6) The property $(c_1c_2)\cdot\alpha=c_1\cdot(c_2\cdot\alpha)$ does not hold since $(c_1c_2)\alpha=(-c_1c_2)\alpha$ while $$c_1(c_2\alpha)=c_1(-c_2\alpha)=(-c_1(-c2\alpha))=+c_1c_2\alpha.$$ Since $c_1c_2\not=-c_1c_2$ for all $c_1,c_2$ they are not always equal.</p>
<p>(7) It does hold that $c\cdot(\alpha\oplus\beta)=c\cdot\alpha\oplus c\cdot\beta$. Firstly, $$c\cdot(\alpha\oplus\beta)=c\cdot(\alpha-\beta)=-c(\alpha-\beta)=-c\alpha+c\beta.$$ And secondly $$c\cdot\alpha\oplus c\cdot\beta=(-c\alpha)\oplus(-c\beta)=-c\alpha-(-c\beta)=-c\alpha+c\beta.$$ Thus they are equal.</p>
<p>(8) It does not hold that $(c_1+c_2)\cdot\alpha=(c_1\cdot\alpha)\oplus(c_2\cdot\alpha)$. Firstly, $$(c_1+c_2)\cdot\alpha=-(c_1+c_2)\alpha=-c_1\alpha-c_2\alpha.$$ Secondly, $$c_1\cdot\alpha\oplus c_2\cdot\alpha=(-c_1\cdot\alpha)\oplus(-c_2\cdot\alpha)=-c_1\alpha+c_2\alpha.$$ Since $-c_1\alpha-c_2\alpha\not=-c_1\alpha-c_2\alpha$ for all $c_1,c_2$ they are not equal.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Set of all complex-valued functions as a vector space over $\mathbb R$</title>
    <url>/lahk/linear-algebra-exercise-2-1-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.6</strong></p>
<p>Let $V$ be the set of all complex-valued functions $f$ on the real line such that (for all $t$ in $\mathbb R$) $$f(-t) = \overline{f(t)}.$$ The bar denotes complex conjugation. Show that $V$, with the operations $$(f + g)(t) = f(t) + g(t)$$ $$(cf)(t) = cf(t)$$ is a vector space over the field of <em>real</em> numbers. Give an example of a function in $V$ which is not real-valued.</p>
<a id="more"></a>
<hr>
<p>Solution: We will use the basic fact that $$\overline{a+b}=\overline{a}+\overline{b},\quad \overline{ab}=\overline{a}\cdot\overline{b}.$$<br>Before we show $V$ satisfies the eight properties we must first show vector addition and scalar multiplication as defined are actually well-defined in the sense that they are indeed operations on $V$. In other words if $f$ and $g$ are two functions in $V$ then we must show that $f+g$ is in $V$. In other words if $f(-t)=\overline{f(t)}$ and $g(-t)=\overline{g(t)}$ then we must show that $(f+g)(-t)=\overline{(f+g)(t)}$. This is true because $$(f+g)(-t)=f(-t)+g(-t)=\overline{f(t)}+\overline{g(t)}=\overline{(f(t)+g(t)}=\overline{(f+g)(t)}.$$ Similary, if $c\in\mathbb R$, $$(cf)(-t)=cf(-t)=c\overline{f(t)}=\overline{cf(t)}$$ since $\overline{c}=c$ when $c\in\mathbb R$.</p>
<p>Thus the operations are well defined. We now show the eight properties hold:</p>
<p>(1) Addition on functions in $V$ is defined by adding in $\mathbb C$ to the values of the functions in $\mathbb C$. Thus since $\mathbb C$ is commutative, addition in $V$ inherits this commutativity.</p>
<p>(2) Similar to 1, since $\mathbb C$ is associative, addition in $V$ inherits this associativity.</p>
<p>(3) The zero function $g(t)=0$ is in $V$ since $-0=\overline{0}$. And $g$ satisfies $f+g=f$ for all $f\in V$. Thus $V$ has a right additive identity.</p>
<p>(4) Let $g$ be the function $g(t)=-f(t)$. Then $$g(-t)=-f(-t)=-\overline{f(t)}=\overline{-f(t)}=\overline{g(t)}.$$ Thus $g\in V$. And $$(f+g)(t)=f(t)+g(t)=f(t)-f(t)=0.$$ Thus $g$ is a right additive inverse for $f$.</p>
<p>(5) Clearly $1\cdot f=f$ since $1$ is the multiplicative identity in $\mathbb R$.</p>
<p>(6) As before, associativity in $\mathbb C$ implies $(c_1c_2)f=c_1(c_2f)$.</p>
<p>(7) Similarly, the distributive property in $\mathbb C$ implies $c(f+g)=cf+cg$.</p>
<p>(8) Similarly, the distributive property in $\mathbb C$ implies $(c_1+c_2)f=c_1f+c_2f$.</p>
<p>An example of a function in $V$ which is not real valued is $f(x)=ix$. Since $f(1)=i$, $f$ is not real-valued. And $$f(-x)=-ix=\overline{ix}$$ since $x\in\mathbb R$, so $f\in V$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify if a set is a vector space with operations like projection</title>
    <url>/lahk/linear-algebra-exercise-2-1-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.1 Exercise 2.1.7</strong></p>
<p>Let $V$ be the set of pairs $(x, y)$ of real numbers and let $F$ be the field of real numbers. Define $$(x,y)+(x_1,y_1)=(x+x_1,0)$$ $$c(x,y)=(cx,0)$$ Is $V$, with these operations, a vector space?</p>
<a id="more"></a>
<hr>
<p>Solution: This is not a vector space because there would have to be an additive identity element $(a,b)$ which has the property that $$(a,b)+(x,y)=(x,y)$$ for all $(x,y)\in V$. But this is impossible, because $$(a,b)+(0,1)=(a,0)\not=(0,1)$$ no matter what $(a,b)$ is. Thus $V$ does not satisfy the third requirement of having an additive identity element.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Check if they are subspaces of $\mathbb R^n$</title>
    <url>/lahk/linear-algebra-exercise-2-2-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.1</strong></p>
<p>Which of the following sets of vectors $\alpha=(a_1,\dots,a_n)$ in $\mathbb R^n$ are subspaces of $\mathbb R^n$ ($n\geqslant 3$)? </p>
<p>(a) all $\alpha$ such that $a_1\geqslant 0$; </p>
<p>(b) all $\alpha$ such that $a_1+3a_2=a_3$; <a id="more"></a></p>
<p>(c) all $\alpha$ such that $a_2=a_1^2$; </p>
<p>(d) all $\alpha$ such that $a_1a_2=0$; </p>
<p>(e) all $\alpha$ such that $a_2$ is rational.</p>
<hr>
<p>Solution:</p>
<p>(a) This is not a subspace because for $(1,\dots,1)$ the additive inverse is $(-1,\dots,-1)$ which does not satisfy the condition.</p>
<p>(b) Suppose $(a_1,a_2,a_3,\dots,a_n)$ and $(b_1,b_2,b_3,\dots,b_n)$ satisfy the condition and let $c\in\Bbb R$. By Theorem 1 (page 35) we must show that $$c(a_1,a_2,a_3,\dots,a_n)+(b_1,b_2,b_3,\dots,b_n)=(ca_1+b_1,\dots,ca_n+b_n)$$ satisfies the condition. Now $$(ca_1+b_1)+3(ca_2+b_2)=c(a_1+3a_2)+(b_1+3b_2)=c(a_3)+(b_3)=ca_3+b_3.$$ Thus it does satisfy the condition so $V$ is a vector space.</p>
<p>(c) This is not a vector space because $(1,1)$ satisfies the condition since $1^2=1$, but $$(1,1,\dots)+(1,1,\dots)=(2,2,\dots)$$ and $(2,2,\dots)$ does not satisfy the condition because $2^2\not=2$.</p>
<p>(d) This is not a subspace. $(1,0,\dots)$ and $(0,1,\dots)$ both satisfy the condition, but their sum is $(1,1,\dots)$ which does not satisfy the condition.</p>
<p>(e) This is not a subspace. $(1,1,\dots,1)$ satisfies the condition, but $\pi(1,1,\dots,1)=(\pi,\pi,\dots,\pi)$ does not satisfy the condition.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Check if they are subspaces of space of real functions</title>
    <url>/lahk/linear-algebra-exercise-2-2-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.2</strong></p>
<p>Let $V$ be the (real) vector space of all functions $f$ from $\mathbb R$ into $\mathbb R$. Which of the following sets of functions are subspaces of $V$? </p>
<p>(a) all $f$ such that $f(x^2)=f(x)^2$; </p>
<p>(b) all $f$ such that $f(0)=f(1)$; <a id="more"></a></p>
<p>(c) all $f$ such that $f(3)=1+f(-5)$; </p>
<p>(d) all $f$ such that $f(-1)=0$; </p>
<p>(e) all $f$ which are continuous.</p>
<hr>
<p>Solution:</p>
<p>(a) Not a subspace. Let $f(x)=x$ and $g(x)=x^2$. Then both satisfy the condition: $f(x^2)=x^2=(f(x))^2$ and $g(x^2)=(x^2)^2=(g(x))^2$. But $(f+g)(x)=x+x^2$ and $(f+g)(x^2)=x^2+x^4$ while $$[(f+g)(x)]^2=(x+x^2)^2=x^4+2x^3+x^2.$$ These are not equal polynomials so the condition does not hold for $f+g$.</p>
<p>(b) Yes a subspace. Suppose $f$ and $g$ satisfy the property. Let $c\in\mathbb R$. Then $$(cf+g)(0)=cf(0)+g(0)=cf(1)+g(1)=(cf+g)(1).$$ Thus $(cf+g)(0)=(cf+g)(1)$. By Theorem 1 (page 35) the set of all such functions constitute a subspace.</p>
<p>(c) Not a subspae. Let $f(x)$ be the function defined by $f(3)=1$ and $f(x)=0$ for all $x\not=3$. Let $g(x)$ be the function defined by $g(-5)=0$ and $g(x)=1$ for all $x\not=-5$. Then both $f$ and $g$ satisfy the condition. But $$(f+g)(3)=f(3)+g(3)=1+1=2,$$ while $$1+(f+g)(-5)=1+f(-5)+g(-5)=1+0+0=1.$$ Since $1\not=2$, $f+g$ does not satisfy the condition.</p>
<p>(d) Yes a subspace. Suppose $f$ and $g$ satisfy the property. Let $c\in\mathbb R$. Then $$(cf+g)(-1)=cf(-1)+g(-1)=c\cdot0+0=0.$$ Thus $(cf+g)(-1)=0$. By Theorem 1 (page 35) the set of all such functions constitute a subspace.</p>
<p>(e) Yes a subspace. Let $f$ and $g$ be continuous functions from $\mathbb R$ to $\mathbb R$ and let $c\in\mathbb R$. Then we know from basic results of real analysis that the sum and product of continuous functions are continuous. Since the function $c\mapsto c$ is continuous as well as $f$ and $g$, it follows that $cf+g$ is continuous. By Theorem 1 (page 35) the set of all cotinuous functions constitute a subspace.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Is the vector $(3, -1, 0, - 1)$ in the subspace of $\mathbb R^4$?</title>
    <url>/lahk/linear-algebra-exercise-2-2-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.3</strong></p>
<p>Is the vector $(3, -1, 0, - 1)$ in the subspace of $\mathbb R^4$ spanned by the vectors $(2, -1, 3, 2)$, $(-1, 1, 1, -3)$, and $(1, 1, 9, -5)$?</p>
<a id="more"></a>
<hr>
<p>Solution: No, $(3,-1,0,-1)$ is not in the subspace. If we row reduce the augmented matrix<br>$$\left[\begin{array}{ccc|c}2&amp;-1&amp;1&amp;3\\-1&amp;1&amp;1&amp;-1\\3&amp;1&amp;9&amp;0\\2&amp;-3&amp;-5&amp;-1\end{array}\right]$$we obtain<br>$$\left[\begin{array}{ccc|c}1&amp;0&amp;2&amp;2\\0&amp;1&amp;3&amp;1\\0&amp;0&amp;0&amp;-7\\0&amp;0&amp;0&amp;-2\end{array}\right].$$The two bottom rows are zero rows to the left of the divider, but the values to the right of the divider in those two rows are non-zero. Thus the system does not have a solution (see comments bottom of page 24 and top of page 25).</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Combination</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis for the solution set of linear equations</title>
    <url>/lahk/linear-algebra-exercise-2-2-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.4</strong></p>
<p>Let $W$ be the set of all $(x_1,x_2,x_3,x_4,x_5)$ in $\mathbb R^5$ which satisfy $$2x_1-x_2+\frac43x_3-x_4\quad=0$$ $$x_1\quad+\frac23x_3\quad-x_5=0$$ $$9x_1-3x_2+6x_3-3x_4-3x_5=0.$$ Find a finite set of vectors which spans $W$.</p>
<a id="more"></a>
<hr>
<p>Solution: The matrix of the system is<br>$$\left[\begin{array}{ccccc}2&amp;-1&amp;4/3&amp;-1&amp;0\\1&amp;0&amp;2/3&amp;0&amp;-1\\9&amp;-3&amp;6&amp;-3&amp;-3\end{array}\right].$$Row reducing to reduced echelon form gives<br>$$\left[\begin{array}{ccccc}1&amp;0&amp;2/3&amp;0&amp;-1\\0&amp;1&amp;0&amp;1&amp;-2\\0&amp;0&amp;0&amp;0&amp;0\end{array}\right].$$Thus the system is equivalent to<br>$$x_1+2/3x_3-x_5=0$$$$x_2+x_4-2x_5=0.$$Thus the system is parametrized by $(x_3,x_4,x_5)$. Setting each equal to one and the other two to zero (as in Example 15, page 42), in turn, gives the three vectors $(-2/3,0,1,0,0)$, $(0,-1,0,1,0)$ and $(1,2,0,0,1)$. These three vectors therefore span $W$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Linear equations</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify if subsets are subpace for space of matrices</title>
    <url>/lahk/linear-algebra-exercise-2-2-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.5</strong></p>
<p>Let $F$ be a field and let $n$ be a positive integer $(n\geqslant 2)$. Let $V$ be the vector space of all $n\times n$ matrices over $F$. Which of the following sets of matrices $A$ in $V$ are subspaces of $V$? </p>
<p>(a) all invertible $A$; </p>
<p>(b) all non-invertible $A$; <a id="more"></a></p>
<p>(c) all $A$ such that $AB=BA$, where $B$ is some fixed matrix in $V$; </p>
<p>(d) all $A$ such that $A^2=A$.</p>
<hr>
<p>Solution:</p>
<p>(a) This is not a subspace. Let $A=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]$ and let $B=\left[\begin{array}{cc}-1&amp;0\\0&amp;-1\end{array}\right]$. Then both $A$ and $B$ are invertible, but $A+B=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$ which is not invertible. Thus the subset is not closed with respect to matrix addition. Therefore it cannot be a subspace.</p>
<p>(b) This is not a subspace. Let $A=\left[\begin{array}{cc}1&amp;0\\0&amp;0\end{array}\right]$ and let $B=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right]$. Then neither $A$ nor $B$ is invertible, but $A+B=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]$ which is invertible. Thus the subset is not closed with respect to matrix addition. Therefore it cannot be a subspace.</p>
<p>(c) This is a subspace. Suppose $A_1$ and $A_2$ satisfy $A_1B=BA_1$ and $A_2B=BA_2$. Let $c\in F$ be any constant. Then \begin{align*}(cA_1+A_2)B&amp;=cA_1B+A_2B\\&amp;=cBA_1+BA_2=B(cA_1)+BA_2=B(cA_1+A_2).\end{align*} Thus $cA_1+A_2$ satisfy the criteria. By Theorem 1 (page 35) the subset is a subspace.</p>
<p>(d) This is a subspace if $F$ equals $\mathbb Z/2\mathbb Z$, otherwise it is not a subspace.</p>
<p>Suppose first that char$(F)\not=2$. Let $A=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]$. Then $A^2=A$. But $A+A=\left[\begin{array}{cc}2&amp;0\\0&amp;2\end{array}\right]$ and $$\left[\begin{array}{cc}2&amp;0\\0&amp;2\end{array}\right]^2=\left[\begin{array}{cc}4&amp;0\\0&amp;4\end{array}\right]\not=\left[\begin{array}{cc}2&amp;0\\0&amp;2\end{array}\right].$$ Thus $A+A$ does not satisfy the criteria so the subset cannot be a subspace.</p>
<p>Suppose now that $F=\mathbb Z/2\mathbb Z$. Suppose $A$ and $B$ both satisfy $A^2=A$ and $B^2=B$. Let $c\in F$ be any scalar. Then $$(cA+B)^2=c^2A^2+2cAB+B^2.$$ Now $2=0$ so this reduces to $c^2A^2+B^2$. If $c=0$ then this reduces to $B^2$ which equals $B$, if $c=1$ then this reduces to $A^2+B^2$ which equals $A+B$. In both cases $(cA+B)^2=cA+B$. Thus in this case by Theorem 1 (page 35) the subset is a subspace.</p>
<p>Finally suppose char$(F)=2$ but $F$ is not $\mathbb Z/2\mathbb Z$. Then $|F|&gt;2$. The polynomial $x^2-x=0$ has at most two solutions in $F$, so $\exists$ $c\in F$ such that $c^2\not=c$. Consider the identity matrix $I=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]$. Then $I^2=I$. If such matrices form a subspace then it must be that $cI$ is also in the subspace. Thus it must be that $(cI)^2=cI$. Which is equivalent to $c^2=c$, which contradicts the way $c$ was chosen.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Matrix</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Find all subspaces of $\mathbb R^1$, $\mathbb R^2$, $\mathbb R^3$</title>
    <url>/lahk/linear-algebra-exercise-2-2-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.6</strong></p>
<p>(a) Prove that the only subspaces of $\mathbb R^1$ are $\mathbb R^1$ and the zero subspace. </p>
<p>(b) Prove that a subspace of $\mathbb R^2$ is $\mathbb R^2$, or the zero subspace, or consists of all scalar multiples of some fixed vector in $\mathbb R^2$. (The last type of subspace is, intuitively, a straight line through the origin.) <a id="more"></a></p>
<p>(c) Can you describe the subspaces of $\mathbb R^3$?</p>
<hr>
<p>Solution:</p>
<p>(a) Let $V$ be a subspace of $\mathbb R^1$. Suppose $\exists$ $v\in V$ with $v\not=0$. Then $v$ is a vector but it is also simply an element of $\mathbb R$. Let $\alpha\in\mathbb R$. Then $\alpha=\frac{\alpha}{v}\cdot v$ where $\frac{\alpha}{v}$ is a scalar in the base field $\mathbb R$. Since $cv\in V$ $\forall$ $c\in\mathbb R$, it follows that $\alpha\in V$. Thus we have shown that if $V\not=\{0\}$ then $V=\mathbb R^1$.</p>
<p>(b) We know the subsests $\{(0,0)\}$ (example 6a, page 35) and $\mathbb R^2$ (example 1, page 29) are subspaces of $\mathbb R^2$. Also for any vector $v$ in any vector space over any field $F$, the set $\{cv\mid c\in F\}$ is a subspace (Theorem 3, page 37). Thus we will be done if we show that if $V$ is a subspace of $\mathbb R^2$ and there exists $v_1,v_2\in V$ such that $v_1$ and $v_2$ do not lie on the same line, then $V=\mathbb R^2$. Equivalently we must show that any vector $w\in\mathbb R^2$ can be written as a linear combination of $v_1$ and $v_2$ whenever $v_1$ and $v_2$ are not co-linear. Equivalently, by Theorem 13 (iii) (page 23), it suffices to show that if $v_1=(a,b)$ and $v_2=(c,d)$ are not colinear, then the matrix $A=[v_1^T\ \ v_2^T]$ is invertible. Suppose $a\not=0$ and let $x=c/a$. Then $xa=c$, and since $v_1$ and $v_2$ are not colinear, it follows that $xb\not=d$. Thus equivalently $ad-bc\not=0$. It follows now from Exercise 1.6.8 pae 27 that if $v_1$ and $v_2$ not colinear then the matrix $A^T$ is invertible. Finally $A^T$ is invertible implies $A$ is invertible, since clearly $(A^T)^{-1}=(A^{-1})^T$. Similarly if $a=0$ then it must be that $b\not=0$ so we can make the same argument. So in all cases $A$ is invertible.</p>
<p>(c) The subspaces are the zero subspace $\{0,0,0\}$, lines $\{cv\mid c\in\mathbb R\}$ for fixed $v\in\mathbb R^3$, planes $$\{c_1v_1+c_2v_2\mid c_1,c_2\in\mathbb R\}$$ for fixed $v_1,v_2\in\mathbb R^3$ and the whole space $\mathbb R^3$. By Theorem 3 we know these all are subspaces, we just must show they are the only subspaces. It suffices to show that if $v_1$, $v_2$ and $v_3$ are not co-planar then the space generated by $v_1, v_2,v_3$ is all of $\mathbb R^3$. Equivalently we must show if $v_1$ and $v_2$ are not co-linear, and $v_3$ is not in the plane generated by $v_1,v_2$ then any vector $w\in\mathbb R^3$ can be written as a linear combination of $v_1,v_2,v_3$. Equivalently, by Theorem 13 (iii) (page 23), it suffices to show the matrix $A=[v_1\ \ v_2\ \ v_3]$ is invertible. $A$ is invertible $\Leftrightarrow$ $A^T$ is invertible, since clearly $(A^T)^{-1}=(A^{-1})^T$. Now $v_3$ is in the plane generated by $v_1,v_2$ $\Leftrightarrow$ $v_3$ can be written as a linear combination of $v_1$ and $v_2$ $\Leftrightarrow$ $A^T$ is row equivalent to a matrix with one of its rows equal to all zeros (this follows from Theorem 12, page 23) $\Leftrightarrow$ $A^T$ is <em>not</em> invertible. Thus $v_3$ is not in the plane generated by $v_1,v_2$ $\Leftrightarrow$ $A$ is invertible.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>When union of subspaces is again a subspace</title>
    <url>/lahk/linear-algebra-exercise-2-2-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.7</strong></p>
<p>Let $W_1$ and $W_2$ be subspaces of a vector space $V$ such that the set-theoretic union of $W_1$ and $W_2$ is also a subspace. Prove that one of the spaces $W_i$ is contained in the other.<a id="more"></a></p>
<hr>
<p>Solution: Assume the space generated by $W_1$ and $W_2$ is equal to their set-theoretic union $W_1\cup W_2$. Suppose $W_1\not\subseteq W_2$ and $W_2\not\subseteq W_1$. We wish to derive a contradiction. So suppose $\exists$ $w_1\in W_1\setminus W_2$ and $\exists$ $w_2\in W_2\setminus W_1$. Consider $w_1+w_2$. By assumption this is in $W_1\cup W_2$, so $\exists$ $w_1’\in W_1$ such that $$w_1+w_2=w_1’$$ or $\exists$ $w_2’\in W_2$ such that $$w_1+w_2=w_2’.$$ If the former, then $$w_2=w_1′-w_1\in W_1$$ which contradicts the assumption that $w_2\not\in W_1$. Likewise the latter implies the contradiction $w_1\in W_2$. Thus we are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Functions can uniquely rewritten as a sum of even and odd functions</title>
    <url>/lahk/linear-algebra-exercise-2-2-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.8</strong></p>
<p>Let $V$ be the vector space of all functions from $\Bbb R$ into $\Bbb R$; let $V_e$ be the susbset of even functions, $f(-x)=f(x)$; let $V_o$ be the subset of odd functions, $f(-x)=-f(x)$. </p>
<p>(a) Prove that $V_e$ and $V_o$ are subspaces of $V$. <a id="more"></a></p>
<p>(b) Prove that $V_e+V_o=V$. </p>
<p>(c) Prove that $V_e\cap V_o=\{0\}$.</p>
<hr>
<p>Solution:</p>
<p>(a) Let $f,g\in V_e$ and $c\in\mathbb R$. Let $h=cf+g$. Then $$h(-x)=cf(-x)+g(-x)=cf(x)+g(x)=h(x).$$ So $h\in V_e$. By Theorem 1 (page 35) $V_e$ is a subspace. Now let $f,g\in V_o$ and $c\in\mathbb R$. Let $h=cf+g$. Then $$h(-x)=cf(-x)+g(-x)=-cf(x)-g(x)=-h(x).$$ So $h\in V_o$. By Theorem 1 (page 35) $V_o$ is a subspace.</p>
<p>(b) Let $f\in V$. Let $$f_e(x)=\frac{f(x)+f(-x)}{2}$$ and $$f_o=\frac{f(x)-f(-x)}{2}.$$ Then $f_e$ is even and $f_o$ is odd and $f=f_e+f_o$. Thus we have written $f$ as $g+h$ where $g\in V_e$ and $h\in V_o$.</p>
<p>(c) Let $f\in V_e\cap V_o$. Then $f(-x)=-f(x)$ and $f(-x)=f(x)$. Thus $f(x)=-f(x)$ which implies $2f(x)=0$ which implies $f=0$.</p>
<blockquote>
<p>That means $V_e\oplus V_o=V$ is a direct sum.</p>
</blockquote>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Function</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Unique linear combinations of direct sums</title>
    <url>/lahk/linear-algebra-exercise-2-2-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.2 Exercise 2.2.9</strong></p>
<p>Let $W_1$ and $W_2$ be subspaces of a vector space $V$ such that $W_1 + W_2 = V$ and $W_1 \cap W_2 = {0}$. Prove that for each vector $\alpha$ in $V$ there are unique vectors $\alpha_1$ in $W_1$ and $\alpha_2$ in $W_2$ such that $\alpha=\alpha_1+\alpha_2$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $\alpha\in W$. Suppose $\alpha=\alpha_1+\alpha_2$ for $\alpha_i\in W_i$ and $\alpha=\beta_1+\beta_2$ for $\beta_i\in W_i$. Then $$\alpha_1+\alpha_2=\beta_1+\beta_2$$ which implies $$\alpha_1-\beta_1=\beta_2-\alpha_2.$$ Thus $\alpha_1-\beta_1\in W_1$ and $\alpha_1-\beta_1\in W_2$, namely $\alpha_1-\beta_1\in W_1\cap W_2$. </p>
<p>Since $W_1\cap W_2=\{0\}$ it follows that $\alpha_1-\beta_1=0$ and thus $\alpha_1=\beta_1$. Therefore $$\beta_2-\alpha_2=\alpha_1-\beta_1=0$$ so also $\alpha_2=\beta_2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Linear Combination</tag>
        <tag>Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>If two vectors are linearly dependent, one of them is a scalar multiple of the other</title>
    <url>/lahk/linear-algebra-exercise-2-3-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.1</strong></p>
<p>Prove that if two vectors are linearly dependent, one of them is a scalar multiple of the other.</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $v_1$ and $v_2$ are linearly dependent. If one of them, say $v_1$, is the zero vector then it is a scalar multiple of the other one $v_1=0\cdot v_2$. So we can assume both $v_1$ and $v_2$ are non-zero. Then if there exist $c_1,c_2$ such that $c_1v_1+c_2v_2=0$, both $c_1$ and $c_2$ must be non-zero. Therefore we can write $$v_1=-\frac{c_2}{c_1}v_2.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Dependence</tag>
      </tags>
  </entry>
  <entry>
    <title>Space spanned by a finite list is finite-dimensional</title>
    <url>/lahk/linear-algebra-exercise-2-3-10.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.10</strong></p>
<p>Let $V$ be a vector space over the field $F$. Suppose there are a finite number of vectors $\alpha_1,\dots,\alpha_r$ in $V$ which span $V$. Prove that $V$ is finite-dimensional.</p>
<a id="more"></a>
<hr>
<p>Solution: If any $\alpha_i$’s are equal to zero then we can remove them from the set and the remaining $\alpha_i$’s still span $V$. Thus we can assume WLOG that $\alpha_i\not=0$ $\forall$ $i$. If $\alpha_1,\dots,\alpha_r$ are linearly independent, then $\{ \alpha_1,\dots,\alpha_r\}$ is a basis and $\dim(V)=r&lt;\infty$. On the other hand if $\alpha_1,\dots,\alpha_r$ are linearly dependent, then $\exists$ $c_1,\dots,c_r\in F$, not all zero, such that $c_1\alpha_1+\cdots+c_r\alpha_r=0$. Suppose WLOG that $c_r\not=0$. Then $$\alpha_r=-\frac{c_1}{c_r}\alpha_1-\cdots-\frac{c_{r-1}}{c_r}\alpha_{r-1}.$$ Thus $\alpha_r$ is in the subspace spanned by $\alpha_1,\dots,\alpha_{r-1}$. Thus $\alpha_1,\dots,\alpha_{r-1}$ spans $V$. </p>
<p>If $\alpha_1,\dots,\alpha_{r-1}$ are linearly independent then $\{\alpha_1,\dots,\alpha_{r-1}\}$ is a basis and $\dim(V)=r-1&lt;\infty$. </p>
<p>If $\alpha_1,\dots,\alpha_{r-1}$ are linearly dependent then arguing as before (with possibly re-indexing) we can produce $\alpha_1,\dots,\alpha_{r-2}$ which span $V$. </p>
<p>Continuing in this way we must eventually arrive at a linearly independent set, or arrive at a set that consists of a single element, that still spans $V$. If we arrive at a single element $v_1$ then $\{v_1\}$ is linearly independent since $cv_1=0$ $\Rightarrow$ $c=0$ (see comments after (2-9) page 31). Thus we must eventually arrive at a finite set that is spans and is linearly independent. Thus we must eventually arrive at a finite basis, which implies $\dim(V)&lt;\infty$.</p>
<div class="note warning flat"><p>The statement follows from Theorem 4 on Page 44.</p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Generating Set</tag>
      </tags>
  </entry>
  <entry>
    <title>Complex matrices as vector space over real numbers</title>
    <url>/lahk/linear-algebra-exercise-2-3-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.11</strong></p>
<p>Let $V$ be the set of all $2\times2$ matrices $A$ with <em>complex</em> entries which satisfy $A_{11}+A_{22}=0$.<br>(a) Show that $V$ is a vector space over the field of <em>real</em> numbers, with the usual operations of matrix addition and multiplication of a matrix by a scalar.<br>(b) Find a basis for this vector space.<br>(c) Let $W$ be the set of all matrices $A$ in $V$ such that $A_{21}=-\overline{A_{12}}$ (the bar denotes complex conjugation). Prove that $W$ is a subspace of $V$ and find a basis for $W$.</p>
<a id="more"></a>
<hr>
<p>Solution: </p>
<p>(a) It is clear from inspection of the definition of a vector space (pages 28-29) that a vector space over a field $F$ is a vector space over every subfield of $F$, because all properties (e.g. commutativity and associativity) are inherited from the operations in $F$. Let $M$ be the vector space of all $2\times2$ matrices over $\mathbb C$ ($M$ is a vector space, see example 2 page 29). We will show $V$ is a subspace $M$ as a vector space over $\mathbb C$. It will follow from the comment above that $V$ is a vector space over $\mathbb R$. Now $V$ is a subset of $M$, so using Theorem 1 (page 35) we must show whenever $A,B\in V$ and $c\in\mathbb C$ then $cA+B\in V$. Let $A,B\in V$. Write $A=\left[\begin{array}{cc}x&amp;y\\z&amp;w\end{array}\right]$ and $B=\left[\begin{array}{cc}x’&amp;y’\\z’&amp;w’\end{array}\right]$. Then<br>\begin{equation}<br>x+w=x’+w’=0.<br>\label{p2.3.11}<br>\end{equation}$$cA+B=\left[\begin{array}{cc}cx+x’&amp;cy+y’\\cz+z’&amp;cw+w’\end{array}\right]$$To show $cA+B\in V$ we must show $(cx+x’) + (cw+w’)=0$. Rearranging the left hand side gives $c(x+w)+(x’+w’)$ which equals zero by (\ref{p2.3.11}).</p>
<p>(b) We can write the general element of $V$ as<br>$$A=\left[\begin{array}{cc}a+bi&amp;e+fi\\g+hi&amp;-a-bi\end{array}\right].$$Let<br>$$v_1=\left[\begin{array}{cc}1&amp;0\\0&amp;-1\end{array}\right],\quad v_2=\left[\begin{array}{cc}i&amp;0\\0&amp;-i\end{array}\right],$$$$v_3=\left[\begin{array}{cc}0&amp;1\\0&amp;0\end{array}\right],\quad v_4=\left[\begin{array}{cc}0&amp;i\\0&amp;0\end{array}\right],$$$$v_5=\left[\begin{array}{cc}0&amp;0\\1&amp;0\end{array}\right],\quad v_6=\left[\begin{array}{cc}0&amp;0\\i&amp;0\end{array}\right].$$Then $A=av_1+bv_2+ev_3+fv_4+gv_5+hv_6$ so $v_1$, $v_2$, $v_3$, $v_4$, $v_5$, $v_6$ span $V$.Suppose $$av_1+bv_2+ev_3+fv_4+gv_5+hv_6=0.$$ Then<br>$$av_1+bv_2+ev_3+fv_4+gv_5+hv_6=\left[\begin{array}{cc}a+bi&amp;e+fi\\g+hi&amp;-a-bi\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$$implies $a=b=c=d=e=f=g=h=0$ because a complex number $u+vi=0$ $\Leftrightarrow$ $u=v=0$. Thus $v_1$, $v_2$, $v_3$, $v_4$, $v_5$, $v_6$ are linearly independent. Thus $\{v_1, \dots, v_6\}$ is a basis for $V$ as a vector space over $\mathbb R$, and $\dim(V)=6$.</p>
<p>(c) Let $A,B\in W$ and $c\in\mathbb R$. By Theorem 1 (page 35) we must show $cA+B\in W$. Write $A=\left[\begin{array}{cc}x&amp;y\\-\bar{y}&amp;-x\end{array}\right]$ and $B=\left[\begin{array}{cc}x’&amp;y’\\-\bar{y’}&amp;-x’\end{array}\right]$, where $x,y,x’,y’\in\mathbb C$. Then $$cA+B=\left[\begin{array}{cc}cx+x’&amp;cy+y’\\-c\bar{y}-\bar{y’}&amp;-cx-x’\end{array}\right].$$ Since $-c\bar{y}-\bar{y’}=-\overline{(cy+y’)}$, it follows that $cA+B\in W$. Note that we definitely need $c\in\mathbb R$ for this to be true.</p>
<p>It remains to find a basis for $W$. We can write the general element of $W$ as<br>$$A=\left[\begin{array}{cc}a+bi&amp;e+fi\\-e+fi&amp;-a-bi\end{array}\right].$$Let<br>$$v_1=\left[\begin{array}{cc}1&amp;0\\0&amp;-1\end{array}\right],\quad v_2=\left[\begin{array}{cc}i&amp;0\\0&amp;-i\end{array}\right],$$$$v_3=\left[\begin{array}{cc}0&amp;1\\-1&amp;0\end{array}\right],\quad v_4=\left[\begin{array}{cc}0&amp;i\\i&amp;0\end{array}\right].$$Then $A=av_1+bv_2+ev_3+fv_4$ so $v_1$, $v_2$, $v_3$, $v_4$ span $V$.Suppose $av_1+bv_2+ev_3+fv_4=0$. Then<br>$$av_1+bv_2+ev_3+fv_4=\left[\begin{array}{cc}a+bi&amp;e+fi\\-e+fi&amp;-a-bi\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$$implies $a=b=e=f=0$ because a complex number $u+vi=0$ $\Leftrightarrow$ $u=v=0$. Thus $v_1$, $v_2$, $v_3$, $v_4$ are linearly independent. Thus $\{v_1, \dots, v_4\}$ is a basis for $V$ as a vector space over $\mathbb R$, and $\dim(V)=4$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>A basis for space of matrices of size $m\times n$</title>
    <url>/lahk/linear-algebra-exercise-2-3-12.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.12</strong></p>
<p>Prove that the space of $m\times n$ matrices over the field $F$ has dimension $mn$, by exhibiting a basis for this space.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $M$ be the space of all $m\times n$ matrices. Let $M_{ij}$ be the matrix of all zeros except for the $i,j$-th place which is a one. We claim $$\{M_{ij}\mid 1\leq i\leq m, 1\leq j\leq n\}$$ constitute a basis for $M$. Let $A=(a_{ij})$ be an arbitrary marrix in $M$. Then $A=\sum_{ij}a_{ij}M_{ij}$. Thus $\{M_{ij}\}$ span $M$. </p>
<p>Suppose $\sum_{ij}a_{ij}M_{ij}=0$. The left hand side equals the matrix $(a_{ij})$ and this equals the zero matrix if and only if every $a_{ij}=0$. Thus $\{M_{ij}\}$ are linearly independent as well. Thus the $nm$ matrices constitute a basis and $M$ has dimension $mn$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear independent list may be linearly dependent after changing the base field</title>
    <url>/lahk/linear-algebra-exercise-2-3-13.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.13</strong></p>
<p>Discuss <a href="/hoffman-kunze/linear-algebra-exercise-2-3-9.html">Exercise 9</a>, when $V$ is a vector space over the field with two elements described in <a href="/hoffman-kunze/linear-algebra-exercise-2-3-5.html">Exercise 5</a>, Section 1.1.</p>
<a id="more"></a>
<hr>
<p>Solution: If $F$ has characteristic two then $$(\alpha+\beta)+(\beta+\gamma)+(\gamma+\alpha)=2\alpha+2\beta+2\gamma=0+0+0=0$$ since in a field of characteristic two, $2=0$. Thus in this case $(\alpha+\beta)$, $(\beta+\gamma)$ and $(\gamma+\alpha)$ are linearly dependent. However any two of them are linearly independent. </p>
<p>For example suppose $a_1(\alpha+\beta)+a_2(\beta+\gamma)=0$. The LHS equals $a_1\alpha+a_2\gamma+(a_1+a_2)\beta$. Since $\alpha$, $\beta$, $\gamma$ are linearly independent, this is zero only if $a_1=0$, $a_2=0$ and $a_1+a_2=0$. In particular $a_1=a_2=0$, so $\alpha+\beta$ and $\beta+\gamma$ are linearly independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Dependence</tag>
        <tag>Base Field</tag>
      </tags>
  </entry>
  <entry>
    <title>The set of real numbers is not a finite-dimensional space over the field of tational numbers</title>
    <url>/lahk/linear-algebra-exercise-2-3-14.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.14</strong></p>
<p>Let $V$ be the set of real numbers.  Regard $V$ as a vector space over the field of <em>rational</em> numbers, with the usual operations.  Prove that this vector space is <em>not</em> finite-dimensional.</p>
<a id="more"></a>
<hr>
<p>Solution: We know that $\mathbb Q$ is countable and $\mathbb R$ is uncountable. Since the set of $n$-tuples of things from a countable set is countable, $\mathbb Q^n$ is countable for all $n$. Now, suppose $\{r_1,\dots,r_n\}$ is a basis for $\mathbb R$ over $\mathbb Q$. Then every element of $\mathbb R$ can be written as $a_1r_1+\cdots+a_nr_n$. Thus we can map $n$-tuples of rational numbers onto $\mathbb R$ by $$(a_1,\dots,a_n)\mapsto a_1r_1+\cdots+a_nr_n.$$ Thus the cardinality of $\mathbb R$ must be less or equal to $\mathbb Q^n$. But the former is uncountable and the latter is countable, a contradiction. Thus there can be no such finite basis.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Base Field</tag>
        <tag>Linear Independence</tag>
      </tags>
  </entry>
  <entry>
    <title>Are the vectors linearly independent?</title>
    <url>/lahk/linear-algebra-exercise-2-3-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.2</strong></p>
<p>Are the vectors $$\alpha_1=(1,1,2,4),\quad \alpha_2=(2,-1,-5,2)$$ $$\alpha_3=(1,-1,-4,0),\quad \alpha_4=(2,1,1,6)$$ linearly independent in $\mathbb R^4$?</p>
<a id="more"></a>
<hr>
<p>Solution: By Corollary 3, page 46, it suffices to determine if the matrix whose rows are the $\alpha_i$’s is invertible. By Theorem 12 (ii) we can do this by row reducing the matrix<br>$$\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\2&amp;-1&amp;-5&amp;2\\1&amp;-1&amp;-4&amp;0\\2&amp;1&amp;1&amp;6\end{array}\right].$$$$\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\2&amp;-1&amp;-5&amp;2\\1&amp;-1&amp;-4&amp;0\\2&amp;1&amp;1&amp;6\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\0&amp;-3&amp;-9&amp;-6\\0&amp;-2&amp;-6&amp;-4\\0&amp;-1&amp;-3&amp;-2\end{array}\right]<br>\underset{\text{rows}}{\overset{\text{swap}}{\rightarrow}}<br>\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\0&amp;-1&amp;-3&amp;-2\\0&amp;-3&amp;-9&amp;-6\\0&amp;-2&amp;-6&amp;-4\end{array}\right]\rightarrow$$$$<br>\rightarrow<br>\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\0&amp;1&amp;3&amp;2\\0&amp;-3&amp;-9&amp;-6\\0&amp;-2&amp;-6&amp;-4\end{array}\right]<br>\rightarrow\left[\begin{array}{cccc}1&amp;1&amp;2&amp;4\\0&amp;1&amp;3&amp;2\\0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0\end{array}\right]<br>$$Thus the four vectors are not linearly independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Row-reduced Matrix</tag>
        <tag>Linear Dependence</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis for the subspace of $\mathbb R^4$ spanned by the four vectors</title>
    <url>/lahk/linear-algebra-exercise-2-3-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.3</strong></p>
<p>Find a basis for the subspace of $\mathbb R^4$ spanned by the four vectors of <a href="/hoffman-kunze/linear-algebra-exercise-2-3-2.html">Exercise 2.3.2</a>.</p>
<a id="more"></a>
<hr>
<p>Solution: In Section 2.5, Theorem 9, page 56, it will be proven that row equivalent matrices have the same row space. The proof of this is almost immediate so there seems no easier way to prove it than to use that fact. </p>
<p>If you multiply a matrix $A$ on the left by another matrix $P$, the rows of the new matrix $PA$ are linear combinations of the rows of the original matrix. Thus the rows of $PA$ generate a subspace of the space generated by the rows of $A$. </p>
<p>If $P$ is invertible, then the two spaces must be contained in each other since we can go backwards with $P^{-1}$. Thus the rows of row-equivalent matrices generate the same space. Thus using the row reduced form of the matrix in <a href="/hoffman-kunze/linear-algebra-exercise-2-3-2.html">Exercise 2.3.2</a>, it must be that the space is two dimensoinal and generated by $(1,1,2,4)$ and $(0,1,3,2)$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Spanning Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Show that the vectors are linearly independent</title>
    <url>/lahk/linear-algebra-exercise-2-3-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.4</strong></p>
<p>Show that the vectors $$\alpha_1=(1,0,-1),\quad\alpha_2=(1,2,1),\quad\alpha_3=(0,-3,2)$$ form a basis for $\Bbb R^3$. Express each of the standard basis vectors as linear combinations of $\alpha_1$, $\alpha_2$, and $\alpha_3$.</p>
<a id="more"></a>
<hr>
<p>Solution: By Corollary 3, page 46, to show the vectors are linearly independent it suffices to show the matrix whose rows are the $\alpha_i$’s is invertible. By Theorem 12 (ii) we can do this by row reducing the matrix<br>$$A=\left[\begin{array}{ccc}1&amp;0&amp;-1\\1&amp;2&amp;1\\0&amp;-3&amp;2\end{array}\right].$$$$\left[\begin{array}{ccc}1&amp;0&amp;-1\\1&amp;2&amp;1\\0&amp;-3&amp;2\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;-1\\0&amp;2&amp;2\\0&amp;-3&amp;2\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;-1\\0&amp;1&amp;1\\0&amp;-3&amp;2\end{array}\right]\rightarrow$$$$<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;-1\\0&amp;1&amp;1\\0&amp;0&amp;5\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;-1\\0&amp;1&amp;1\\0&amp;0&amp;1\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{array}\right].<br>$$Now to write the standard basis vectors in terms of these vectors, by the discussion at the bottom of page 25 through page 26, we can row-reduce the augmented matrix<br>$$\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\1&amp;2&amp;1&amp;0&amp;1&amp;0\\0&amp;-3&amp;2&amp;0&amp;0&amp;1\end{array}\right].$$This gives<br>$$\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\1&amp;2&amp;1&amp;0&amp;1&amp;0\\0&amp;-3&amp;2&amp;0&amp;0&amp;1\end{array}\right]$$$$\rightarrow\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\0&amp;2&amp;2&amp;-1&amp;1&amp;0\\0&amp;-3&amp;2&amp;0&amp;0&amp;1\end{array}\right]$$$$\rightarrow\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\0&amp;1&amp;1&amp;-1/2&amp;1/2&amp;0\\0&amp;-3&amp;2&amp;0&amp;0&amp;1\end{array}\right]$$$$\rightarrow\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\0&amp;1&amp;1&amp;-1/2&amp;1/2&amp;0\\0&amp;0&amp;5&amp;-3/2&amp;3/2&amp;1\end{array}\right]$$$$\rightarrow\left[\begin{array}{ccc|ccc}1&amp;0&amp;-1&amp;1&amp;0&amp;0\\0&amp;1&amp;1&amp;-1/2&amp;1/2&amp;0\\0&amp;0&amp;1&amp;-3/10&amp;3/10&amp;1/5\end{array}\right]$$$$\rightarrow\left[\begin{array}{ccc|ccc}1&amp;0&amp;0&amp;7/10&amp;3/10&amp;1/5\\0&amp;1&amp;0&amp;-1/5&amp;1/5&amp;-1/5\\0&amp;0&amp;1&amp;-3/10&amp;3/10&amp;1/5\end{array}\right].$$Thus if<br>$$P=\left[\begin{array}{ccc}7/10&amp;3/10&amp;1/5\\-1/5&amp;1/5&amp;-1/5\\-3/10&amp;3/10&amp;1/5\end{array}\right]$$then $PA=I$, so we have$$\frac{7}{10}\alpha_1+\frac3{10}\alpha_2+\frac15\alpha_3=(1,0,0)$$$$-\frac15\alpha_1+\frac15\alpha_2-\frac15\alpha_3=(0,1,0)$$$$-\frac3{10}\alpha_1+\frac3{10}\alpha_2+\frac15\alpha_3=(0,0,1).$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Combination</tag>
        <tag>Linear Independence</tag>
      </tags>
  </entry>
  <entry>
    <title>Find three vectors which are linearly dependent but any two of them are linearly independent</title>
    <url>/lahk/linear-algebra-exercise-2-3-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.5</strong></p>
<p>Find three vectors in $\Bbb R^3$ which are linearly dependent, and are such that any two of them are linearly independent.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $v_1=(1,0,0)$, $v_2=(0,1,0)$ and $v_3=(1,1,0)$. Then $v_1+v_2-v_3=(0,0,0)$ so they are linearly dependent. We know $v_1$ and $v_2$ are linearly independent as they are two of the standard basis vectors (see Example 13, page 41). </p>
<p>Suppose $av_1+bv_3=0$. Then $(a+b,b,0)=(0,0,0)$. The second coordinate implies $b=0$ and then the first coordinate in turn implies $a=0$. Thus $v_1$ and $v_3$ are linearly independent. Analogously $v_2$ and $v_3$ are linearly independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Combination</tag>
        <tag>Linear Dependence</tag>
        <tag>Linear Independence</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis of matrix space and determine its dimension</title>
    <url>/lahk/linear-algebra-exercise-2-3-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.6</strong></p>
<p>Let $V$ be the vector space of all $2\times 2$ matrices over the field $F$. Prove that $V$ has dimension $4$ by exhibiting a basis for $V$ which has four elements.</p>
<a id="more"></a>
<hr>
<p>Solution: Let<br>$$v_{11}=\left[\begin{array}{cc}1&amp;0\\0&amp;0\end{array}\right],\quad v_{12}=\left[\begin{array}{cc}0&amp;1\\0&amp;0\end{array}\right]$$$$v_{21}=\left[\begin{array}{cc}0&amp;0\\1&amp;0\end{array}\right],\quad v_{22}=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right]$$Suppose $av_{11}+bv_{12}+cv_{21}+dv_{22}=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$.Then<br>$$\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right] = \left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right],$$from which it follows immediately that $a=b=c=d=0$. Thus $v_{11}$, $v_{12}$, $v_{21}$, $v_{22}$ are linearly independent.</p>
<p>Now let $\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right]$ be any $2\times2$ matrix. Then $\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right]=av_{11}+bv_{12}+cv_{21}+dv_{22}$. Thus $v_{11}$, $v_{12}$, $v_{21}$, $v_{22}$ span the space of $2\times2$ matrices.</p>
<p>Thus $v_{11}$, $v_{12}$, $v_{21}$, $v_{22}$ are both linearly independent and they span the space of all $2\times2$ matrices. Thus $v_{11}$, $v_{12}$, $v_{21}$, $v_{22}$ constitue a basis for the space of all $2\times2$ matrices.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Linear Independence</tag>
        <tag>Dimension</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine dimensions of subspaces of matrix space</title>
    <url>/lahk/linear-algebra-exercise-2-3-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.7</strong></p>
<p>Let $V$ be the vector space of <a href="/hoffman-kunze/linear-algebra-exercise-2-3-6.html">Exercise 2.3.6</a>. Let $W_1$ be the set of matrices of the form $$\left[\begin{array}{cc}x&amp;-x\\y&amp;z\end{array}\right]$$ and let $W_2$ be the set of matrices of the form $$\left[\begin{array}{cc}a&amp;b\\-a&amp;c\end{array}\right].$$ (a) Prove that $W_1$ and $W_2$ are subspaces of $V$. </p>
<p>(b) Find the dimension of $W_1$, $W_2$, $W_1+W_2$, and $W_1\cap W_2$.</p>
<a id="more"></a>
<hr>
<p>Solution: </p>
<p>(a) Let $A=\left[\begin{array}{cc}x&amp;-x\\y&amp;z\end{array}\right]$ and $B=\left[\begin{array}{cc}x’&amp;-x’\\y’&amp;z’\end{array}\right]$ be two elements of $W_1$ and let $c\in F$. Then<br>$$cA+B=\left[\begin{array}{cc}cx+x’&amp;-cx-x’\\cy+y’&amp;cz+z’\end{array}\right]=\left[\begin{array}{cc}a&amp;-a\\u&amp;v\end{array}\right]$$where $a=cx+x’$, $u=cy+y’$ and $v=cz+z’$. Thus $cA+B$ is in the form of an element of $W_1$. Thus $cA+B\in W_1$. By Theorem 1 (page 35) $W_1$ is a subspace.</p>
<p>Now let $A=\left[\begin{array}{cc}a&amp;b\\-a&amp;d\end{array}\right]$ and $B=\left[\begin{array}{cc}a’&amp;b’\\-a’&amp;d’\end{array}\right]$ be two elements of $W_1$ and let $c\in F$.Then<br>$$cA+B=\left[\begin{array}{cc}ca+a’&amp;cb+b’\\-ca-a’&amp;cd+d’\end{array}\right]=\left[\begin{array}{cc}x&amp;y\\-x&amp;z\end{array}\right]$$where $x=ca+a’$, $y=cb+b’$ and $z=cd+d’$. Thus $cA+B$ is in the form of an element of $W_2$. Thus $cA+B\in W_2$. By Theorem 1 (page 35) $W_2$ is a subspace.</p>
<p>(b) Let<br>$$A_1=\left[\begin{array}{cc}1&amp;-1\\0&amp;0\end{array}\right],\quad A_2=\left[\begin{array}{cc}0&amp;0\\1&amp;0\end{array}\right],\quad A_2=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right].$$Then $A_1, A_2,A_3\in W_1$ and<br>$$c_1A_1+c_2A_2+c_3A_3 = \left[\begin{array}{cc}c_1&amp;-c_1\\c_2&amp;c_3\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$$implies $c_1=c_2=c_3=0$. So $A_1$, $A_2$, $A_3$ are linearly independent. Now let $A=\left[\begin{array}{cc}x&amp;-x\\y&amp;z\end{array}\right]$ be any element of $W_1$. Then $A=xA_1+yA_2+zA_3$. Thus $A_1$, $A_2$, $A_3$ span $W_1$. Thus $\{A_1,A_2,A_3\}$ form a basis for $W_1$. Thus $W_1$ has dimension three.</p>
<p>Let<br>$$A_1=\left[\begin{array}{cc}1&amp;0\\-1&amp;0\end{array}\right],\quad A_2=\left[\begin{array}{cc}0&amp;1\\0&amp;0\end{array}\right],\quad A_2=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right].$$Then $A_1, A_2,A_3\in W_2$ and<br>$$c_1A_1+c_2A_2+c_3A_3 = \left[\begin{array}{cc}c_1&amp;c_2\\-c_1&amp;c_3\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$$implies $c_1=c_2=c_3=0$. So $A_1$, $A_2$, $A_3$ are linearly independent. Now let $A=\left[\begin{array}{cc}x&amp;y\\-x&amp;z\end{array}\right]$ be any element of $W_2$. Then $A=xA_1+yA_2+zA_3$. Thus $A_1$, $A_2$, $A_3$ span $W_2$. Thus $\{A_1,A_2,A_3\}$ form a basis for $W_2$. Thus $W_2$ has dimension three.</p>
<p>Let $V$ be the space of $2\times2$ matrices. We showed in Exercise 6 that the $\dim(V)=4$. Now $W_1\subseteq W_1+W_2\subseteq V$. Thus by Corollary 1, page 46, $3\leq\dim(W_1+W_2)\leq4$. </p>
<p>Let $A=\left[\begin{array}{cc}1&amp;0\\-1&amp;0\end{array}\right]$. Then $A\in W_2$ and $A\not\in W_1$. Thus $W_1+W_2$ is strictly bigger than $W_1$. Thus $$4\geq\dim(W_1+W_2)&gt;\dim(W_1)=3.$$ Thus $\dim(W_1+W_2)=4$.</p>
<p>Suppose $A=\left[\begin{array}{cc}a&amp;b\\c&amp;d\end{array}\right]$ is in $W_1\cap W_2$. Then $A\in W_1$ $\Rightarrow$ $a=-b$ and $A\in W_2$ $\Rightarrow$ $a=-c$. So $A=\left[\begin{array}{cc}a&amp;-a\\-a&amp;b\end{array}\right]$. Let $A_1=\left[\begin{array}{cc}1&amp;-1\\-1&amp;0\end{array}\right]$, $A_2=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right]$. Suppose $aA_1+bA_2=0$. Then<br>$$\left[\begin{array}{cc}a&amp;-a\\-a&amp;b\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right],$$which implies $a=b=0$. Thus $A_1$ and $A_2$ are linearly independent. Let $A=\left[\begin{array}{cc}a&amp;-a\\-a&amp;b\end{array}\right]\in W_1\cap W_2$. Then $A=aA_1+bA_2$. So $A_1,A_2$ span $W_1\cap W_2$. Thus $\{A_1,A_2\}$ is a basis for $W_1\cap W_2$. Thus $\dim(W_1\cap W_2)=2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Matrix</tag>
        <tag>Dimension</tag>
      </tags>
  </entry>
  <entry>
    <title>Determine dimensions of subspaces of matrix space consisting of idempotent matrices</title>
    <url>/lahk/linear-algebra-exercise-2-3-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.8</strong></p>
<p>Again let $V$ be the space of $2\times 2$ matrices over $F$. Find a basis $\{A_1,A_2,A_3,A_4\}$ for $V$ such that $A_j^2=A_j$ for each $j$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $V$ be the space of all $2\times2$ matrices. Let<br>$$A_1=\left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right],\quad A_2=\left[\begin{array}{cc}0&amp;0\\0&amp;1\end{array}\right]$$$$A_3=\left[\begin{array}{cc}1&amp;1\\0&amp;0\end{array}\right],\quad A_4=\left[\begin{array}{cc}0&amp;0\\1&amp;1\end{array}\right]$$Then $A_i^2=A_i$ for all $i$. Now<br>$$aA_1+bA_2+cA_3+dA_4=\left[\begin{array}{cc}a+c&amp;c\\d&amp;b+d\end{array}\right]=\left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right]$$implies $c=d=0$ which in turn implies $a=b=0$. Thus $A_1,A_2,A_3,A_4$ are linearly independent. Thus they span a subspace of $A$ of dimension four. </p>
<p>But by <a href="/hoffman-kunze/linear-algebra-exercise-2-3-6.html">Exercise 6</a>, $A$ also has dimension four. Thus by Corollary 1, page 46, the subspace spanned by $A_1,A_2,A_3,A_4$ is the entire space. Thus $\{A_1,A_2,A_3,A_4\}$ is a basis.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Basis</tag>
        <tag>Matrix</tag>
        <tag>Dimension</tag>
        <tag>Idempotent</tag>
      </tags>
  </entry>
  <entry>
    <title>If $\alpha$, $\beta$, and $\gamma$ are linearly independent so are $(\alpha+\beta)$, $(\beta+\gamma)$, and $(\gamma+\alpha)$</title>
    <url>/lahk/linear-algebra-exercise-2-3-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 2.3 Exercise 2.3.9</strong></p>
<p>Let $V$ be a vector space over a subfield $F$ of the complex numbers. Suppose $\alpha$, $\beta$, and $\gamma$ are linearly independent vectors in $V$. Prove that $(\alpha+\beta)$, $(\beta+\gamma)$, and $(\gamma+\alpha)$ are linearly independent.</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $a(\alpha+\beta)+b(\beta+\gamma)+c(\gamma+\alpha)=0$. Rearranging gives $$(a+c)\alpha+(a+b)\beta+(b+c)\gamma=0.$$ Since $\alpha$, $\beta$, and $\gamma$ are linearly independent it follows that $$a+c=a+b=b+c=0.$$ This gives a system of equations in $a,b,c$ with matrix<br>$$\left[\begin{array}{ccc}1&amp;1&amp;0\\1&amp;0&amp;1\\0&amp;1&amp;1\end{array}\right].$$This row-reduces as follows:<br>$$\left[\begin{array}{ccc}1&amp;1&amp;0\\1&amp;0&amp;1\\0&amp;1&amp;1\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;1&amp;0\\0&amp;-1&amp;1\\0&amp;1&amp;1\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;1&amp;0\\0&amp;1&amp;-1\\0&amp;1&amp;1\end{array}\right]\rightarrow$$$$<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;1\\0&amp;1&amp;-1\\0&amp;0&amp;2\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;1\\0&amp;1&amp;-1\\0&amp;0&amp;1\end{array}\right]<br>\rightarrow<br>\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{array}\right].<br>$$Since this row-reduces to the identity matrix, by Theorem 7, page 13, the only solution is $a=b=c=0$. Thus $(\alpha+\beta)$, $(\beta+\gamma)$, and $(\gamma+\alpha)$ are linearly independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Independence</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute polynomials in a matrix</title>
    <url>/lahk/linear-algebra-exercise-4-2-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.1</strong></p>
<p>Let $F$ be a subfield of the complex numbers and let $A$ be the following $2\times 2$ matrix over $F$<br>$$A=\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right].$$For each of the following polynomials $f$ over $F$, compute $f(A)$.</p>
<p>(a) $f=x^2-x+2$;<br>(b) $f=x^3-1$;<br>(c) $f=x^2-5x+7$;</p>
<a id="more"></a>
<hr>
<p>Solution:</p>
<p>(a) we have<br>\begin{align*}A^2=&amp;\ \left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\cdot\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}3&amp;5\\-5&amp;8\end{array}\right].\end{align*} Therefore<br>\begin{align*}f(A)=&amp;\ A^2-A+2\\=&amp;\ \left[\begin{array}{cc}3&amp;5\\-5&amp;8\end{array}\right]-\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]+\left[\begin{array}{cc}2&amp;0\\0&amp;2\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}3&amp;4\\-4&amp;7\end{array}\right]\end{align*}</p>
<p>(b) We have<br>\begin{align*}A^3=&amp;\ \left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\cdot\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\cdot\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}3&amp;5\\-5&amp;8\end{array}\right]\cdot\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}1&amp;18\\-18&amp;19\end{array}\right]\end{align*}Therefore<br>\begin{align*}f(A)=&amp;A^3-1\\=&amp;\ \left[\begin{array}{cc}1&amp;18\\-18&amp;19\end{array}\right] – \left[\begin{array}{cc}1&amp;0\\0&amp;1\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}0&amp;18\\-18&amp;18\end{array}\right]\end{align*}</p>
<p>(c) We have<br>\begin{align*}f(A)=&amp;\ A^2-5A+7\\=&amp;\ \left[\begin{array}{cc}3&amp;5\\-5&amp;8\end{array}\right] – 5\left[\begin{array}{cc}2&amp;1\\-1&amp;3\end{array}\right]+\left[\begin{array}{cc}7&amp;0\\0&amp;7\end{array}\right]\\=&amp;\ \left[\begin{array}{cc}0&amp;0\\0&amp;0\end{array}\right].\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute a polynomial in a operator</title>
    <url>/lahk/linear-algebra-exercise-4-2-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.2</strong></p>
<p>Let $T$ be the linear operator on $\mathbb R^3$ defined by<br>$$T(x_1,x_2,x_3)=(x_1,x_3,-2x_2-x_3).$$Let $f$ be the polynomial over $\mathbb R$ defined by $f=-x^3+2$. Find $f(T)$.</p>
<a id="more"></a>
<hr>
<p>Solution: The matrix of $T$ with respect to the standard basis is<br>$$A=\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;-2&amp;-1\end{array}\right]$$Thus<br>\begin{align*}A^2=&amp;\ \left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;-2&amp;-1\end{array}\right]\cdot\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;-2&amp;-1\end{array}\right]\\=&amp;\ \left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;-2&amp;-1\\0&amp;2&amp;-1\end{array}\right]\end{align*}So<br>\begin{align*}A^3=&amp;\ \left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;-2&amp;-1\\0&amp;2&amp;-1\end{array}\right]\cdot\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;-2&amp;-1\end{array}\right]\\=&amp;\ \left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;2&amp;-1\\0&amp;2&amp;3\end{array}\right]\end{align*}Thus<br>\begin{align*}-A^3+2=&amp;\ -\left[\begin{array}{ccc}1&amp;0&amp;0\\0&amp;2&amp;-1\\0&amp;2&amp;3\end{array}\right]+\left[\begin{array}{ccc}2&amp;0&amp;0\\0&amp;2&amp;0\\0&amp;0&amp;2\end{array}\right]\\=&amp;\ \left[\begin{array}{ccc}-1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;-2&amp;-1\end{array}\right].\end{align*}This corresponds to the transformation$$f(T)(x_1,x_2,x_3)=(-x_1,x_3,-x_2-x_3).$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify the diagonal case of Caley-Hamilton Theorem</title>
    <url>/lahk/linear-algebra-exercise-4-2-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.3</strong></p>
<p>Let $A$ be an $n\times n$ diagonal matrix over the field $F$, i.e., a matrix satisfying $A_{ij}=0$ for $i\not=j$. Let $f$ be the polynomial over $F$ defined by<br>$$f=(x-A_{11})\cdots(x-A_{nn}).$$What is the matrix $f(A)$?</p>
<a id="more"></a>
<hr>
<p>Solution: The product of $n$ diagonal matrices is again a diagonal matrix, where the $(i,i)$ element is the product of the entries in the $(i,i)$ position of the $n$ individual matrices. For each $i$, the $(i,i)$ terms of $A-A_{ii}$ is zero. Therefore each diagonal entry of $$(A-A_{11})\cdots(A-A_{nn})$$ is a product of numbers one of which is zero. Therefore $(A-A_{11})\cdots(A-A_{nn})$ is the zero matrix.</p>
<div class="note info flat"><p>This is a special case of Caley-Hamilton Theorem.</p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
        <tag>Polynomial</tag>
        <tag>Cayley-Hamilton Theorem</tag>
      </tags>
  </entry>
  <entry>
    <title>Independent polynomials remain independent after multiplying a non-zero polynomial</title>
    <url>/lahk/linear-algebra-exercise-4-2-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.4</strong></p>
<p>If $f$ and $g$ are independent polynomials over the field $F$ and $h$ is a non-zero polynomial over $F$, show that $fh$ and $gh$ are independent.</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose there are scalars $r,s\in F$ such that $$rfh+sgh=0.$$ Then $rfh=-sgh$ and so by Corollary 2 on page 121, it follows that $rf=-sg$ so that $$rf+sg=0.$$ Since $f$ and $g$ are independent, it follows that $r=s=0$. Thus $fh$ and $gh$ are independent.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Product of non-zero polynomials is also non-zero</title>
    <url>/lahk/linear-algebra-exercise-4-2-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.5</strong></p>
<p>If $F$ is a field, show that the product of two non-zero elements of $F^{\infty}$ is non-zero.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $f=(f_0,f_1,f_2,\dots)$ and $g=(g_0,g_1,g_2,\dots)$ be two elements of $F^{\infty}$. Let $n$ be the index of the first non-zero $f_i$ and let $m$ be the index of the first non-zero $g_i$ (could be $n=m=0$). Then what is the $n+m$ coordinate of the product? It is<br>$$(fg)_{n+m}=\sum_{i=0}^{n+m}f_ig_{n+m-i}=\sum_{i=n}^{n+m}f_ig_{n+m-i}$$and if $i&gt;n$ then $g_{n+m-i}=0$ thus<br>$$\sum_{i=n}^{n+m}f_ig_{n+m-i}=\sum_{i=n}^{n}f_ig_{n+m-i}=f_ng_m.$$Now we’ve assumed $f_n$ and $g_m$ are non-zero thus $f_ng_m\not=0$ and thus $fg\not=0$ in $F^{\infty}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Polynomials with distinct degrees are linearly independent</title>
    <url>/lahk/linear-algebra-exercise-4-2-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.6</strong></p>
<p>Let $S$ be a set of non-zero polynomials over a field $F$. If no two elements of $S$ have the same degree, show that $S$ is an independent set in $F[x]$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $f_1,\dots,f_n\in S$. Suppose deg$(f_i)=d$ and deg$(f_j)&lt; d$ $\forall$ $i\not=j$. We can do this because by assumption all polynomials in the set $\{f_1,\dots,f_n\}$ have different degrees, so one of them must have the largest. Suppose the $d$-th coefficient of $f_i$ is $r\not=0$. Then any linear combination $$a_1f_1+\cdots a_nf_n$$ has $d$-th coefficient equal to $ra_i$. Thus if this linear combination is zero then necessarily $a_i=0$. We can now apply the same argument to the $f_j$ with the second largest degree to show its coefficient in the linear combination is zero. And then to the third largest, etc. Until we have eventually shown all coefficients in the linear combination are zero. It follows that $\{f_1,\dots,f_n\}$ is a linearly independent subset of $S$ and since it was an arbitrary finite subset of $S$ it follows that $S$ is a linearly independent set.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>A basis of space of all polynomials with distinct degrees</title>
    <url>/lahk/linear-algebra-exercise-4-2-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.7</strong></p>
<p>If $a$ and $b$ are elements of a field $F$ and $a\not=0$, show that the polynomials $1$, $ax+b$, $(ax+b)^2$, $(ax+b)^3$, $\dots$ form a basis of $F[x]$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $$S=\{1, ax+b, (ax+b)^2, (ax+b)^3,\dots\}.$$ And let $\langle S\rangle$ be the subspace spanned by $S$. By the <a href="hoffman-kunze/linear-algebra-exercise-4-2-6.html">previous exercise</a> we know $S$ is a linearly independent set. We must just show $S$ spans the space of all polynomials. </p>
<p>Since $1\in S$ and $ax+b\in S$ it follows that $$-\frac ba\cdot 1+\frac1a(b+ax)\in \langle S\rangle.$$ Thus $x\in\langle S\rangle$. Now we can subtract a multiple of $1$ and a multiple of $x$ from $(a+bx)^2$ to get $a^2x^2\in\langle S\rangle$. Thus $$x^2=\frac1{a^2}\cdot a^2x^2\in\langle S\rangle.$$ Thus $x^2\in S$. Continuing in this way we can show that $x^n\in\langle S\rangle$ for all $n$. Since $\{1,x,x^2,\dots\}$ span the space of all polynomials, it follows that $S$ spans the space of all polynomials.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear transformation and isomorphism from $F[x]$ to $F[x]$</title>
    <url>/lahk/linear-algebra-exercise-4-2-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.8</strong></p>
<p>If $F$ is a field and $h$ is a polynomial over $F$ of degree $\geq1$, show that the mapping $f\rightarrow f(h)$ is a one-one linear transformation of $F[x]$ into $F[x]$. Show that this transformation is an isomorphism of $F[x]$ onto $F[x]$ if and only if deg $h=1$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $G:F[x]\rightarrow F[x]$ be the function $G(f)=f(h)$. Clearly $G$ is a well-defined function from $F[x]$ to $F[x]$. By definition $$G(f+g)=(f+g)(h)=f(h)+g(h)=G(f)+G(g)$$ and for $r\in F$, $$G(rf)=(rf)(h)=r\cdot f(h)=rG(f).$$ Thus $G$ is a linear transformation. We first show that $G$ is one-to-one. Taking a basis $$f_0,f_1,f_2,f_3,\dots,$$ of $F[x]$ with distinct degrees, $f_i=x^i$. Then $f_i(h)$ has degree $i\deg(h)$. Since $\deg h\geqslant 1$, all $f_i(h)$ have distinct degrees. Therefore by <a href="/hoffman-kunze/linear-algebra-exercise-4-2-8.html">Exercise 6</a>, $f_i(h)$ are linearly independent. Since $G$ maps a basis to a linearly independent list, $G$ is one-to-one (see the proof of Theorem 8 in page 80).</p>
<div class="note warning flat"><p>Please fill the gap in the last sentence (a good exercise). If you have trouble with it, please make a comment. I will give more detail.</p>
</div>

<hr>
<p>Let us prove the second statement. </p>
<p>Suppose  $\deg h=1$, so that $h(x)=a+bx$, where $b\ne 0$. Let $$h’= \frac1bx-\frac ab$$ and let $G’$ be thelinear transformation from $F[x]$ to $F[x]$ given by $$G’(f)=f\left(\frac1bx-\frac ab\right).$$ Then $G\circ G’$ and $G’\circ G$ both give the identify function on $F[x]$ (check it). Thus $G$ is an isomorphism.</p>
<p>If $\deg h &gt; 1$, then $$\deg f(h)=\deg f\cdot \deg h$$ can never be one. This means the image of $G$ does not contain polynomials with degree one. Hence $G$ is not onto and thus can not be an isomorphism.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Linear Transformation</tag>
      </tags>
  </entry>
  <entry>
    <title>Differentiation Operator and Integration Operator</title>
    <url>/lahk/linear-algebra-exercise-4-2-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.2 Exercise 4.2.9</strong></p>
<p>Let $F$ be a subfield of the complex numbers and let $T$, $D$ be the transformations on $F[x]$ defined by<br>$$T\left(\sum_{i=0}^nc_ix^i\right)=\sum_{i=0}^n\frac{c_i}{1+i}x^{i+1}$$and<br>$$D\left(\sum_{i=0}^nc_ix^i\right)=\sum_{i=1}^nic_ix^{i-1}.$$ (a) Show that $T$ is a non-singular linear operator on $F[x]$. Show also that $T$ is not invertible.  <a id="more"></a><br>(b) Show that $D$ is a linear operator on $F[x]$ and find its null space.<br>(c) Show that $DT=I$, and $TD\not=I$.<br>(d) Show that $T[(Tf)g]=(Tf)(Tg)-T[f(Tg)]$ for all $f,g$ in $F[x]$.<br>(e) State and prove a rule for $D$ similar to the one given for $T$ in (d)<br>(f) Suppose $V$ is a non-zero subspace of $F[x]$ such that $Tf$ belongs to $V$ for each $f$ in $V$. Show that $V$ is not finite-dimensional.<br>(g) Suppose $V$ is a finite-dimensional subspace of $F[x]$. Prove there is an integer $m\geq0$ such that $D^mf=0$ for each $f$ in $V$.</p>
<hr>
<div class="note info flat"><p>If you know calculus. You can see that $T$ is the integration operator while $D$ is the differentiation operator.</p>
</div>

<p>Solution:</p>
<p>(a) Clearly $T$ is a function from $F[x]$ to $F[x]$. We must show $T$ is linear.<br>\begin{align*} T\left(\sum_{i=0}^nc_ix^i+\sum_{i=0}^nc’_ix^i\right)=&amp;\ T\left(\sum_{i=0}^n(c_i+c’_i)x^i\right)\\=&amp;\ \sum_{i=0}^n\frac{c_i+c’_i}{i+1}x^{i+1}=\sum_{i=0}^n\left(\frac{c_i}{1+i}x^{i+1}+\frac{c’_i}{1+i}x^{i+1}\right)\\=&amp;\ T\left(\sum_{i=0}^nc_ix^i\right)+T\left(\sum_{i=0}^nc’_ix^i\right)\end{align*}and<br>\begin{align*}T\left(r\sum_{i=0}^nc_ix^i\right)=&amp;\ T\left(\sum_{i=0}^nrc_ix^i\right)<br>=\sum_{i=0}^n\frac{rc_i}{i+1}x^{i+1}\\<br>=&amp;\ r\sum_{i=0}^n\frac{c_i}{i+1}x^{i+1}<br>=r\cdot T\left(\sum_{i=0}^nc_ix^i\right).\end{align*}Thus $T$ is linear.</p>
<p>Since $F$ has characterisitc zero we can find $a,b\in F$, such that $a\not=b$. Consider $a$ and $b$ as constant polynomials in $F$. Then $T(a)=T(b)=0$. Thus $T$ is not one-to-one. Thus $T$ is not invertible.</p>
<p>(b) Clearly $D$ is a function from $F[x]$ to $F[x]$. We must show $D$ is linear.<br>\begin{align*} D\left(\sum_{i=0}^nc_ix^i+\sum_{i=0}^nc’_ix^i\right)=&amp;\ D\left(\sum_{i=0}^n(c_i+c’_i)x^i\right)\\=&amp;\ \sum_{i=1}^ni(c_i+c’_i)x^{i-1}=\sum_{i=1}^n(ic_ix^{i-1}+ic’_ix^{i-1})\\=&amp;\ D\left(\sum_{i=0}^nc_ix^i\right)+D\left(\sum_{i=0}^nc’_ix^i\right)\end{align*}and<br>\begin{align*}D\left(r\sum_{i=0}^nc_ix^i\right)=&amp;\ D\left(\sum_{i=0}^nrc_ix^i\right)<br>=\sum_{i=1}^nrc_ix^{i-1}\\<br>=&amp;\ r\sum_{i=1}^nc_ix^{i-1}<br>=r\cdot D\left(\sum_{i=0}^nc_ix^i\right).\end{align*}Thus $D$ is linear.</p>
<p>Suppose $f(x)=\sum_{i=0}^nc_ix^i$ is in the null space of $D$. Then<br>$$D(f)=\sum_{i=1}^nic_ix^{i-1}=0.$$ A polynomial is zero if and only if every coefficient is zero. Thus it must be that $0=c_1=c_2=c_3=\cdots$. So it must be that $f(x)=c_0$ a constant polynomial. Thus the null space of $D$ contains the constant polynomials. Since $D(f)=0$ for all constant polynomials, the null space of $D$ consists of exatly the constant polynomials.</p>
<p>(c)Note that$$D\left(T\left(\sum_{i=0}^nc_ix^i\right)\right)=D\left(\sum_{i=0}^n\frac{c_i}{1+i}x^{i+1}\right).$$The first non-zero term of this sum is the linear term $c_0x$. Thus when we apply $D$ the sum still starts at zero:<br>$$=\sum_{i=0}^n(i+1)\frac{c_i}{1+i}x^{i+1-1}=\sum_{i=0}^nc_ix^i.$$Thus<br>$$D\left(T\left(\sum_{i=0}^nc_ix^i\right)\right)=\sum_{i=0}^nc_ix^i.$$Thus $DT=I$.</p>
<p>Let $f(x)=1$. Then $TD(f)=T(D(f))=T(0)=0$. Thus $TD(1)\not=1$. Thus $TD\not=I$.</p>
<p>(d) This follows rather easily from part (e). And likewise (e) follows rather easily from (d). Thus one can derive (d) straight from the definition of $T$ and then derive (e) from it, or one can derive (e) straight from the definition of $D$ and then derive (d) from it. I’ve chosen to do the latter.</p>
<div class="note info flat"><p>Integration by part.</p>
</div>

<p>In part (e) below the product formula is proven straight from the definition. So we will use it here to prove this part. In particular, we apply the product formula from part (e) to $(Tf)(Tg)$<br>$$D[(Tf)(Tg)]=(Tg)D(Tf)+(Tf)D(Tg).$$By part (c) $DT=I$ so this is equivalent to<br>$$D[(Tf)(Tg)]=f(Tg)+(Tf)g.$$Thus<br>$$D[(Tf)(Tg)]-f(Tg)=(Tf)g.$$Now apply $T$ to both sides<br>$$T\left(\rule{0mm}{4mm}D[(Tf)(Tg)]-f(Tg)\right)=T((Tf)g).$$Since $T$ is a linear transformation this is equivalent to<br>$$T\left(\rule{0mm}{4mm}D[(Tf)(Tg)]\right)-T[f(Tg)]=T((Tf)g).$$We showed in part (c) that $TD\not=I$, however if $f$ has constant term equal to zero then in fact $T(D(f))$ does equal $f$. Now $Tf$ and $Tg$ have constant term equal to zero, so $(Tf)(Tg)$ has constant term zero, thus<br>$$T\left(\rule{0mm}{4mm}D[(Tf)(Tg)]\right)=(Tf)(Tg).$$Thus<br>$$(Tf)(Tg)-T[f(Tg)]=T((Tf)g).$$(e) I believe they are after the product formula here:<br>\begin{equation}<br>D(fg)=fD(g)+gD(f).<br>\label{abbdwefe}<br>\end{equation}We prove this by brute force appealing just to the definition and to the product formula for polynomials. Let $f(x)=\sum_{i=0}^nc_ix^i$ and $g(x)=\sum_{i=0}^md_ix^i$. Then using the product formula (4-8) on page 121 we have<br>$$D(fg)=D\left(\sum_{i=0}^nc_ix^i\sum_{i=0}^md_ix^i\right)<br>=D\left(\sum_{i=0}^{n+m}\left(\sum_{j=0}^ic_jd_{i-j}\right)x^i\right)$$And using the linearity of the differentiation operator $D$ this equals<br>\begin{equation}<br>\sum_{i=0}^{n+m}i\left(\sum_{j=0}^ic_jd_{i-j}\right)x^{i-1}.<br>\label{j203r2}<br>\end{equation}Now we write down the sum for the right hand side of (\ref{abbdwefe}):<br>$$fD(g)+gD(f)$$\begin{equation}<br>=\sum_{i=0}^nc_ix^i\sum_{i=1}^mid_ix^{i-1} + \sum_{i=1}^nic_ix^{i-1}\sum_{i=0}^md_ix^i.<br>\label{f320r}<br>\end{equation}Consider<br>$$x\cdot\sum_{i=0}^nc_ix^i\sum_{i=1}^mid_ix^{i-1}.$$This equals<br>$$\sum_{i=0}^nc_ix^i\sum_{i=1}^mid_ix^i$$and since $0d_0=0$ we can write this as<br>$$\sum_{i=0}^nc_ix^i\sum_{i=0}^mid_ix^i.$$It’s straightforward to apply (4-8) page 121 to this product. In (4-8) we let $f_i=c_i$ and $g_i=id_i$ and it equals<br>$$\sum_{i=0}^{m+n}\left(\sum_{j=0}^i(i-j)c_jd_{i-j}\right)x^i.$$ The constant terms is zero thus we can write it as<br>$$\sum_{i=1}^{m+n}\left(\sum_{j=0}^i(i-j)c_jd_{i-j}\right)x^i.$$And thus the sum<br>$$\sum_{i=0}^nc_ix^i\sum_{i=1}^mid_ix^{i-1}$$equals<br>$$\sum_{i=1}^{m+n}\left(\sum_{j=0}^i(i-j)c_jd_{i-j}\right)x^{i-1}.$$Similary the second sum is<br>$$\sum_{i=1}^{n+m}\left(\sum_{j=0}^ijc_jd_{i-j}\right)x^i.$$Thus (\ref{f320r}) does equal (\ref{j203r2}).</p>
<div class="note info flat"><p>Product rule for derivatives.</p>
</div>

<p>(f) Suppose $V$ is finite dimensional. Let $\{b_1,\cdots,b_n\}$ be a basis for $V$. Let $d=\max_{i=1,\cdots n} \deg(b_i)$. It follows from Theorem 1(v) and induction that the degree of a linear combination of polynomials is no larger than the max of the degress of the individual polynomials involved in the linear combination. Thus no element of $V$ has degree greater than $d$. Now let $f\in V$ be any non-zero element. Let $d’=\deg(f)$. Then $Tf$ has degree $d’+1$, $T^2f$ has degree $d’+2$, etc. Thus for some $n$, $\deg(T^nf)&gt;d$. If $T^nf\in V$ then this is a contradiction. Thus if $T^nf\in V$ for all $f\in V$ it must be that $V$ is not finite dimensional.</p>
<p>(g) Let $\{b_1,\cdots,b_n\}$ be a basis for $V$. Let $d=\max_{i=1,\cdots n} \deg(b_i)$. For any $f\in F[x]$, we know $$\deg(Df)&lt;\deg(f).$$ Thus $D^{d+1}b_i=0$ for all $i=1,\dots,n$. Since $D^{d+1}(b_i)=0$ for all elements of the basis $\{b_1,\dots,b_n\}$ it follows that $D^{d+1}(f)=0$ for all $f\in V$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Differentiation Operator</tag>
        <tag>Integration Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Greatest common divisor of $pf$ and $pg$ is $p$ if $f$ and $g$ are relatively prime</title>
    <url>/lahk/linear-algebra-exercise-4-5-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.1</strong></p>
<p>Let $p$ be a monic polynomial over the field $F$, and let $f$ and $g$ be relatively prime polynomials ovef $F$. Prove that the g.c.d. of $pf$ and $pg$ is $p$.</p>
<a id="more"></a>
<hr>
<p>Solution: We use the definition of g.c.d. in terms of ideals. Since gcd$(f,g)=1$, the ideal generated by $f$ and $g$ is the same as the ideal generated by $1$. In other words $fF[x]+gF[x]=F[x]$. Thus $$pfF[x]+pgF[x]=pF[x].$$ Since $p$ is monic by assumption, it follows that $p$ satisifes the definition of gcd$(f,g)$ in $F[x]$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Polynomials over $\mathbb C$ are relative prime iff they have no common root</title>
    <url>/lahk/linear-algebra-exercise-4-5-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.2</strong></p>
<p>Assuming the Fundamental Theorem of Algebra prove the following. If $f$ and $g$ are polynomials over the field of complex numbers, then g.c.d$(f,g)=1$ if and only if $f$ and $g$ have no common root.</p>
<a id="more"></a>
<hr>
<p>Solution: By the Fundamental Theorem of Algebra, we can factor $f$ and $g$ all the way to linear factors<br>$$f=(x-a_1)^{n_1}\cdots(x-a_k)^{n_k}$$$$g=(x-b_1)^{m_1}\cdots(x-b_{\ell})^{m_{\ell}}.$$The roots of $f$ are exactly $a_1,\dots,a_k$, the roots of $g$ are exactly $b_1,\dots,b_{\ell}$.If gcd$(f,g)=1$ then (by the comments at the top of page 137) $f$ and $g$ have no common factors, and therefore $a_i\not=b_j$ $\forall$ $i,j$. Thus (by Corollary 1, page 128) $f$ and $g$ have no common roots. And if $f$ and $g$ have no common roots then (by Corollary 1, page 128) none of the factors $(x-a_i)$ can equal any of the factors $(x-b_j)$. Thus gcd$(f,g)=1$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Polynomials and its derivative over $\mathbb C$ are relative prime iff it does not have multiple roots</title>
    <url>/lahk/linear-algebra-exercise-4-5-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.3</strong></p>
<p>Let $D$ be the differentiation operator on the space of polynomials over the field of complex numbers. Let $f$ be a monic polynomial over the field of complex numbers. Prove that<br>$$f=(x-c_1)\cdots(x-c_k)$$ where $c_1,\dots,c_k$ are distinct complex numbers if and only if $f$ and $Df$ are relatively prime. In other words, $f$ has no repeated roots if and only if $f$ and $Df$ have no common root. (Assume the Fundamental Theorem of Algebra.)</p>
<a id="more"></a>
<hr>
<p>Solution: First assume all $c_i$’s are distinct. Then by Theorem 11, page 137, we know $f$ and $Df$ are relatively prime.</p>
<p>Now assume $f$ and $f’$ are relatively prime. Then again by Theorem 11 we know $f$ is a product of distinct irreducibles. Since $\mathbb C$ is algebraically closed each of those irreducibles must be of the form $x-a$. It follows that $f$ must be of the form $(x-c_1)\cdots(x-c_n)$ for distinct $c_1,\dots,c_n$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Derivative</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Generalization of Taylor’s formula for composition of polynomials</title>
    <url>/lahk/linear-algebra-exercise-4-5-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.4</strong></p>
<p>Prove the following generalization of Taylor’s formula. Let $f$, $g$, and $h$ be polynomials over a subfield of the complex numbers, with $\deg f\leq n$. Then<br>$$f(g)=\sum_{k=0}^n\frac{1}{k!}f^{(k)}(h)(g-h)^k.$$(Here $f(g)$ denotes ‘$f$ of $g$.’)</p>
<a id="more"></a>
<hr>
<p>Solution: Since we are working over the base field $\mathbb C$ by Theorem 3 page 126 there is a natural isomorphism between the algebra $\mathbb C[x]$ and the algebra of polynomial functions from $\mathbb C$ into $\mathbb C$. Taylor’s Theorem is therefore also a theorem about polynomial functions from $\mathbb C$ to $\mathbb C$. So we may plug any complex numbers we want in for $x$ and $c$ in the statement of Taylor’s Theorem and the equality remains valid. In particular we can subsitute $g$ in for $x$ and $h$ in for $c$ to obtain the desired formula. We then simply translate over to the algebra $\mathbb C[x]$ via the isomorphism in Theorem 3 to obtain the corresponding result in $\mathbb C[x]$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Taylor Series</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Congruence modulo $p$ is an equivalence relation</title>
    <url>/lahk/linear-algebra-exercise-4-5-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.5</strong></p>
<p>For the remaining exercises, we shall need the following definition. If $f$, $g$, and $p$ are polynomials over the field $F$ with $p\not=0$, we say $f$ <strong>is congruent to $g$ modulo</strong> $p$ if $(f-g)$ is divisible by $p$. If $f$ is congruent to $g$ modulo $p$, we write $$f\equiv g\pmod p.$$</p>
<a id="more"></a>
<hr>
<p>Prove for any non-zero polynomial $p$, that congruence modulo $p$ is an equivalence relation.</p>
<p>(a) It is reflexive: $f\equiv f\pmod p$.  </p>
<p>(b) It is symmetric: if $f\equiv g\pmod p$, then $g\equiv f\pmod p$.  </p>
<p>(c) It is transitive: if $f\equiv g\pmod p$ and $g\equiv h\pmod p$, then $f\equiv h\pmod p$.</p>
<hr>
<p>Solution:</p>
<p>(a). In this case $p$ must divide $f-f$ which equals zero. But everything divides zero. Just take $d=0$ and then $p=d(f-f)$. Thus $f\equiv f\pmod p$ is always true.</p>
<p>(b). Assume $f\equiv g\pmod p$. Then $p$ divides $f-g$. Thus $\exists$ $d$ s.t. $f-g=pd$. Let $d’=-d$. Then $g-f=pd’$ thus $p$ divides $g-f$. Thus $g\equiv f\pmod p$.</p>
<p>(c). Assume $f\equiv g\pmod p$ and $g\equiv h\pmod p$. Then $\exists$ $d$ and $d^\dagger$ such that $f-g=pd$ and $g-h=pd^\dagger$. Adding these two equations gives $f-h=pd+pd^\dagger$. Let $d^\top=d+d^\dagger$. Then $f-h=pd^\top$. Thus $f\equiv h\pmod p$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Equivalence Relation</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of congruence modulo (1)</title>
    <url>/lahk/linear-algebra-exercise-4-5-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.6</strong></p>
<p>Suppose $f\equiv g\pmod p$ and $f_1\equiv g_1\pmod p$.</p>
<p>(a) Prove that $f+f_1\equiv g+g_1\pmod p$.  </p>
<p>(b) Prove that $ff_1\equiv gg_1\pmod p$.</p>
<a id="more"></a>
<hr>
<p>For the remaining exercises, we shall need the following definition. If $f$, $g$, and $p$ are polynomials over the field $F$ with $p\not=0$, we say $f$ <strong>is congruent to $g$ modulo</strong> $p$ if $(f-g)$ is divisible by $p$. If $f$ is congruent to $g$ modulo $p$, we write $$f\equiv g\pmod p.$$</p>
<hr>
<p>Solution:</p>
<p>(a) By assumption there are polynomials $d$ and $d^\dagger$ such that $f-g=pd$ and $f_1-g_1=pd^\dagger$. Adding these two equations gives $$f+f_1-g-g_1=pd+pd^\dagger.$$ Or equivalently $$(f+f_1)-(g+g_1)=p(d+d^\dagger).$$ Thus $f+f_1\equiv g+g_1\pmod p$.</p>
<p>(b) By assumption there are polynomials $d$ and $d^\dagger$ such that $f-g=pd$ and $f_1-g_1=pd^\dagger$. Now \begin{align*}ff_1-gg_1&amp;=ff_1-g_1f+g_1f-gg_1\\&amp;=f(f_1-g_1)+g_1(f-g)\\&amp;=fpd^\dagger+g_1pd=p(fd^\dagger+g_1d).\end{align*} Thus $p$ divides $ff_1-gg_1$. Thus $ff_1\equiv gg_1\pmod p$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of congruence modulo (2)</title>
    <url>/lahk/linear-algebra-exercise-4-5-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.7</strong></p>
<p>Use <a href="/hoffman-kunze/linear-algebra-exercise-4-5-6.html">Exercise 6</a> to prove the following. If $f$, $g$, and $p$ are polynomials over the field $F$ and $p\not=0$, and if $f\equiv g\pmod p$, then $h(f)\equiv h(g)\pmod p$.</p>
<a id="more"></a>
<hr>
<p>For the remaining exercises, we shall need the following definition. If $f$, $g$, and $p$ are polynomials over the field $F$ with $p\not=0$, we say $f$ <strong>is congruent to $g$ modulo</strong> $p$ if $(f-g)$ is divisible by $p$. If $f$ is congruent to $g$ modulo $p$, we write $$f\equiv g\pmod p.$$</p>
<hr>
<p>Solution: It follows from <a href="/hoffman-kunze/linear-algebra-exercise-4-5-6.html">Exercise 6</a> part (b) that $f\equiv g\pmod p$ $\Rightarrow$ $f^2\equiv g^2\pmod p$ (since $f\equiv g\pmod p$ and $f\equiv g\pmod p$). By induction $f^n\equiv g^n\pmod p$ for all $n=1,2,3,\dots$. </p>
<p>Let $c\in F$. Then letting $f_1=g_1=c$ we get $cf\equiv cg\pmod p$ for any $c\in F$. Thus if $h(x)=cx^n$ we have shown the result is true. Thus the result is true for all monomials. </p>
<p>Now we can obtain the result on the sum of monomials using part (a) of <a href="/hoffman-kunze/linear-algebra-exercise-4-5-6.html">Exercise 6</a>. Since the general $h$ is a sum of monomials, the general result follows.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Properties of congruence modulo and irreducible polynomial</title>
    <url>/lahk/linear-algebra-exercise-4-5-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 4.5 Exercise 4.5.8</strong></p>
<p>If $p$ is an irreducible polynomial and $fg\equiv 0\pmod p$, prove that either $f\equiv 0\pmod p$ or $g\equiv 0\pmod p$. Give an example which shows that this is false if $p$ is not irreducible.</p>
<a id="more"></a>
<hr>
<p>For the remaining exercises, we shall need the following definition. If $f$, $g$, and $p$ are polynomials over the field $F$ with $p\not=0$, we say $f$ <strong>is congruent to $g$ modulo</strong> $p$ if $(f-g)$ is divisible by $p$. If $f$ is congruent to $g$ modulo $p$, we write $$f\equiv g\pmod p.$$</p>
<hr>
<p>Solution: $fg\equiv0\pmod p$ implies $p$ divides $fg$. By the Corollary to Theorem 8, page 135, it follows that $p$ divides $f$ or $p$ divides $g$. Thus $f\equiv0\pmod p$ or $g\equiv0\pmod p$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Compute eigenvalues and corresponding eigenvectors</title>
    <url>/lahk/linear-algebra-exercise-6-2-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.1</strong></p>
<p>In each of the following cases, let $T$ be the linear operator on $\mathbb R^2$ which is represented by the matrix $A$ in the standard ordered basis for $\mathbb R^2$, and let $U$ be the linear operator on $\mathbb C^2$ represented by $A$ in the standard ordered basis. Find the characyteristic polynomial for $T$ and that for $U$, find the characteristic values of each operator, and for each such charactersistic value $c$ find a basis for the corresponding space of characteristic vectors.<br>$$A=\left[\begin{array}{cc}1&amp;0\\0&amp;0\end{array}\right],\quad\left[\begin{array}{cc}2&amp;3\\-1&amp;1\end{array}\right],\quad\left[\begin{array}{cc}1&amp;1\\1&amp;1\end{array}\right].$$</p>
<a id="more"></a>
<hr>
<p>Solution: We have</p>
<p>$$A=\left[\begin{array}{cc}1&amp;0\\0&amp;0\end{array}\right],\quad xI-A=\left[\begin{array}{cc}x-1&amp;0\\0&amp;x\end{array}\right]$$The characteristic polynomial equals $|xI-A|=x(x-1)$. So $c_1=0$, $c_1=1$. </p>
<p>A basis for $W_1$ is $\{(0,1)\}$, $\alpha_1=(0,1)$. A basis for $W_2$ is $\{(1,0)\}$, $\alpha_2=(1,0)$. This is the same whether the base field is $\mathbb R$ or $\mathbb C$ since the characteristic polynomial factors completely.</p>
<hr>
<p>We have$$A=\left[\begin{array}{cc}2&amp;3\\-1&amp;1\end{array}\right],\quad |xI-A|=\left|\begin{array}{cc}x-2&amp;-3\\1&amp;x-1\end{array}\right|$$<br>$=(x-2)(x-1)+3=x^2-3x+5$. This is a parabola opening up with vertex $(3/2,11/4)$. Thus there are no real roots. Using the quadratic formula $$c_1=\frac{3+\sqrt{11}i}{2}, \quad c_2=\frac{3-\sqrt{11}i}{2}.$$ To find the a characteristic vector for $c_1$ we solve<br>$$\left[\begin{array}{cc}\frac{-1+\sqrt{11}i}{2} &amp; 3\\ -1 &amp; \frac{1+\sqrt{11}i}{2}\end{array}\right]\left[\begin{array}{c} x\\y\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right].$$This gives the characteristic vector $\alpha_1=(\frac{1+\sqrt{11}i}{2},1)$.</p>
<p>To find the a characteristic vector for $c_2$ we solve<br>$$\left[\begin{array}{cc}\frac{-1-\sqrt{11}i}{2} &amp; 3\\ -1 &amp; \frac{1-\sqrt{11}i}{2}\end{array}\right]\left[\begin{array}{c} x\\y\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right].$$This gives the characteristic vector $\alpha_2=(\frac{1-\sqrt{11}i}{2},1)$.</p>
<hr>
<p>We have $$A=\left[\begin{array}{cc}1&amp;1\\1&amp;1\end{array}\right],$$$$|xI-A|=\left|\begin{array}{cc}x-1 &amp; 1\\ 1 &amp; x-1\end{array}\right|=(x-1)^2-1=x(x-2).$$ So $c_1=0$ for which $\alpha_1=(1,-1)$. And $c_2=2$ for which $\alpha_2=(1,1)$. This is the same in both $\mathbb R$ and $\mathbb C$ since the characteristic polynomial factors completely.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
      </tags>
  </entry>
  <entry>
    <title>Symmetric matrices are diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-2-10.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.10</strong></p>
<p>Suppose that $A$ is a $2\times2$ matrix with real entries which is symmetrix $(A^t=A)$. Prove that $A$ is similar over $\mathbb R$ to a diagonal matrix.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $A$ is symmetric, set $A=\left[\begin{array}{cc}a &amp; b\\b &amp; d\end{array}\right]$. So the characteristic polynomial is $$|xI-A|=\left|\begin{array}{cc}x-a &amp; -b\\ -b &amp; x-d\end{array}\right|=x^2-(a+d)x+ad-b^2.$$  If $b=0$ then $A$ is already diagonal. </p>
<p>If $b\not=0$ then the discriminant of the characteristic polynomial is $$\Delta=(a+d)^2-4(ad-b^2)=(a-d)^2+4b^2&gt;0.$$Hence there exist two distinct solutions to the characteristic polynomial. So we also have two distinct characteristic values for $A$. By <a href="/hoffman-kunze/linear-algebra-exercise-6-2-7.html">Exercise 7</a> $A$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Symmetric Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Structure of two by two nilpotent matrices</title>
    <url>/lahk/linear-algebra-exercise-6-2-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.11</strong></p>
<p>Let $N$ be a $2\times2$ complex matrix such that $N^2=0$. Prove that either $N=0$ or $N$ is similar over $\mathbb C$ to<br>$$\left[\begin{array}{cc}0 &amp; 0\\1 &amp; 0\end{array}\right].$$</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $N=\left[\begin{array}{cc}a &amp; b\\c &amp; d\end{array}\right]$. Now $N^2=0$ $\Rightarrow$ $\left[\begin{array}{c}a\\c\end{array}\right]$, $\left[\begin{array}{c}b\\d\end{array}\right]$ are characteristic vectors (if non-zero) for the characteristic value $0$. If $\left[\begin{array}{c}a\\c\end{array}\right]$, $\left[\begin{array}{c}b\\d\end{array}\right]$ are linearly independent then $W_1$ has rank two and $N$ is diagonalizable to $\left[\begin{array}{cc}0 &amp; 0\\0 &amp; 0\end{array}\right]$. If $PNP^{-1}=0$ then $N=P^{-1}0P=0$ so in this case $N$ itself is the zero matrix. This contradicts the assumption that $\left[\begin{array}{c}a\\c\end{array}\right]$, $\left[\begin{array}{c}b\\d\end{array}\right]$ are linearly independent.</p>
<p>So we can assume that $\left[\begin{array}{c}a\\c\end{array}\right]$, $\left[\begin{array}{c}b\\d\end{array}\right]$ are linearly dependent. If both equal the zero vector then $N=0$. So we can assume at least one vector is non-zero. If $\left[\begin{array}{c}b\\d\end{array}\right]$ is the zero vector then $N=\left[\begin{array}{cc}a &amp; 0 \\ c &amp; 0\end{array}\right]$. So $N^2=0$ $\Rightarrow$ $a^2=0$ $\rightarrow$ $a=0$. Thus $N=\left[\begin{array}{cc}a &amp; 0 \\ c &amp; 0\end{array}\right]$. In this case $N$ is similar to $N =\left[\begin{array}{cc}0 &amp; 0 \\ 1 &amp; 0\end{array}\right]$ via the matrix $P=\left[\begin{array}{cc}c &amp; 0 \\ 0 &amp; 1\end{array}\right]$. Similary if $\left[\begin{array}{c}a\\c\end{array}\right]$ is the zero vector, then $N^2=0$ implies $d^2=0$ implies $d=0$ so $N=\left[\begin{array}{cc}0 &amp; b \\ 0 &amp; 0\end{array}\right]$. In this case $N$ is similar to $N=\left[\begin{array}{cc}0 &amp; 0 \\ b &amp; 0\end{array}\right]$ via the matrix $P=\left[\begin{array}{cc}0&amp;1\\1&amp;0\end{array}\right]$, which is simiilar to $\left[\begin{array}{cc}0 &amp; 0 \\ 1 &amp; 0\end{array}\right]$ as above.</p>
<p>By the above we can assume neither $\left[\begin{array}{c}a\\c\end{array}\right]$ or $\left[\begin{array}{c}b\\d\end{array}\right]$ is the zero vector. Since they are linearly dependent we can assume $\left[\begin{array}{c}b\\d\end{array}\right]=x\left[\begin{array}{c}a\\c\end{array}\right]$ so $N=\left[\begin{array}{cc}a &amp; ax \\ c &amp; cx\end{array}\right]$. So $N^2=0$ implies<br>$$a(a+cx)=0,\quad c(a+cx)=0,$$$$ax(a+cx)=0,\quad cx(a+cx)=0.$$We know that at least one of $a$ or $c$ is not zero. If $a=0$ then since $c\not=0$ it must be that $x=0$. So in this case $N=\left[\begin{array}{cc}0 &amp; 0 \\ c &amp; 0\end{array}\right]$ which is similar to $\left[\begin{array}{cc}0 &amp; 0 \\ 1 &amp; 0\end{array}\right]$ as before. If $a\not=0$ then $x\not=0$ else $a(a+cx)=0$ implies $a=0$. Thus $a+cx=0$ so $N=\left[\begin{array}{cc} a &amp; ax\\ -a/x &amp; -a\end{array}\right]$. This is similar to $\left[\begin{array}{cc} a &amp; a\\ -a &amp; -a\end{array}\right]$ via $P=\left[\begin{array}{cc}\sqrt{x} &amp; 0\\0 &amp; 1/\sqrt{x}\end{array}\right]$. And $\left[\begin{array}{cc} a &amp; a\\ -a &amp; -a\end{array}\right]$ is similar to $\left[\begin{array}{cc} 0 &amp; 0\\ -a &amp; 0\end{array}\right]$ via $P=\left[\begin{array}{cc}-1 &amp; -1\\1 &amp; 0\end{array}\right]$. And this finally is similar to $\left[\begin{array}{cc}0 &amp; 0 \\ 1 &amp; 0\end{array}\right]$ as before.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Nilpotent Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Structure of general two by two matrices</title>
    <url>/lahk/linear-algebra-exercise-6-2-12.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.12</strong></p>
<p>Use the result of <a href="/hoffman-kunze/linear-algebra-exercise-6-2-11.html">Exercise 11</a> to prove the following: If $A$ is a $2\times2$ matrix with complex entries, then $A$ is similar over $\mathbb C$ to a matrix of one of the two types<br>$$\left[\begin{array}{cc}a &amp; 0\\ 0 &amp; b\end{array}\right]\quad\quad\left[\begin{array}{cc}a &amp; 0\\ 1 &amp; a\end{array}\right].$$</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $A=\left[\begin{array}{cc}a &amp; b\\c &amp; d\end{array}\right]$. Since the base field is $\Bbb C$ the characteristic polynomial $$p(x)=(x-c_1)(x-c_2).$$ If $c_1\not=c_2$ then $A$ is diagonalizable by <a href="/hoffman-kunze/linear-algebra-exercise-6-2-7.html">Exercise 7</a>. If $c_1=c_2$ then $p(x)=(x-c_1)^2$. If $W$ has dimension two then $A$ is diagonalizable by Theorem 2. Thus we will be done if we show that if $p(x)=(x-c_1)^2$ and $\dim(W_1)=1$ then $A$ is similar to $\left[\begin{array}{cc}a &amp; 0\\1 &amp; a\end{array}\right]$.</p>
<p>We will need the following three identities:<br>\begin{equation}<br>\left[\begin{array}{cc}a &amp; 0\\c &amp; d\end{array}\right]\sim\left[\begin{array}{cc}a &amp; 0\\1 &amp; d\end{array}\right]\quad\text{via $p=\left[\begin{array}{cc}c &amp; 0\\0 &amp; 1\end{array}\right]$}\label{eq2}<br>\end{equation}\begin{equation}<br>\left[\begin{array}{cc}a &amp; b\\c &amp; d\end{array}\right]\sim\left[\begin{array}{cc}a-b &amp; c-d\\b &amp; d\end{array}\right]\quad\text{via $p=\left[\begin{array}{cc}1 &amp; 0\\-1 &amp; 1\end{array}\right]$}<br>\label{eq3}<br>\end{equation}\begin{equation}<br>\left[\begin{array}{cc}a &amp; b\\c &amp; d\end{array}\right]\sim\left[\begin{array}{cc}a &amp; xb\\c/x &amp; d\end{array}\right]\quad\text{via $p=\left[\begin{array}{cc}\sqrt{x} &amp; 0\\0 &amp; 1/\sqrt{x}\end{array}\right]$ for $x\not=0$.}<br>\label{eq4}<br>\end{equation}Now we know in this case that $A$ is not diagonalizable. If $d\not=0$ then $\left[\begin{array}{cc}a &amp; b\\c &amp; d\end{array}\right]\sim\left[\begin{array}{cc}a &amp; bc/d\\d &amp; d\end{array}\right]$ by (\ref{eq4}) with $x=c/d$ and this in turn is similar to $\left[\begin{array}{cc}a-bc/d &amp; 0\\-a+2bc/d &amp; d\end{array}\right]$ by (\ref{eq3}).</p>
<p>Now we know the diagonal entries are the characteristic values, which are equal. Thus $a-\dfrac{bc}{d}=d$. So this equals $\left[\begin{array}{cc}d &amp; 0\\x &amp; d\end{array}\right]$ where $x=-a+\dfrac{2bc}{d}$ and we know $x\not=0$ since $A$ is not diagonalizable. Thus $A\sim\left[\begin{array}{cc}d &amp; 0\\1 &amp; d\end{array}\right]$ by (\ref{eq2}). Now suppose $d=0$. Then $$A=\left[\begin{array}{cc}a &amp; b\\c &amp;0\end{array}\right]\sim\left[\begin{array}{cc}0 &amp; c\\b &amp; a\end{array}\right]$$ via $p=\left[\begin{array}{cc}0 &amp; 1\\1 &amp; 0\end{array}\right]$. If $b=0$ then $A=\left[\begin{array}{cc}a &amp; 0\\c &amp; 0\end{array}\right]$ and again since $A$ has equal characteristic values it must be that $a=0$. So $A=\left[\begin{array}{cc}0&amp; 0\\c &amp; 0\end{array}\right]$ which is similar to $\left[\begin{array}{cc}0 &amp; 0\\1 &amp; 0\end{array}\right]$ via $P=\left[\begin{array}{cc}c &amp; 0\\0 &amp; 1\end{array}\right]$. So assume $b\not=0$. Then $A\sim\left[\begin{array}{cc}0 &amp; c\\b &amp; a\end{array}\right]$ and we can argue exact as above were $d\not=0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Similarity</tag>
      </tags>
  </entry>
  <entry>
    <title>Integration operator has no characteristic values</title>
    <url>/lahk/linear-algebra-exercise-6-2-13.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.13</strong></p>
<p>Let $V$ be the vector space of all functions from $\mathbb R$ into $\mathbb R$ which are continuous, i.e., the space of continuous real-valued functions on the real line. Let $T$ be the linear operator on $V$ defined by<br>$$(Tf)(x)=\int_0^xf(t)dt.$$Prove that $T$ has no characteristic values.</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $c$ is a characteristic value of $T$, then there exists a non-zero continuous function $f(x)$ on $\mathbb R$ such that \[T(f)=cf(x),\quad\text{for all }x\in \mathbb R.\]That is\[cf(x)=\int_{0}^xf(x)dx\]for all $x\in \mathbb R$. Define a function\[F(x)=\int_0^xf(x)dx.\]Then $F(x)$ is differentiable on $\mathbb R$ and $F’(x)=f(x)$ by fundamental theorem of calculus. Moreover, $F(0)=0$. Therefore, we have\[cF’(x)=F(x).\]If $c=0$, then $F(x)\equiv 0$ and hence $f(x)=\equiv 0$ which is impossible by assumption. Thus $c\ne 0$, we must have\[\left(e^{-x/c}F(x)\right)’=-e^{-x/c}(F(x)-cF’(x))/c=0.\]Hence $e^{-x/c}F(x)$ is a constant, namely $F(x)=ke^{x/c}$. However, because $F(0)=0$, we have $k=0$. Therefore $F(x)\equiv 0$ and we obtain a contradiction again. Therefore $T$ has no characteristic values.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Integration Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Matrices commute with a diagonal block matrix</title>
    <url>/lahk/linear-algebra-exercise-6-2-14.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.14</strong></p>
<p>Let $A$ be an $n\times n$ diagonal matrix with characteristic polynomial<br>$$(x-c_1)^{d_1}\cdots(x-c_k)^{d_k},$$ where $c_1,\dots,c_k$ are distinct. Let $V$ be the space of $n\times n$ matrices $B$ such that $AB=BA$. Prove that the dimension of $V$ is $d_1^2+\cdots+ d_k^2$.</p>
<a id="more"></a>
<hr>
<p>Solution: Write<br>$$A=\left[\begin{array}{cccc}<br>c_1I &amp; &amp; &amp; \\<br>&amp; c_2I &amp; \Large 0 &amp;\\<br>&amp; \Large 0 &amp; \ddots &amp; \\<br>&amp; &amp; &amp; c_kI\end{array}\right].$$Write<br>$$B=\left[\begin{array}{cccc}<br>B_{11} &amp; B_{12} &amp; \cdots &amp; B_{1k}\\<br>B_{21} &amp; B_{22} &amp; \cdots &amp; B_{2k}\\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\<br>B_{k1} &amp; B_{k2} &amp; \cdots &amp; B_{kk}\\<br>\end{array}\right]$$where $B_{ij}$ has dimenson $d_i\times d_j$. Then $AB=BA$ implies<br>$$<br>\left[\begin{array}{cccc}<br>c_1B_{11} &amp; c_1B_{12} &amp; \cdots &amp; c_1B_{1k}\\<br>c_2B_{21} &amp; c_2B_{22} &amp; \cdots &amp; c_2B_{2k}\\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\<br>c_kB_{kk} &amp; c_kB_{k2} &amp; \cdots &amp; c_kB_{kk}\\<br>\end{array}\right]<br>=<br>\left[\begin{array}{cccc}<br>c_1B_{11} &amp; c_2B_{12} &amp; \cdots &amp; c_kB_{1k}\\<br>c_1B_{21} &amp; c_2B_{22} &amp; \cdots &amp; c_kB_{2k}\\<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\<br>c_1B_{k1} &amp; c_2B_{k2} &amp; \cdots &amp; c_kB_{kk}\\<br>\end{array}\right]<br>$$Thus $c_i\not=c_j$ for $i\not=j$ implies $B_{ij}=0$ for $i\not=j$, while $B_{11},B_{22},\dots,B_{kk}$ can be arbitrary. The dimension of $B_{ii}$ is therefore $d_i^2$ thus the dimension of the space of all such $B_{ii}$’s is $d_1^2+d_2^2+\cdots+d_k^2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Linear operator induced by left multiplication by a matrix</title>
    <url>/lahk/linear-algebra-exercise-6-2-15.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.15</strong></p>
<p>Let $V$ be the space of $n\times n$ matrices over $F$. Let $A$ be a fixed $n\times n$ matrix over $F$. Let $T$ be the linear operator <em>left multiplication by</em> $A$ on $V$. Is it true that $A$ and $T$ have the same characteristic values?</p>
<a id="more"></a>
<hr>
<p>Solution: Yes. Represent an element of $V$ as a column vector by stacking the columns of $V$ on top of each other, with the first column on top. Then the matrix for $T$ is given by $$\left[\begin{array}{cccc}A &amp; &amp; &amp; \\&amp; A &amp; \Large 0 &amp; \\ &amp; \Large 0 &amp; \ddots &amp; \\ &amp; &amp; &amp; A\end{array}\right].$$ By the argument on page 157 the determinant of this matrix is $\det(A)^n$. Similarly if $p$ is the characteristic polynomial of $A$ then $p^n$ is the characteristic polynomial of $T$. Thus they have exactly the same roots and thus they have exactly the same characteristic values.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Characteristic Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Characteristic polynomials of identity and zero operators</title>
    <url>/lahk/linear-algebra-exercise-6-2-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.2</strong></p>
<p>Let $F$ be an $n$-dimensional vector space over $F$. What is the characteristic polynomial of the identity operator on $V$? What is the characteristic polynomial for the zero operator?</p>
<a id="more"></a>
<hr>
<p>Solution: The identity operator can be represented by the $n\times n$ identity matrix $I$. The characteristic polynomial of the identity operator is therefore $(x-1)^n$. </p>
<p>The zero operator is represented by the zero matrix in any basis. Thus the characteristic polynomial of the zero operator is $x^n$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Characteristic Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Characteristic polynomialx of diagonal matrices</title>
    <url>/lahk/linear-algebra-exercise-6-2-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.3</strong></p>
<p>Let $A$ be an $n\times n$ triangular matrix over the field $F$. Prove that the characteristic values of $A$ are the diagonal entries of $A$, i.e., the scalars $A_{ii}$.</p>
<a id="more"></a>
<hr>
<p>Solution: The determinant of a triangular matrix is the product of the diagonal entries. Thus $$|xI-A|=\prod(x-a_{ii}).$$Hence the characteristic values of $A$ are the diagonal entries of $A$, i.e., the scalars $A_{ii}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Characteristic Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>A matrix is diagonalizable over $\mathbb C$ but not over $\mathbb R$</title>
    <url>/lahk/linear-algebra-exercise-6-2-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.4</strong></p>
<p>Let $T$ be the linear operator of $\mathbb R^3$ which is represented in the standard ordered basis by the matrix<br>$$\left[\begin{array}{ccc}-9 &amp; 4 &amp; 4\\-8 &amp; 3 &amp; 4\\-16 &amp; 8 &amp; 7\end{array}\right].$$Prove that $T$ is diagonalizable by exhibiting a basis for $\mathbb R^3$, each vector fo which is a characteristic vector of $T$.</p>
<a id="more"></a>
<hr>
<p>Solution: We have \begin{align*}|xI-A|=&amp;\ \left|\begin{array}{ccc}x+9 &amp; -4 &amp; -4\\8 &amp; x-3 &amp; -4\\16 &amp; -8 &amp; x-7\end{array}\right|\\=&amp;\ \left|\begin{array}{ccc}x+9 &amp; 0 &amp; -4\\8 &amp; x+1 &amp; -4\\16 &amp; -x-1 &amp; x-7\end{array}\right|\\=&amp;\ (x+1)\left|\begin{array}{ccc}x+9 &amp; 0 &amp; -4\\8 &amp; 1 &amp; -4\\16 &amp; -1 &amp; x-7\end{array}\right|\\=&amp;\ (x+1)\left|\begin{array}{ccc}x+9 &amp; 0 &amp; -4\\8 &amp; 1 &amp; -4\\24 &amp; 0 &amp; x-11\end{array}\right|\\=&amp;\ (x+1)\left|\begin{array}{cc}x+9 &amp; -4\\24 &amp; x-11\end{array}\right|\\=&amp;\ (x+1)[(x+9)(x-11)+96]\\=&amp;\ (x+1)(x^2-2x-3)\\=&amp;\ (x+1)(x-3)(x+1)\\= &amp;\ (x+1)^2(x-3).\end{align*} Thus $c_1=-1$, $c_2=3$. </p>
<p>For $c_1$, $xI-A$ equals<br>$$=\left[\begin{array}{ccc}8 &amp; -4 &amp; -4\\8 &amp; -4 &amp; -4\\16 &amp; -8 &amp; -8\end{array}\right]$$<br>This matrix evidently has rank one. Thus the null space has rank two. The two characteristic vectors $(1,2,0)$ and $(1,0,2)$ are independent, so they form a basis for $W_1$. </p>
<p>For $c_2$, $xI-A$ equals<br>$$=\left[\begin{array}{ccc}-12 &amp; -4 &amp; -4\\8 &amp; 0 &amp; -4\\16 &amp; -8 &amp; -4\end{array}\right]$$This is row equivalent to<br>$$=\left[\begin{array}{ccc}1 &amp; -0&amp; -1/2\\0&amp; 1 &amp; -1/2\\0 &amp; 0 &amp; 0\end{array}\right]$$Thus the null space one dimensional and is given by $(z/2,z/2,z)$. So $(1,1,2)$ is a characteristic vector and a basis for $W_2$. By Theorem 2 (ii) $T$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>A matrix is diagonalizable over $\mathbb C$ but not over $\mathbb R$</title>
    <url>/lahk/linear-algebra-exercise-6-2-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.5</strong></p>
<p>Let<br>$$A=\left[\begin{array}{ccc}6&amp; -3 &amp; -2\\4 &amp; -1 &amp; -2\\10 &amp; -5 &amp; -3\end{array}\right].$$Is $A$ similar over the field $\mathbb R$ to a diagonal matrix? Is $A$ similar over the field $\mathbb C$ to a diagonal matrix?</p>
<a id="more"></a>
<hr>
<p>Solution: \begin{align*}|xI-A|=&amp;\ \left|\begin{array}{ccc}x-6&amp; 3 &amp; 2\\-4 &amp; x+1 &amp; 2\\-10 &amp; 5 &amp; x+3\end{array}\right|\\=&amp;\ \left|\begin{array}{ccc}x-6&amp; 3 &amp; 2\\-x+2 &amp; x-2 &amp; 0\\-10 &amp; 5 &amp; x+3\end{array}\right|\\=&amp;\ (x-2)\left|\begin{array}{ccc}x-6&amp; 3 &amp; 2\\-1 &amp; 1 &amp; 0\\-10 &amp; 5 &amp; x+3\end{array}\right|\\=&amp;\ (x-2)\left|\begin{array}{ccc}x-3&amp; 3 &amp; 2\\0 &amp; 1 &amp; 0\\-5 &amp; 5 &amp; x+3\end{array}\right|\\=&amp;\ (x-2)((x-3)(x+3)+10)\\ =&amp;\ (x-2)(x^2+1).\end{align*} Since this is not a product of linear factors over $\mathbb R$, by Theorem 2, page 187, $A$ is not diagonalizable over $\mathbb R$. </p>
<p>Over $\mathbb C$ this factors to $(x-2)(x-i)(x+i)$. Thus over $\mathbb C$ the matrix $A$ has three distinct characteristic values. The space of characteristic vectors for a given characteristic value has dimension at least one. Thus the sum of the dimensions of the $W_i$’s must be at least $3$. It cannot be greater than $3$ so it must equal $3$ exactly. Thus $A$ is diagonalizable over $\mathbb C$.</p>
<div class="note info flat"><p>See <a href="/hoffman-kunze/linear-algebra-exercise-6-2-7.html">Exercise 7</a> for more general setting.</p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>A nilpotent matrix is diagonalizable if and only if it is zero</title>
    <url>/lahk/linear-algebra-exercise-6-2-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.6</strong></p>
<p>Let $T$ be the linear operator on $\mathbb R^4$ which is represented in the standard ordered basis by the matrix<br>$$\left[\begin{array}{cccc}0 &amp; 0 &amp; 0 &amp; 0 \\ a &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; b &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; c &amp; 0 \end{array}\right].$$<br>Under what conditions on $a$, $b$, and $c$ is $T$ diagonalizable?</p>
<a id="more"></a>
<hr>
<p>Solution: We have$$|xI-A|=\left|\begin{array}{cccc}x &amp; 0 &amp; 0 &amp; 0 \\ -a &amp; x &amp; 0 &amp; 0\\ 0 &amp; -b &amp; x &amp; 0 \\ 0 &amp; 0 &amp; -c &amp; x \end{array}\right|=x^4.$$Therefore there is only one characteristic value $c_1=0$. Thus $c_1I-A=A$ and $W_1$ is the null space of $A$. So if $A$ is diagonalizable then $\dim(W)=4$. This implies that $A$ is the zero matrix and hence $$a=b=c=0.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Nilpotent Matrix</tag>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Operator with $n$ distinct characteristic values is diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-2-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.7</strong></p>
<p>Let $T$ be the linear operator on the $n$-dimensional vector space $V$, and suppose that $T$ has $n$ distinct characteristic values. Prove that $T$ is diagonalizable.</p>
<a id="more"></a>
<hr>
<p>Solution: The space of characteristic vectors for a given characteristic value has dimension at least one. Thus the sum of the dimensions of the $W_i$’s must be at least $n$. By the lemma on page 186, this sum is no more than the dimension of $V$ and hence it cannot be greater than $n$. Therefore it must equal $n$ exactly. Thus by Theorem 2, $T$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>$I-AB$ is invertible if and only if $I-BA$ is invertible</title>
    <url>/lahk/linear-algebra-exercise-6-2-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.8</strong></p>
<p>Let $A$ and $B$ be $n\times n$ matrices over the field $F$. Prove that if $(I-AB)$ is invertible, then $I-BA$ is invertible and<br>$$(I-BA)^{-1}=I+B(I-AB)^{-1}A.$$</p>
<a id="more"></a>
<hr>
<p>Solution: We have \begin{align*} &amp;\ (I-BA)(I+B(I-AB)^{-1}A)\\ =&amp;\ I-BA+B(I-AB)^{-1}A-BAB(I-AB)^{-1}A\\ =&amp;\ I-B(A-(I-AB)^{-1}A+AB(I-AB)^{-1}A)\\ =&amp;\ I-B(I-(I-AB)^{-1}+AB(I-AB)^{-1}A\\ =&amp;\ I-B(I-(I-AB)(I-AB)^{-1})A\\ =&amp;\ I-B(I-I)A=I. \end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Inverse</tag>
      </tags>
  </entry>
  <entry>
    <title>$AB$ and $BA$ have precisely the same characteristic values</title>
    <url>/lahk/linear-algebra-exercise-6-2-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.2 Exercise 6.2.9</strong></p>
<p>Use the result of <a href="/hoffman-kunze/linear-algebra-exercise-6-2-8.html">Exercise 8</a> to prove that, if $A$ and $B$ are $n\times n$ matrices over the field $F$, then $AB$ and $BA$ have precisely the same characteristic values in $F$.</p>
<a id="more"></a>
<hr>
<p>Solution: By Theorem 3, page 154, $\det(AB)=\det(A)\det(B)$. Thus $AB$ is singular iff $BA$ is singular. Therefore $0$ is a characteristic values of $AB$ iff $0$ is a characteristic value of $BA$. </p>
<p>Now condier the characteristic value $c$ of $AB$ whic is not equal to zero. Then $$|cI-AB|=0 \Leftrightarrow c^n\left|I- \frac1c AB\right| =0$$ by <a href="/hoffman-kunze/linear-algebra-exercise-6-2-8.html">Exercise 8</a> it is equivalent to $$c^n\left|I- \frac1c BA\right|=0 \Leftrightarrow |cI-BA|=0.$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
      </tags>
  </entry>
  <entry>
    <title>Minimal polynomials for identity operator and zero operator</title>
    <url>/lahk/linear-algebra-exercise-6-3-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.3 Exercise 6.3.1</strong></p>
<p>Let $V$ be a finite-dimensional vector space. What is the minimal polynomial for the identity operator on $V$? What is the minimal polynomial for the zero operator?</p>
<a id="more"></a>
<hr>
<p>Solution: </p>
<p>The minimal polynomial for the identity operator is $x-1$. It annihilates the identity operator and the monic zero degree polynomial $p(x)=1$ does not, so it must be the minimal polynomial. </p>
<p>The minimal polynomial for the zero operator is $x$. It is a monic polynomial that annihilates the zero operator and again the monic zero degree polynomial $p(x)=1$ does not, so it must be the minimal polynomial.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Minimal and characteristic polynomials of a Companion Matrix</title>
    <url>/lahk/linear-algebra-exercise-6-3-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.3 Exercise 6.3.2</strong></p>
<p>Let $a,b$ and $c$ be tlements of a field $F$, and let $A$ be the following $3\times3$ matrix over $F$:<br>$$A=\left[\begin{array}{ccc}0 &amp; 0 &amp; c\\1 &amp; 0 &amp; b\\ 0 &amp; 1 &amp; a\end{array}\right].$$Prove that the characteristic polynomial for $A$ is $x^3-ax^2-bx-c$ and that this is also the minimal polynomial for $A$.</p>
<a id="more"></a>
<hr>
<p>Solution: The characteristic polynomial is<br>\begin{align*}\left|\begin{array}{ccc} x &amp; 0 &amp; -c\\-1 &amp; x &amp; -b\\0 &amp; -1 &amp; x-a\end{array}\right|=&amp;\ \left|\begin{array}{ccc} x &amp; 0 &amp; -c\\-1 &amp; 0 &amp; x^2-ax-b\\0 &amp; -1 &amp; x-a\end{array}\right|\\ =&amp;\ 1\cdot\left|\begin{array}{cc}x &amp; -c\\ -1 &amp; x^2-ax-b\end{array}\right|\\= &amp;\ x^3-ax^2-bx-c.\end{align*}Now for any $r,s\in F$<br>$$A^2+rA+s=\left[\begin{array}{ccc}0 &amp; c &amp; ac\\0 &amp; b &amp; c+ba\\1 &amp; a &amp; b+a^2\end{array}\right] + \left[\begin{array}{ccc}0 &amp; 0 &amp; rc\\r&amp; 0 &amp;rb\\0 &amp; r&amp; ra\end{array}\right] + \left[\begin{array}{ccc}s &amp; 0&amp; 0\\0 &amp; s &amp; 0\\0 &amp; 0 &amp; s\end{array}\right]$$$$=\left[\begin{array}{ccc}s &amp; c &amp; ac+rc\\r &amp; b +s&amp; c+ba+br\\1 &amp; a+r &amp; b+a^2+ra+s\end{array}\right]\not=0.$$Thus $f(A)\not=0$ for all $f\in F[x]$ such that $\deg(F)=2$. Thus the minimal polynomial cannot have degree two. The minimal polynomial also cannot be a polynomial of degree one. It follows from Theorem 4 that minimal polynomial divides the charactersitc polynomial. Hence it must therefore have degree three (since it cannot be degree 1 or degree 2). Since it divides $x^3-ax^2-bx-c$ it must equal $x^3-ax^2-bx-c$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Charactersitc Polynomial</tag>
        <tag>Companion Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Minimal and characteristic polynomials of a Matrix</title>
    <url>/lahk/linear-algebra-exercise-6-3-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.3 Exercise 6.3.3</strong></p>
<p>Let $A$ be the $4\times4$ real matrix<br>$$\left[\begin{array}{cccc}1 &amp; 1 &amp; 0 &amp; 0\\<br>-1 &amp; -1 &amp; 0 &amp; 0\\<br>-2 &amp; -2 &amp; 2 &amp; 1\\<br>1 &amp; 1 &amp; -1 &amp; 0\end{array}\right].$$Show that the characteristic polynomial for $A$ is $x^2(x-1)^2$ and that it is also the minimal polynomial.</p>
<a id="more"></a>
<hr>
<p>Solution: The characteristic polynomial equals<br>\begin{align*}&amp;\ \left|\begin{array}{cccc}x-1 &amp; -1 &amp; 0 &amp; 0\\<br>1 &amp;x+ 1 &amp; 0 &amp; 0\\<br>2 &amp; 2 &amp; x-2 &amp; -1\\<br>-1 &amp; -1 &amp; 1 &amp; x\end{array}\right|\\=&amp;\ \left|\begin{array}{cc}x-1&amp;-1\\1&amp;x+1\end{array}\right|\cdot\left|\begin{array}{cc}x-2&amp;-1\\1&amp;x\end{array}\right|\\=&amp;\ x^2(x^2-2x+1)=x^2(x-1)^2.\end{align*}Here we used (5-20) page 158. The minimum polynomial is clearly not linear, thus the minimal polynomial is one of $x^2(x-1)^2$, $x^2(x-1)$, $x(x-1)^2$ or $x(x-1)$. We will plug $A$ in to the first three and show it is not zero. It will follow that the minimum polynomial must be $x^2(x-1)^2$.<br>$$A^2=<br>\left[\begin{array}{cccc}<br>0 &amp; 0 &amp; 0 &amp; 0\\<br>0 &amp; 0 &amp; 0 &amp; 0\\<br>-3 &amp; -3 &amp; 3 &amp; 2\\<br>2 &amp; 2 &amp; -2 &amp; -1<br>\end{array}\right]$$$$A-I=<br>\left[\begin{array}{cccc}<br>0 &amp; 1 &amp; 0 &amp; 0\\<br>-1 &amp; -2 &amp; 0 &amp; 0\\<br>-2 &amp; -2 &amp; 1 &amp; 1\\<br>1 &amp; 1 &amp; -1 &amp; -1<br>\end{array}\right]$$and<br>$$(A-I)^2=<br>\left[\begin{array}{cccc}<br>-1 &amp; -2 &amp; 0 &amp; 0\\<br>2 &amp; 3 &amp; 0 &amp; 0\\<br>1 &amp; 1 &amp; 0 &amp; 0\\<br>0 &amp; 0 &amp; 0 &amp; 0<br>\end{array}\right]$$Thus<br>$$A^2(A-I)=<br>\left[\begin{array}{cccc}<br>0 &amp; 0 &amp; 0 &amp; 0\\<br>0 &amp; 0 &amp; 0 &amp; 0\\<br>-1 &amp; -1 &amp; 1 &amp; 1\\<br>1 &amp; 1 &amp; -1 &amp; -1<br>\end{array}\right]\not=0$$$$A(A-I)^2=<br>\left[\begin{array}{cccc}<br>1 &amp; 1 &amp; 0 &amp; 0\\<br>-1 &amp; -1&amp; 0 &amp; 0\\<br>0 &amp; 0 &amp; 0 &amp; 0\\<br>0&amp; 0&amp; 0 &amp; 0<br>\end{array}\right]\not=0$$and<br>$$A(A-I)=<br>\left[\begin{array}{cccc}<br>-1 &amp; -1 &amp; 0 &amp; 0\\<br>1 &amp; 1&amp; 0 &amp; 0\\<br>-1 &amp; -1 &amp; 1 &amp; 1\\<br>1&amp; 1&amp; -2 &amp; -2<br>\end{array}\right]\not=0.$$Thus the minimal polynomial must be $x^2(x-1)^2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Charactersitc Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>A matrix which is not diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-3-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.3 Exercise 6.3.4</strong></p>
<p>Is the matrix $A$ of <a href="/hoffman-kunze/linear-algebra-exercise-6-3-3.html">Exercise 3</a> similar over the field of complex numbers to a diagonal matrix?</p>
<a id="more"></a>
<hr>
<p>Solution: Not diagonalizable, because for characteristic value $c=0$ the matrix $A-cI=A$ and $A$ is row equivalent to<br>$$\left[\begin{array}{cccc}1&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\\0&amp;0&amp;0&amp;1\\0&amp;0&amp;0&amp;0\end{array}\right]$$which has rank three. So the null space has dimension one. So if $W$ is the null space for $A-cI$ then $W$ has dimension one, which is less than the power of $x$ in the characteristic polynomial. So by Theorem 2, page 187, $A$ is not diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalization</tag>
      </tags>
  </entry>
  <entry>
    <title>A niloptent operator $T$ always satisfies $T^n=0$</title>
    <url>/lahk/linear-algebra-exercise-6-3-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.3 Exercise 6.3.5</strong></p>
<p>Let $V$ be an $n$-dimensional vector space and let $T$ be a linear operator on $V$. Suppose that there exists some positive integer $k$ so that $T^k=0$. Prove tht $T^n=0$.</p>
<a id="more"></a>
<hr>
<p>Solution: The condition $T^k=0$ implies that the only characteristic value of $T$ is zero. We know the minimal polynomial divides this so the minimal polynomial is of the form $t^r$ for some $1\leq r\leq n$. Thus by Theorem 3, page 193, the characteristic polynomial’s only root is zero, and the characteristic polynomial has degree $n$. So the characteristic polynomial equals $t^n$. By Theorem 4 (Caley-Hamilton) $T^n=0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Cayley-Hamilton Theorem</tag>
        <tag>Nilpotent Operator</tag>
        <tag>Annihilator</tag>
      </tags>
  </entry>
  <entry>
    <title>A $2\times 2$ Matrix having no chracteristic value over $\mathbb R$</title>
    <url>/lahk/linear-algebra-exercise-6-4-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.1</strong></p>
<p>Let $T$ be the linear operator on $\mathbb R^2$, the matrix of which in the standard ordered basis is<br>$$A=\left[\begin{array}{cc}1&amp;-1\\2&amp;2\end{array}\right].$$(a) Prove that the only subspaces of $\mathbb R^2$ invariant under $T$ are $\mathbb R^2$ and the zero subspace.</p>
<p>(b) If $U$ is the linear operator on $\mathbb C^2$, the matrix of which in the standard ordered basis is $A$, show that $U$ has $1$-dimensional invariant subspaces.</p>
<a id="more"></a>
<hr>
<p>Solution: </p>
<p>(a) The characteristic polynomial equals $$\left|\begin{array}{cc}x-1&amp;1\\-2&amp;x-2\end{array}\right|=(x-1)(x-2)+2=x^2-3x+4.$$ This is a parabola opening upwards with vertex $(3/2,7/4)$, so it has no real roots. If $T$ had an invariant subspace. It would have to be not $1$-dimensional since otherwise $T$ would therefore have a characteristic value.</p>
<p>(b) Over $\mathbb C$ the characteristic polynomial factors into two linears. Therefore over $\mathbb C$, $T$ has two characteristic values and therefore has at least one characteristic vector. The subspace generated by a characteristic vector is a $1$-dimensional subspace.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Operator not diagonalizable over $\mathbb R$ but diagonalizable over $\mathbb C$</title>
    <url>/lahk/linear-algebra-exercise-6-4-10.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.10</strong></p>
<p>Let $A$ be a $3\times3$ matrix with real entries. Prove that, if $A$ is not similar over $\mathbb R$ to a triangular matrix, then $A$ is similar over $\mathbb C$ to a diagonal matrix.</p>
<a id="more"></a>
<hr>
<p>Solution: If $A$ is not similar to a triangular matrix then the minimalpolynomial of $A$ must be of the form $$(x-c)(x^2+ax+b)$$ where $x^2+ax+b$ has no real roots. The roots of $x^2+ax+b$ are then two non-real complex conjugates $z$ and $\bar z$. Thus over $\mathbb C$ the minimum polynomial factors as $$(x-c)(x-z)(x-\bar z).$$ Since $c$ is real, $c$, $z$ and $\bar z$ constintute three distinct numbers. Thus by Theorem 6 $A$ is diagonalizable over $\mathbb C$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
        <tag>Minimal Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>A non-diagonal matrix may be similar to a diagonal matrix</title>
    <url>/lahk/linear-algebra-exercise-6-4-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.11</strong></p>
<p>True or false? If the triangular matrix $A$ is similar to a diagonal matrix, then $A$ is already diagonal.</p>
<a id="more"></a>
<hr>
<p>Solution: False. Let $$A=\left[\begin{array}{cc}1&amp;1\\0&amp;0\end{array}\right].$$ Then $A$ is triangular and not diagonal. The characteristic polynomial is $x(x-1)$ which has distinct roots, so the minimum polynomial is $x(x-1)$. Thus by Theorem 6, $A$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Similarity</tag>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Eigenvalues of a polynomial in an operator</title>
    <url>/lahk/linear-algebra-exercise-6-4-12.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.12</strong></p>
<p>Let $T$ be a linear operator on a finite-dimensional vector space over an algebraically closed field $F$. Let $f$ be a polynomial over $F$. Prove that $c$ is a characteristic value of $f(T)$ if and only if $c=f(t)$, where $t$ is a characteristic value of $T$.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $F$ is algebraically closed, the corollary at the bottom of page 203 implies there’s a basis under which $T$ is represented by a triangular matrix $A$, $A=[a_{ij}]$ where $a_{ij}=0$ if $i&gt;j$. Then the $a_{ii}$, $i=1,\dots,n$ are the characteristic values of $T$. </p>
<p>Now $f(A)=[b_{ij}]$ where $b_{ij}=0$ if $i&gt;j$ and $b_{ii}=f(a_{ii})$ for all $i=1,\dots,n$. Thus the characteristic values of $f(A)$ are exactly the $f(c)$’s where $c$ is a characteristic value of $A$. </p>
<p>Since $f(A)$ is a matrix representative of $f(T)$ in the same basis, we conclude the same thing about the transformation $T$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Left multiplication and commutator by a diagonalizable matrix are also diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-4-13.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.13</strong></p>
<p>Let $V$ be the space of $n\times n$ matrices over $F$. Let $A$ be a fixed $n\times n$ matrix over $F$. Let $T$ and $U$ be the linear operators on $V$ defined by<br>\begin{alignat*}{1}<br>T(B) &amp;= AB\\<br>U(B) &amp;= AB-BA<br>\end{alignat*}(a) True or false? If $A$ is a diagonalizable (over $F$), then $T$ is diagonalizable.</p>
<p>(b) True or false? If $A$ is diagonalizable, then $U$ is diagonalizable.</p>
<a id="more"></a>
<hr>
<p>Solution: </p>
<p>(a) True by <a href="/hoffman-kunze/linear-algebra-exercise-6-3-10.html">Exercise 6.3.10</a> page 198 since by Theorem 6 diagonalizability depends entirely on the minimal polynomial or by the proof of <a href="/hoffman-kunze/linear-algebra-exercise-6-2-15.html">Exercise 6.2.15</a>. </p>
<p>(b) True. Find a basis so that $A$ is diagonal<br>$$A=\left[\begin{array}{cccc}c_1&amp;&amp;&amp;\\&amp;c_2&amp;\Large0&amp;\\&amp;\Large0&amp;\ddots&amp;\\&amp;&amp;&amp;c_n\end{array}\right].$$Let $B=[b_{ij}]$. Then $U(B)=AB-BA$. The $n^2$ matrices $B_{ij}$ such that $b_{ij}\not=0$ and all other entries equal zero form a basis for $V$. For any $B_{ij}$, $U(B_{ij})=AB_{ij}-B_{ij}A=[d_{i’j’}]$ where $$d_{i’j’}=c_{i’}b_{i’j’}-c_{j’}b_{i’j’}=(c_{i’}-c_{j’})b_{i’j’}.$$ Thus $d_{i’j’}\not=0$ only when $i’=i$ and $j’=j$. Thus $U(B_{ij})=(c_i-c_j)B_{ij}$. So $c_i-c_j$ is a characteristic value and $B_{ij}$ is a characteristic vector for all $i,j$. Thus $V$ has a basis of characteristic vectors for $U$. Thus $U$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Diagonalizable Operator</tag>
        <tag>Commutator</tag>
      </tags>
  </entry>
  <entry>
    <title>Minimal Polynomial of Operator over Invariant Subspace</title>
    <url>/lahk/linear-algebra-exercise-6-4-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.2</strong></p>
<p>Let $W$ be an invariant subspace for $T$. Prove that the minimal polynomial for the restriction operator $T_W$ divides the minimal polynomial for $T$, without referring to matrices.</p>
<a id="more"></a>
<hr>
<p>Solution: By definition, the minimal polynomial of $T_W$ divides any polynomial $f(t)$ where $f(T_W)=0$. If $f$ is the minimum polynomial for $T$, the it suffices to show that $f(T_W)=0$. </p>
<p>Since  $f$ is the minimal polynomial for $T$, $F(T)v=0$ for all $v\in V$. Therefore, $f(T)w=0$ for all $w\in W$ as well. So $f(T_W)w=0$ for all $w\in W$ since by definition $f(T_W)w=f(T)w$ for $w\in W$. Therefore, $f(T_W)=0$. Therefore the minimal polynomial for $T_W$ divides $f$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Restriction of an operator to the eigenspace</title>
    <url>/lahk/linear-algebra-exercise-6-4-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.3</strong></p>
<p>Let $c$ be a characteristic value of $T$ and let $W$ be the space of characteristic vectors associated with the characteristic value $c$. What is the restriction operator $T_W$?</p>
<a id="more"></a>
<hr>
<p>Solution: For $w\in W$ the transformation $$T(w)=cw.$$ Thus $T_W$ is diagonalizable with single characteristic value $c$. In other words under which it is represented by the matrix<br>$$\left[\begin{array}{cccc}c&amp;&amp;&amp;\\&amp;c&amp; \Large0&amp;\\&amp; \Large0&amp;\ddots&amp;\\&amp;&amp;&amp;c\end{array}\right]$$where there are dim$(W)$ $c$’s on the diagonal.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Invariant Space</tag>
        <tag>Eigenspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a basis such that the operator is represented as a triangular matrix</title>
    <url>/lahk/linear-algebra-exercise-6-4-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.4</strong></p>
<p>Let<br>$$A=\left[\begin{array}{ccc}0&amp;1&amp;0\\2&amp;-2&amp;2\\2&amp;-3&amp;2\end{array}\right].$$Is $A$ similar over the field of real numbers to a triangular matrix? If so, find such a triangular matrix.</p>
<a id="more"></a>
<hr>
<p>Solution: We have$$A^2=\left[\begin{array}{ccc}2&amp;-2&amp;2\\0&amp;0&amp;0\\-2&amp;2&amp;-2\end{array}\right].$$And $A^3=0$. Thus the minimal polynomial $x^3$ and the only characteristic value is $0$. </p>
<p>We now follow the constructive proof of Theorem 5. $W=\{0\}$, $\alpha_1$ a characteristic vector of $A$ is $\left[\begin{array}{c}1\\0\\-1\end{array}\right]$. We need $\alpha_2$ such that $A\alpha_2\in\mathbb C\{\alpha_1\}$. $\alpha_2=\left[\begin{array}{c}-1\\1\\2\end{array}\right]$ satisfies $A\alpha_2=\alpha_1$. Now need $\alpha_3$ such that $A\alpha_3\in\mathbb C\{\alpha_1,\alpha_2\}$. $\alpha_3=\left[\begin{array}{c}0\\0\\1\end{array}\right]$ satisfies $A\alpha_3=2\alpha_1+2\alpha_2$. </p>
<p>Thus with respect to the basis $\{\alpha_1,\alpha_2,\alpha_3\}$ the transformation corresponding to $A$ is $\left[\begin{array}{ccc}0&amp;1&amp;2\\0&amp;0&amp;2\\0&amp;0&amp;0\end{array}\right]$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Minimal Polynomial</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>An idempotent is diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-4-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.5</strong></p>
<p>Every matrix $A$ such that $A^2=A$ is similar to a diagonal matrix.</p>
<a id="more"></a>
<hr>
<p>Solution: The equality $A^2=A$ implies that $A$ satisfies the polynomial $x^2-x=x(x-1)$. Therefore the minimal polynomial of $A$ is either $x$, $x-1$ or $x(x-1)$. In all three cases the minimal polynomial factors into distinct linears. Therefore, by Theorem 6 $A$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Idempotent</tag>
        <tag>Diagonalizable Operator</tag>
        <tag>Minimal Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Restriction of diagonalizable opeartor to invariant subspace is also diagonalizable</title>
    <url>/lahk/linear-algebra-exercise-6-4-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.6</strong></p>
<p>Let $T$ be a diagonalizable linear opeartor on the $n$-dimensional vector space $V$, and let $W$ be a subspace which is invariant under $T$. Prove that the restriction operator $T_W$ is diagonalizable.</p>
<a id="more"></a>
<hr>
<p>Solution: By <a href="/hoffman-kunze/linear-algebra-exercise-6-4-2.html">Exercise 6.4.2</a> or the lemma on page 80 the minimum polynomial for $T_W$ divides the minimum polynomial for $T$. Now $T$ diagonalizable implies (by Theorem 6) that the minimum polynomial for $T$ factors into distinct linears. Since the minimum polynomial for $T_W$ divides it, it must also factor into distinct linears. Thus by Theorem 6 again $T_W$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
        <tag>Minimal Polynomial</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>$T$ is diagonalizable if and only if $T$ is annihilated by a polynomial over $\mathbb C$ which has distinct roots</title>
    <url>/lahk/linear-algebra-exercise-6-4-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.7</strong></p>
<p>Let $T$ be a linear operator on a finite-dimensional vector space over the field of complex numbers. Prove that $T$ is diagonalizable if and only if $T$ is annihilated by some polynomial over $\mathbb C$ which has distinct roots.</p>
<a id="more"></a>
<hr>
<p>Solution: If $T$ is diagonalizable then its minimal polynomial is a product of distinct linear factors, and the minimal polynomial annihilates $T$. This proves “$\Rightarrow$”. </p>
<p>“$\Leftarrow$”. Now suppose $T$ is annihilated by a polynomial over $\mathbb C$ with distinct roots. Since the base field is $\mathbb C$ this polynomial factors completely into distinct linear factors. Since the minimal polynomial divides this polynomial, the minimal polynomial factors completely into distinct linear factors. Thus by Theorem 6, $T$ is diagonalizable.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
        <tag>Minimal Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Every subspace is invariant under $T$ iff $T$ is a scalar multiple of the identity operator</title>
    <url>/lahk/linear-algebra-exercise-6-4-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.8</strong></p>
<p>Let $T$ be a linear operator on $V$. If every subspace of $V$ is invariant under $T$, then $T$ is a scalar multiple of the identity operator.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $\{\alpha_i\}$ be a basis. The subspace generated by $\alpha_i$ is invariant thus $T\alpha_i$ is a multiple of $\alpha_i$. Thus $\alpha_i$ is a characteristic vector since $T\alpha_i=c_i\alpha_i$ for some $c_i$. Suppose there exist $i,j$ such that $c_i\not=c_j$. Then $$T(\alpha_i+\alpha_j)=T\alpha_i+T\alpha_j=c_i\alpha_i+c_j\alpha_j=c(\alpha_i+\alpha_j).$$ Since the subspace generated by $\{\alpha_i,\alpha_j\}$ is invariant under $T$. Thus $c_i=c$ and $c_j=c$ since coefficients of linear combinations of basis vectors are unique. And we obtain a contradiction to $c_i\not=c_j$. Therefore all $c_i$ are the same. Thus $T\alpha_i=c\alpha_i$ for all $i$. Thus $T$ is $c$ times the identity operator.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Invariant subspaces of space of functions under integration operator</title>
    <url>/lahk/linear-algebra-exercise-6-4-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.4 Exercise 6.4.9</strong></p>
<p>Let $T$ be the indefinite inntegral operator<br>$$(Tf)(x)=\int_0^xf(t)dt$$on the space of continuous functions on the interval $[0,1]$. Is the space of polynomial functions invariant under $T$? Ths space of differentiable functions? The space of functions which vanish at $x=1/2$?</p>
<a id="more"></a>
<hr>
<p>Solution: The integral from $0$ to $x$ of a polynomial is again a polynomial, so the space of polynomial functions is invariant under $T$. </p>
<p>The integral from $0$ to $x$ of a differntiable function is differentiable, so the space of differentiable functions is invariant under $T$. </p>
<p>Now let $f(x)=x-1/2$. Then $f$ vanishes at $1/2$ but $$\int_0^xf(t)dt=\frac12x^2-\frac12x$$ which does not vanish at $x=1/2$. So the space of functions which vanish at $x=1/2$ is not invariant under $T$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Differentiation Operator</tag>
        <tag>Integration Operator</tag>
        <tag>Invariant Space</tag>
      </tags>
  </entry>
  <entry>
    <title>Simultaneously diagonalize two matrices</title>
    <url>/lahk/linear-algebra-exercise-6-5-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.5 Exercise 6.5.1</strong></p>
<p>Find an invertible real matrix $P$ such that $P^{-1}AP$ and $P^{-1}BP$ are both diagonal, where $A$ and $B$ are the real matrices<br>$$\text{(a)}\quad A=\left[\begin{array}{cc} 1&amp;2\\0&amp;2\end{array}\right],\quad B=\left[\begin{array}{cc} 3&amp;-8\\0&amp;-1\end{array}\right]$$$$\text{(b)} \quad A=\left[\begin{array}{cc} 1&amp;1\\1&amp;1\end{array}\right],\quad B=\left[\begin{array}{cc} 1&amp;a\\a&amp;1\end{array}\right].$$ </p>
<a id="more"></a>
<hr>
<p>Solution: The proof of Theorem 8 shows that if a $2\times2$ matrix has two characteristic values then the $P$ that diagonalizes $A$ will necessarily also diagonalize any $B$ that commutes with $A$.</p>
<p>(a) Characteristic polynomial equals $(x-1)(x-2)$. So $c_1=1$, $c_2=2$.<br>$$c_1:\quad\left[\begin{array}{cc}0&amp;-2\\0&amp;-2\end{array}\right]\left[\begin{array}{c}1\\0\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right]$$$$c_2:\quad\left[\begin{array}{cc}1&amp;-2\\0&amp;0\end{array}\right]\left[\begin{array}{c}2\\1\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right]$$So $P=\left[\begin{array}{cc}0&amp;2\\0&amp;1\end{array}\right]$ and $P^{-1}=\left[\begin{array}{cc}1&amp;-2\\0&amp;1\end{array}\right]$.<br>$$P^{-1}AP=\left[\begin{array}{cc}1&amp;0\\0&amp;2\end{array}\right],\quad P^{-1}BP=\left[\begin{array}{cc}3&amp;0\\0&amp;-1\end{array}\right]$$(b) Characteristic polynomial equals $x(x-2)$. So $c_1=0$, $c_2=2$. $$c_1:\quad\left[\begin{array}{cc}-1&amp;-1\\-1&amp;-1\end{array}\right]\left[\begin{array}{c}-1\\1\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right]$$$$c_2:\quad\left[\begin{array}{cc}1&amp;-1\\-1&amp;1\end{array}\right]\left[\begin{array}{c}1\\1\end{array}\right]=\left[\begin{array}{c}0\\0\end{array}\right]$$So $P=\left[\begin{array}{cc}-1&amp;1\\1&amp;1\end{array}\right]$ and $P^{-1}=\left[\begin{array}{cc}-1/2&amp;1/2\\1/2&amp;1/2\end{array}\right]$.$$P^{-1}AP=\left[\begin{array}{cc}0&amp;0\\0&amp;2\end{array}\right],\quad P^{-1}BP=\left[\begin{array}{cc}1-a&amp;0\\0&amp;1+a\end{array}\right].$$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Similarity</tag>
        <tag>Diagonalization</tag>
      </tags>
  </entry>
  <entry>
    <title>Maximal number of mutually commuting linearly independent matrices</title>
    <url>/lahk/linear-algebra-exercise-6-5-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.5 Exercise 6.5.2</strong></p>
<p>Let $\mathcal F$ be a commuting family of $3\times3$ complex matrices. How many linearly independent matrices can $\mathcal F$ contain? What about the $n\times n$ case?</p>
<a id="more"></a>
<hr>
<p>Solution: This turns out to be quite a hard question, so I’m not sure what Hoffman &amp; Kunze had in mind. But there’s a general theorem from 1905 by I. Schur which says the answer is $\left \lfloor{\frac{n^2}{4}}\right \rfloor+1$. A simpler proof was published in 1998 by M. Mirzakhani in the <a href="https://www.tandfonline.com/doi/abs/10.1080/00029890.1998.12004879">American Mathematical Monthly</a>.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Commuting Operators</tag>
      </tags>
  </entry>
  <entry>
    <title>Maximal number of mutually commuting linearly independent matrices</title>
    <url>/lahk/linear-algebra-exercise-6-5-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.5 Exercise 6.5.3</strong></p>
<p>Let $T$ be a linear operator on an $n$-dimensional space, and suppose that $T$ has $n$ distinct characteristic values. Prove that any linear operator which commutes with $T$ is a polynomial in $T$.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $T$ has $n$ distinct characteristic values, $T$ is diagonalizable, see <a href="https://emath.page/hoffman-kunze/linear-algebra-exercise-6-2-7.html">Exercise 6.2.7</a>. Choose a basis $\mathcal B$ for which $T$ is represented by a diagonal matrix $A$. </p>
<p>Suppose the linear transformation $S$ commutes with $T$. Let $B$ be the matrix of $S$ in the basis $\mathcal B$. Then the $ij$-th entry of $AB$ is $a_{ii}b_{ij}$ and the $ij$-th entry of $BA$ is $a_{jj}b_{ij}$. Therefore if $a_{ii}b_{ij}=a_{jj}b_{ij}$ and $a_{ii}\not=a_{jj}$ for $i\ne j$, then it must be that $b_{ij}=0$ for $i\ne j$. So we have shown that $B$ must also be diagonal. </p>
<p>So we have to show there exists a polynomial such that $f(a_{ii})=b_{ii}$ for all $i=1,\dots,n$. By Section 4.3 <em>Lagrange Interpolation</em> there exists a polynomial with this property.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Commuting Operators</tag>
        <tag>Diagonal Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Determinant of a block matrix whose blocks are mutually commuting</title>
    <url>/lahk/linear-algebra-exercise-6-5-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.5 Exercise 6.5.4</strong></p>
<p>Let $A$, $B$, $C$, and $D$ be $n\times n$ complex matrices which commute. Let $E$ be the $2n\times2n$ matrix<br>$$E=\left[\begin{array}{cc} A &amp; B\\ C &amp; D\end{array}\right].$$Prove that $\det E=\det(AD-BC)$.</p>
<a id="more"></a>
<hr>
<p>Solution: If $A$ is <em>invertible</em>, then\[\left[\begin{array}{cc} A &amp; B\\ C &amp; D\end{array}\right]\cdot \left[\begin{array}{cc} I_n &amp; -A^{-1}B\\ 0 &amp; I_n\end{array}\right]=\left[\begin{array}{cc} A &amp; 0\\ C &amp; D-CA^{-1}B\end{array}\right].\]Hence $$\det E=\det A\det (D-CA^{-1}B)=\det(AD-ACA^{-1}B).$$Since $A$ and $C$ commute, we have $AD-ACA^{-1}B=AD-CB$. Thus $$\det E=\det(AD-ACA^{-1}B)=\det(AD-BC).$$If $A$ is <em>not invertible</em>, then we set $A_t=A+tI_n$, where $t$ is a complex number. Let$$E_t=\left[\begin{array}{cc} A_t &amp; B\\ C &amp; D\end{array}\right].$$Clearly, for enough small $t$, $A_t$ is invertible ($\det A_t$ is a polynomial of $t$ which can only have finitely many solutions). Moreover, $A_t$ and $C$ commute. Hence by the case we proved, we have $$\det E_t=\det(A_tD-BC)$$ for sufficiently small $t$. But both sides are polynomials in $t$, hence we can take $t\to 0$ and the limit should be the same. That is $\det E=\det(AD-BC)$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Determinant</tag>
      </tags>
  </entry>
  <entry>
    <title>Commutators induced by diagonal matrices are mutually commuting</title>
    <url>/lahk/linear-algebra-exercise-6-5-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.5 Exercise 6.5.5</strong></p>
<p>Let $F$ be a field, $n$ a positive integer, and let $V$ be the space of $n\times n$ matrices over $F$. If $A$ is a fixed $n\times n$ matrix over $F$, let $T_A$ be the linear operator on $V$ defined by $T_A(B)=AB-BA$. Consider the family of linear operators $T_A$ obtained by letting $A$ vary over all diagonal matrices. Prove that the operators in that family are simultaneously diagonalizable.</p>
<a id="more"></a>
<hr>
<p>Solution: If we stack the cloumns of an $n\times n$ matrix on top of each other with column one at the top, the matrix of $T_A$ in the standard basis is then given by<br>$$\left[\begin{array}{cccc}<br>A &amp; &amp; &amp; \\<br>&amp; A &amp; &amp;\\<br>&amp; &amp; \ddots &amp; \\<br>&amp; &amp; &amp; A<br>\end{array}\right].$$Thus if $A$ is diagonal then $T_A$ is diagonalizable.<br>4<br>Now $$T_AT_B(C)=ABC-ACB-BCA+CBA$$ and $$T_BT_A(C)=BAC-BCA-ACB+CAB.$$ Therefore we must show that $$BAC+CAB=ABC+CBA.$$ The $i,j$-th entry of $BAC+CAB$ is $c_{ij}(a_{ii}b_{ii}+a_{jj}b_{jj})$. And this is exactly the same as the $i,j$-th entry of $ABC+CBA$. Thus $T_A$ and $T_B$ commute. Thus by Theorem 8 the family can be simultaneously diagonalized.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Diagonalization</tag>
        <tag>Commutator</tag>
      </tags>
  </entry>
  <entry>
    <title>Expand a basis and find complement of subspace</title>
    <url>/lahk/linear-algebra-exercise-6-6-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.1</strong></p>
<p>Let $V$ be a finite-dimensional vector space and let $W_1$ be any subspace of $V$. Prove that there is a subspace $W_2$ of $V$ such that $V=W_1\oplus W_2$.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $V$ is finite-dimensional, so is $W_1$. Let $w_1,\dots,w_n$ be a basis of $W$. Then by Theorem 5 of Page 45, we can extend it to a basis $w_1,\dots,w_n$, $v_1,\dots,v_m$ of $V$.</p>
<p>Let $W_2=\mathrm{span}(v_1,\dots,v_m)$. Then it is clear that $V=W_1\oplus W_2$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Direct Sum</tag>
      </tags>
  </entry>
  <entry>
    <title>Direct-sum decomposition of space with images of projections as summands</title>
    <url>/lahk/linear-algebra-exercise-6-6-10.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.10</strong></p>
<p>Let $F$ be a subfield of the complex numbers (or, a field of characteristic zero). Let $V$ be a finite-dimensional vector space over $F$. Suppose that $E_1,\dots,E_k$ are projections of $V$ and that $E_1+\cdots E_k=I$. Prove that $E_iE_j=0$ for $i\not=j$ (Hint: use the trace function and ask yourself what the trace of a porjection is.)</p>
<a id="more"></a>
<hr>
<p>Solution: Let $W_i$ be the image $W_i$ of the projection $E_i$</p>
<p>Since $E_i$ is a projection, its minimal polynomial is a monic divisor of $x(x-1)$. Since $x(x-1)$ has no multiple roots, by Theorem 6 of page 204, $E_i$ is diagonalizable. Moreover, the eigenvalues are zero or one. Therefore the trace $\mathrm{tr}(E_i)$ is exactly the dimension of $W_i$.</p>
<p>Clearly, we have $W_1+W_2+\cdots+W_k\subset V$. But $E_1+\cdots+E_k=I$, for any $v\in V$, we have\[v=E_1v+\cdots+E_kv\in W_1+W_2+\cdots+W_k.\]Hence $W_1+W_2+\cdots+W_k=V$. Moreover, taking the trace on $E_1+\cdots+E_k=I$, we get that (trace function is linear)\[\dim W_1+\cdots+\dim W_k=\dim V.\]Therefore, we have $V=W_1\oplus\cdots\oplus W_k$ by Exercise 6.6.2.</p>
<p>Taking $w_i\in W_i$, we have\[w_i=Iw_i=\sum_{j=1}^k E_jw_i=w_i+\sum_{j\ne i}^kE_jw_i.\]Since $V=W_1\oplus\cdots\oplus W_k$, we have $E_jw_i=0$ for $j\ne i$. Hence $E_jW_i=0$ for all $j\ne i$. Therefore $$E_jE_iv\in E_j W_i=0$$ for all $v\in V$ and $j\ne i$. Namely, $E_jE_i=0$ for $j\ne i$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Projection</tag>
        <tag>Direct Sum</tag>
      </tags>
  </entry>
  <entry>
    <title>Direct-sum decomposition of dual space</title>
    <url>/lahk/linear-algebra-exercise-6-6-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.11</strong></p>
<p>Let $V$ be a vector space, let $W_1,\dots,W_k$ be subspace of $V$, and let<br>$$V_j=W_1+\cdots W_{j-1}+W_{j+1}+\cdots+W_k.$$Suppose that $V=W_1\oplus\cdots\oplus W_k$. Prove that the dual space $V^*$ has the direct-sum decomposition $V^*=V_1^0\oplus\cdots\oplus V_k^0$.</p>
<a id="more"></a>
<hr>
<p>Solution: We use the transpose from Chapter 3.7. We also use the notation from Theorem 9 of page 212.</p>
<p>By Theorem 9 of page 212, we have projections $E_i$ such that $E_iE_j=0$ for $i\ne j$ and $I=E_1+\dots+E_k$. Define the map $E_i^t:V^*\to V^*$ by\[(E^t_if)(v)=f(E_iv),\]for all $f\in V^*$ and $v\in V$. If $i\ne j$, we have\begin{align*}(E_i^tE_j^tf)v=(E_j^tf)(E_iv)=f(E_jE_iv)=f(0)=0.\end{align*}Hence $E_j^tE_i^t=0$ for $j\ne i$. Similarly, one shows that $E_i^t$ is an idempotent.</p>
<p>We also have\begin{align*}((E_1^t+\cdots+E_k^t)f)v&amp;=f(E_1v)+\cdots+f(E_kv)\\&amp;=f(E_1v+\cdots+E_kv)=f((E_1+\cdots+E_k)v)\\&amp;=f(Iv)=f(v).\end{align*}Hence $E_1^t+\cdots+E_k^t=I$.</p>
<p>Let $S_i$ be the image of $E_i^t$, then by Theorem 9 of page 212, we have\[V^*=S_1\oplus \cdots\oplus S_k.\]Therefore, it suffices to show that $S_i=V_i^0$.</p>
<p>Let $v_i\in V_i$, then $E_iv_i=0$ (page 211). Hence for all $f\in V^*$, we have\[(E_i^tf)v_i=f(E_iv_i)=f(0)=0.\]Hence $E_i^tf\in V_i^0$. Namely $S_i\subset V_i^0$.</p>
<p>Conversely, for $v\in V$, we write $v=w_i+v_i$ where $w_i\in W_i$ and $v_i\in V_i$. Moreover, $E_iv=w_i$. If $f\in V_i^0$, then $$f(v)=f(w_i+v_i)=f(w_i),$$$$(E_i^tf)v=f(E_iv)=f(w_i).$$Therefore, we have $E_i^tf=f$ for $f\in V_i^0$. This implies that $V_i^0\subset S_i$.</p>
<p>We conclude that $S_i=V_i^0$ and we are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Direct Sum</tag>
        <tag>Dual Space</tag>
        <tag>Linear Functional</tag>
      </tags>
  </entry>
  <entry>
    <title>Equality for dimensions ensures a sum is actually a direct sum</title>
    <url>/lahk/linear-algebra-exercise-6-6-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.2</strong></p>
<p>Let $V$ be a finite-dimensional vector space and let $W_1,\dots,W_k$ be subspaces of $V$ such that<br>$$V=W_1+\cdots+W_k\quad\text{and}\quad\dim(V)=\dim(W_1)+\cdots+\dim(W_k).$$Prove that $V=W_1\oplus\cdots\oplus W_k.$</p>
<a id="more"></a>
<hr>
<p>Solution: See <a href="https://linearalgebras.com/2c.html">Exercise 2C.16 of Linear Algebra Done Right</a>. Very similar but not exactly the same. I will add the solution later.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Dimension</tag>
        <tag>Direct Sum</tag>
      </tags>
  </entry>
  <entry>
    <title>Find a projection which projects onto a given subspace along another given subspace</title>
    <url>/lahk/linear-algebra-exercise-6-6-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.3</strong></p>
<p>Find a projection $E$ which projects $\mathbb R^2$ onto the subspace spanned by $(1,-1)$ along the subspace spanned by $(1,2)$.</p>
<a id="more"></a>
<hr>
<p>Solution: Consider the linear map $E:\mathbb R^2\to \mathbb R^2$ such that\[E(1,-1)=(1,-1),\quad E(1,2)=(0,0).\]In terms of the standard basis, we have\[E(1,0)=\frac{1}{3}(2,-2),\quad E(0,1)=\frac{1}{3}(-1,1).\]</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title>Sum of projections may not be a projection</title>
    <url>/lahk/linear-algebra-exercise-6-6-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.4</strong></p>
<p>If $E_1$ and $E_2$ are projections onto independent subspaces, then $E_1+E_2$ is a projection. True or false?</p>
<a id="more"></a>
<hr>
<p>Solution: False. Let $E_1$ be the projection in Exercise <a href="/hoffman-kunze/linear-algebra-exercise-6-6-3.html">6.6.3</a> and $E_2$ be the projection onto the subspace spanned by $(1,0)$ along the subspace spanned by $(0,1)$.</p>
<p>Then $$(E_1+E_2)(1,-1)=(1,-1)+(1,0)=(2,-1)$$and \begin{align*}(E_1+E_2)(2,-1)&amp;=E_1(2,-1)+E_2(2,-1)\\&amp;=\frac{1}{3}(5,-5)+(2,0)\ne (2,-1).\end{align*}Hence $(E_1+E_2)^2\ne E_1+E_2$, so $E_1+E_2$ is not a projection.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title>Every polynomial in a projection is actually a linear polynomial</title>
    <url>/lahk/linear-algebra-exercise-6-6-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.5</strong></p>
<p>If $E$ is a projection and $f$ is a polynomial, then $f(E)=aI+bE$. What are $a$ and $b$ in terms of the coefficents of $f$?</p>
<a id="more"></a>
<hr>
<p>Solution: If $E$ is a projection, then $E^2=E$. Moreover, we have $$E^{k}=E$$for all $k&gt;0$. Hence $a$ is the constant term of $f$ while $b$ is the sum of all other coefficients of $x^{k+1}$, for all $k\geqslant 0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Projection</tag>
        <tag>Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalizable operator with only characteristic values $0$ and $1$ is a projection</title>
    <url>/lahk/linear-algebra-exercise-6-6-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.6</strong></p>
<p>True or false? If a diagonalizable operator has only the characteristic values $0$ and $1$, it is a projection.</p>
<a id="more"></a>
<hr>
<p>Solution: True. Since $T$ is diagonalizable and has only the characteristic values $0$ and $1$. By Theorem 6 of page 204, the minimal polynomial of $T$ is \[p=x(x-1).\]Namely, $$T(T-I)=0\Rightarrow T^2=T.$$Hence $T$ is a projection.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Projection</tag>
        <tag>Eigenvalue</tag>
      </tags>
  </entry>
  <entry>
    <title>Identity minus a projection is again a projection</title>
    <url>/lahk/linear-algebra-exercise-6-6-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.7</strong></p>
<p>Prove that if $E$ is the projection on $R$ along $N$, then $(I-E)$ is the projection on $N$ along $R$.</p>
<a id="more"></a>
<hr>
<p>Solution: We have $V=R\oplus N$. By definition, we have\[Ev_R=v_R,\quad Ev_N=0\]for all $v_R\in R$ and $v_N\in N$. Therefore $$(I-E)v_R=v_R-v_R=0,$$$$(I-E)v_N=v_N-0=v_N.$$Moreover,$$(I-E)^2=I-2E+E^2=I-E.$$Hence $I-E$ is the projection on $N$ along $R$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Projection</tag>
      </tags>
  </entry>
  <entry>
    <title>Idempotent decomposition of identity operator</title>
    <url>/lahk/linear-algebra-exercise-6-6-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.8</strong></p>
<p>Let $E_1,\dots, E_k$ be linear operators on the space $V$ such that $E_1+\cdots+E_k=I$.</p>
<p>(a) Prove that if $E_iE_j=0$ for $i\not=j$, then $E_i^2=E_i$ for each $i$.</p>
<p>(b) In the case $k=2$, prove the converse of (a). That is, if $E_1+E_2=I$ and $E_1^2=E_1$, $E_2^2=E_2$, then $E_1E_2=0$.</p>
<a id="more"></a>
<hr>
<p>Solution: For part (a), we have\begin{align*}E_i^2&amp;=E_i(I-E_1-\cdots-E_{i-1}-E_{i+1}-\cdots-E_{n})\\&amp;=E_i-\sum_{j\ne i}E_{i}E_{j}=E_i,\end{align*}since $E_iE_j=0$ for $i\ne j$.</p>
<p>(b) We have $$E_1=E_1(E_1+E_2)=E_1^2+E_1E_2.$$Since $E_1=E_1^2$, we have $E_1E_2=0$. Similarly, one can show that $E_2E_1=0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Vector Space</tag>
        <tag>Subspace</tag>
        <tag>Projection</tag>
        <tag>Idempotent</tag>
      </tags>
  </entry>
  <entry>
    <title>Inverse of an operator related to an idempotent linear operator</title>
    <url>/lahk/linear-algebra-exercise-6-6-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.6 Exercise 6.6.9</strong></p>
<p>Let $V$ be a real vector space and $E$ an idempotent linear operator on $V$, i.e., a projection. Prove that $(I+E)$ is invertible. Find $(I+E)^{-1}$.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $E$ is idempotent, we have\[E^2-E-2I=-2I,\]i.e.\[(I+E)(2I-E)=2I.\]Hence $(I+E)^{-1}$ is equal to $\frac{1}{2}(2I-E)$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Projection</tag>
        <tag>Idempotent</tag>
        <tag>Inverse</tag>
      </tags>
  </entry>
  <entry>
    <title>What’s wrong with the following proof of Jordan-Chevalley Decomposition</title>
    <url>/lahk/linear-algebra-exercise-6-8-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.11</strong></p>
<p>What’s wrong with the following proof of Theorem 13? Suppose that the minimal polynomial for $T$ is a product of linear factors. Then, by Theorem 5, $T$ is triangulable. Let $\mathscr B$ be an ordered basis such that $A = [T]_{\mathscr B}$ is upper-triangular. Let $D$ be the diagonal matrix with diagonal entries $a_{11}$, $\dots$, $a_{nn}$. Then $A = D + N$, where $N$ is strictly upper-triangular. Evidently $N$ is nilpotent.</p>
<a id="more"></a>
<hr>
<p>Solution: The matrices $D$ and $N$ may not commute. Let $$A=\begin{pmatrix}1&amp;1\\ 0&amp;2\end{pmatrix},$$ then $$D=\begin{pmatrix}1&amp;0\\ 0&amp;2\end{pmatrix}$$ and $$N=\begin{pmatrix}0&amp;1\\ 0&amp;0\end{pmatrix}.$$ It is easy to check that $DN\ne ND$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Nilpotent Operator</tag>
        <tag>Jordan-Chevalley Decomposition</tag>
      </tags>
  </entry>
  <entry>
    <title>Existence of vectors whose annihilator is the minimal polynomial (1)</title>
    <url>/lahk/linear-algebra-exercise-6-8-13.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.13</strong></p>
<p>Let $T$ be a linear operator on $V$ with minimal polynomial of the form $p^n$, where $p$ is irreducible over the scalar field. Show that there is a vector $\alpha$ in $V$ such that the $T$-annihilator of $\alpha$ is $p^n$.</p>
<a id="more"></a>
<hr>
<p>Solution: (Let us assume $V$ is finite-dimensional!) Let $v_1,\dots,v_m$ be a basis of $V$. Then for each $v_i$, the $T$-annihilator of $v_i$ is a divisor of $p^n$ and hence has the form $p^{k_i}$ for some positive integer $k_i$. Clearly, $k_i\leqslant n$.</p>
<p>We consider the set $\{k_1,\dots,k_m\}$. If $$\max\{k_1,\dots,k_m\}&lt; n,$$then $k_i\leqslant n-1$ for all $i$. Hence $p(T)^{n-1}v_i=0$ for all $i$. Thus $P(T)^{n-1}v=0$ for all $v\in V$ as $v_1,\dots,v_m$ is a basis of $V$. Then the minimal polynomial of $T$ cannot be $p^n$, we get a contradiction. Therefore, we must have $\max\{k_1,\dots,k_m\}=n$. That it, $k_i=n$ for some $i$. We are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Nilpotent Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Existence of vectors whose annihilator is the minimal polynomial (2)</title>
    <url>/lahk/linear-algebra-exercise-6-8-14.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.14</strong></p>
<p>Use the primary decomposition theorem and the result of <a href="/hoffman-kunze/linear-algebra-exercise-6-8-13.html">Exercise 13</a> to prove the following. If $T$ is any linear operator on a finite-dimensional vector space $V$, then there is a vector $\alpha$ in $V$ with $T$-annihilator equal to the minimal polynomial for $T$.</p>
<a id="more"></a>

<p>Solution: Here, we use the notation from Theorem 12. By Theorem 12 (Primary Decomposition Theorem) and <a href="/hoffman-kunze/linear-algebra-exercise-6-8-13.html">Exercise 6.8.13</a>, we can take $\alpha_i\in W_i$ such that the $T$-annihilator of $\alpha_i$ is $p_i^{r_i}$.</p>
<p>Let $\alpha=\alpha_1+\cdots+\alpha_k$. Suppose $f(T)\alpha=0$ for some polynomial $f$. Then we have\[0=f(T)\alpha=f(T)\alpha_1+\cdots+f(T)\alpha_k.\]Since $W_i$ is invariant under $T$, we have $f(T)\alpha_i\in W_i$. Note that\[V=W_1\oplus \cdots\oplus W_k.\]We have $f(T)\alpha_i=0$ for all $i$. Since the $T$-annihilator of $\alpha_i$ is $p_i^{r_i}$, we conclude that $p_i^{r_i}|f$ for all $i$. Hence $p|f$. Therefore, the $T$-annihilator of $\alpha$ is $p$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Minimal Polynomial</tag>
        <tag>Annihilator</tag>
        <tag>Primary Decomposition</tag>
      </tags>
  </entry>
  <entry>
    <title>Characteristic polynomial for a nilpotent linear operator is $x^n$</title>
    <url>/lahk/linear-algebra-exercise-6-8-15.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.15</strong></p>
<p>If $N$ is a nilpotent linear operator on an $n$-dimensional vector space $V$, then the characteristic polynomial for $N$ is $x^n$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let us work on algebraically closed field. In general, we can enlarge the filed $\mathbb F$ to its algebraic closure. So this argument works even $F$ is not algebraically closed. But I don’t like this argument. This statement is clear if we know the Jordan form.</p>
<p>Since $N$ is nilpotent, we have $N^m=0$ for some positive integer $m$. Hence the minimal polynomial of $N$ is a monic divisor of $x^m$ and so has the form $x^k$. Recall Theorem 3 of page 193, the characteristic polynomial and the minimal polynomial has the same roots. Hence characteristic polynomial must be of the form $x^\ell$. But we also know that the degree of characteristic polynomial is exactly $\dim V=n$. Hence the characteristic polynomial for $N$ is $x^n$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Characteristic Polynomial</tag>
        <tag>Minimal Polynomial</tag>
        <tag>Nilpotent Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Differentiation operator on space of polynomials is nilpotent</title>
    <url>/lahk/linear-algebra-exercise-6-8-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.3</strong></p>
<p>If $V$ is the space of all polynomials of degree less than or equal to $n$ over a field $F$, prove that the differentiation operator on $V$ is nilpotent.</p>
<a id="more"></a>
<hr>
<p>Solution: This is clear. Let $D$ be the differentiation operator, then $\deg (Df)=\deg f-1$ for polynomial $f$ such that $\deg f\geqslant 1$. Hence we have\[D^{\deg f+1}f=D(D^{\deg f}f)=Dc=0,\]where $c$ is a constant number as $\deg(D^{\deg f}f)=0$.</p>
<p>If $\deg f=0$, then we also have $D^{\deg f+1}f=Dc=0$ since $f$ is a constant.</p>
<p>Therefore, $D^{n+1}$ is a zero operator on the space of all polynomials of degree less than or equal to $n$ over a field $F$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Differentiation Operator</tag>
        <tag>Nilpotent Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalizable part of a polynomial in a linear operator</title>
    <url>/lahk/linear-algebra-exercise-6-8-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.5</strong></p>
<p>Let $V$ be a finite-dimensional vector space over the field of complex numbers. Let $T$ be a linear operator on $V$ and let $D$ be the diagonalizable part of $T$. Prove that if $g$ is any polynomial with complex coeffcients, then the diagonalizable part of $g(T)$ is $g(D)$.</p>
<a id="more"></a>
<hr>
<p>Solution: We write $T=D+N$ as in Theorem 13. Since $D$ is diagonalizable, so is $g(D)$. Note that $D$ is a polynomial in $T$, so is $g(D)$. Thus $g(T)$ commutes with $g(D)$. It follows that $g(D)$ commutes with $g(T)-g(D)$. Therefore, by Theorem 13, it suffices to show that $g(T)-g(D)$ is nilpotent.</p>
<p>Since $T$ and $D$ commute, we can write $$g(T)-g(D)=(T-D)h(T,D)=Nh(T,D)$$for some polynomial $h$ in $T$ and $D$. Clearly, $N$ commutes with $h(T,D)$. Because $N$ is nilpotent, there exists $m&gt;0$ such that $$(g(T)-g(D))^m=(Nh(T,D))^m=N^mh^m(T,D)=0.$$We are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Diagonalizable Operator</tag>
        <tag>Nilpotent Operator</tag>
        <tag>Jordan-Chevalley Decomposition</tag>
      </tags>
  </entry>
  <entry>
    <title>Operator commutes with every diagonalizable operator is a scalar multiple of the identity operator</title>
    <url>/lahk/linear-algebra-exercise-6-8-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.7</strong></p>
<p>Let $V$ be a finite-dimensional vector space over $\mathbb F$, and let $T$ be a linear operator on $V$. Suppose that $T$ commutes with every diagonalizable linear operator on $V$. Prove that $T$ is a scalar multiple of the identity operator.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $v\in V$ be nonzero. Consider a projection $E$ onto the subspace spanned by $v$. Then $E$ is diagonalizable and hence commutes with $T$. We have\[TEv=ETv\Longrightarrow Tv=\lambda v\]for some $\lambda\in F$. Hence $v$ is an characteristic vector of $T$. Therefore, all nonzero vectors are characteristic vectors of $T$.</p>
<p>Take a basis $v_1,\dots,v_n$, then we have $Tv_i=\lambda_i v_i$ for some $\lambda_i\in F$. We show that $\lambda_i=\lambda_j$ for $i\ne j$. Since $v_i+v_j$ is nonzero, there exists $\lambda\in F$ such that $T(v_i+v_j)=\lambda(v_i+v_j)$. Therefore, we have\[\lambda(v_i+v_j)=Tv_i+Tv_j=\lambda_iv_i+\lambda_j v_j\iff (\lambda-\lambda_i)v_i+(\lambda-\lambda_j)v_j=0.\]But $v_i,v_j$ is linearly independent, we have $\lambda=\lambda_i$ and $\lambda=\lambda_j$. It follows that $\lambda_i$ are all the same. Hence $T$ is a scalar multiple of identity matrix.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Same minimal and characteristic polynomials do not imply similarity</title>
    <url>/lahk/linear-algebra-exercise-6-8-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 6.8 Exercise 6.8.9</strong></p>
<p>Give an example of two $4\times 4$ nilpotent matrices which have the same minimal polynomial (they necessarily have the same characteristic polynomial) but which are not similar.</p>
<a id="more"></a>
<hr>
<p>Solution: Consider $$A=\begin{pmatrix}0&amp;1 &amp; 0 &amp; 0\\ 0&amp;0&amp; 0 &amp; 0\\0&amp;0 &amp; 0 &amp; 1\\0&amp;0 &amp; 0 &amp; 0\end{pmatrix}$$and $$B=\begin{pmatrix}0&amp;0 &amp; 0 &amp; 0\\ 0&amp;0&amp; 0 &amp; 0\\0&amp;0 &amp; 0 &amp; 1\\0&amp;0 &amp; 0 &amp; 0\end{pmatrix}.$$Then is clear that the characteristic polynomials of $A$ and $B$ are $x^4$ while the minimal polynomials are the same which is $x^2$. But $A$ and $B$ are not similar. Since $2=\mathrm{rank}(A)\ne \mathrm{rank}(B)=1.$</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Nilpotent Matrix</tag>
        <tag>Similarity</tag>
        <tag>Characteristic Polynomial</tag>
        <tag>Minimal Polynomial</tag>
      </tags>
  </entry>
  <entry>
    <title>Any non-zero vector which is not a characteristic vector in $F^2$ is a cyclic vector</title>
    <url>/lahk/linear-algebra-exercise-7-1-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.1</strong></p>
<p>Let $T$ be a linear operator on $F^2$. Prove that any non-zero vector which is not a characteristic vector for $T$ is a cyclic vector for $T$. Hence, prove that either $T$ has a cyclic vector or $T$ is a scalar multiple of the identity operator.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $v\in F^2$ be nonzero such that $v$ is not a characteristic vector for $T$. Then $v,Tv$ is linearly independent. Hence $v,Tv$ forms a basis of $F^2$. Namely, $v,Tv$ spans the whole space $F^2$. So $v$ is a cyclic vector for $T$.</p>
<p>Suppose $T$ does not have a cyclic vector, we only need to show that $T$ is a scalar multiple of the identity operator. By the first part, any non-zero vector is a characteristic vector for $T$. We take a basis $v_1,v_2$ of $F^2$. Then $Tv_1=av_1$ and $Tv_2=bv_2$. We show that $a=b$. Since $v_1+v_2$ is non-zero and is a characteristic vector for $T$, there exists $c$ such that\[T(v_1+v_2)=c(v_1+v_2).\]Hence we have\[av_1+bv_2=cv_1+cv_2.\]Since $v_1$ and $v_2$ are linearly independent, we must have $a=b=c$. Hence $Tv_1=av_1$ and $Tv_2=av_2$. It is clear that $T$ is a scalar multiple of the identity operator.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Invariant Space</tag>
        <tag>Cyclic Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalizable operator with multiple eigenvalues has no cyclic vector</title>
    <url>/lahk/linear-algebra-exercise-7-1-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.3</strong></p>
<p>Let $T$ be the linear operator on $\mathbb R^3$ which is represented in the standard ordered basis by the matrix $$\begin{bmatrix}2 &amp; 0 &amp; 0\\ 0 &amp; 2 &amp; 0\\ 0 &amp; 0 &amp; -1\end{bmatrix}.$$Prove that $T$ has no cyclic vector. What is the $T$-cyclic subspace generated by the vector $(1,-1,3)$?</p>
<a id="more"></a>
<hr>
<p>Solution: Since $T$ is diagonalizable, the minimal polynomial of $T$ is $(x-2)(x+1)$ but the characteristic polynomial is $(x-2)^2(x+1)$. By Theorem 2 and Corollary in page 230, if $T$ has a cyclic vector then the minimal polynomial and characteristic polynomial are the same. This is impossible. Hence $T$ has no cyclic vectors.</p>
<p>The $T$-cyclic subspace generated by $(1,-1,3)$ is $\{(a,-a,b)|a,b\in F\}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Invariant Space</tag>
        <tag>Cyclic Vector</tag>
        <tag>Cyclic Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Find $T$-annihilator of a vector for a particular operator</title>
    <url>/lahk/linear-algebra-exercise-7-1-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.3</strong></p>
<p>Let $T$ be the linear operator on $\mathbb C^3$ which is represented in the standard ordered basis by the matrix $$\begin{bmatrix}1 &amp; i &amp; 0\\ -1 &amp; 2 &amp; -i \\ 0 &amp; 1 &amp; 1\end{bmatrix}.$$Find the $T$-annihilator of the vector $(1,0,0)$. Find the $T$-annihilator of the vector $(1,0,i)$.</p>
<a id="more"></a>
<hr>
<p>Solution: Note that we have\[T(1,0,0)=(1,-1,0),\quad T^2(1,0,0)=(1-i,-3,-1).\]Hence $(1,0,0)$, $T(1,0,0)$, $T^2(1,0,0)$ are linearly independent. Thus $(1,0,0)$ is a cyclic vector and the T-annihilator of $(1,0,0)$ is exactly the characteristic polynomial of $T$ (please compute it by yourself).</p>
<p>Note that $T(1,0,i)=(1,0,i)$, hence the T-annihilator of $(1,0,i)$ is exactly $x-1$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Annihilator</tag>
        <tag>Invariant Space</tag>
        <tag>Cyclic Subspace</tag>
      </tags>
  </entry>
  <entry>
    <title>Square of an operator has a cyclic vector so does itself</title>
    <url>/lahk/linear-algebra-exercise-7-1-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.4</strong></p>
<p>Prove that if $T^2$ has a cyclic vector, then $T$ has a cyclic vector. Is the converse true?</p>
<a id="more"></a>
<hr>
<p>Solution: It is clear that $Z(\alpha,T^2)\subset Z(\alpha,T)$. Let $\alpha$ be a cyclic vector of $T^2$, then we have\[V=Z(\alpha,T^2)\subset Z(\alpha,T).\]Hence $Z(\alpha,T)=V$, namely $\alpha$ is a cyclic vector of $T$.</p>
<p>The converse is false. Let $T$ be the operator on $F^2$ corresponding to the matrix $\begin{pmatrix} 0 &amp;1\\ 0&amp;0\end{pmatrix}$. Then $T$ is cyclic by Exercise 7.1.1. But $T^2=0$ is not cyclic.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Invariant Space</tag>
        <tag>Cyclic Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>When does a nilpotent operator have a cyclic vector?</title>
    <url>/lahk/linear-algebra-exercise-7-1-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.5</strong></p>
<p>Let $V$ be an $n$-dimensional vector space over the field $\mathbb F$, and let $N$ be a nilpotent linear operator on $V$. Suppose $N^{n-1}\ne 0$, and let $\alpha$ be any vector in $V$ such that $N^{n-1}\alpha\ne 0$. Prove that $\alpha$ is a cyclic vector for $N$. What exactly is the matrix of $N$ in the ordered basis $\{\alpha,N\alpha,\dots,N^{n-1}\alpha\}$?</p>
<a id="more"></a>
<hr>
<p>Solution: Recall that from <a href="/hoffman-kunze/linear-algebra-exercise-6-8-15.html">Exercise 6.8.15</a>, the characteristic polynomial of $N$ is $x^n$ and hence $N^n=0$ by Caley-Hamilton Theorem. Since $N^{n-1}\alpha\ne 0$, the $T$-annihilator of $T$ is $x^n$. Hence by Theorem 1 (i) $Z(\alpha,N)=V$. Thus $\alpha$ is a cyclic vector of $N$. The matrix has the form of (7-2) in page 229 where all $c_i$ are zero, that is $$\begin{bmatrix}0&amp;0&amp;0&amp;\ldots &amp;0&amp;0\\1&amp;0&amp;0&amp;\ldots &amp;0&amp;0\\ 0&amp;1&amp;0&amp;\ldots &amp;0&amp;0 \\ \vdots &amp;\vdots &amp;\vdots &amp;\ddots &amp;\vdots &amp;\vdots \\0&amp;0&amp;0&amp;\ldots &amp;0&amp;0\\0&amp;0&amp;0&amp;\ldots &amp;1&amp;0\end{bmatrix}.$$</p>
<hr>
<p>Here we used the theorem from the textbook. One can show directly that $$\{\alpha,N\alpha,\dots,N^{n-1}\alpha\}$$ is a basis by showing linear independence.</p>
<p>Recall that from <a href="/hoffman-kunze/linear-algebra-exercise-6-8-15.html">Exercise 6.8.15</a>, the characteristic polynomial of $N$ is $x^n$ and hence $N^n=0$ by Caley-Hamilton Theorem. </p>
<p>Suppose $$\sum_{i=0}^{n-1}c_iN^i\alpha=0$$for some numbers $c_i$. We would like to show that all $c_i$ are zero. We argue it by contradiction. Suppose $k$ is the smallest $i$ such that $c_i\ne 0$, we have $$\sum_{i=k}^{n-1}c_iN^i\alpha=0.$$Applying $N^{n-k-1}$ to both sides, one has $$\sum_{i=k}^{n-1}c_iN^{n-k-1+i}\alpha=0.$$ Since $N^n=0$, all terms are zero in the left hand side except the first one. Thus $c_kN^{n-1}\alpha=0$. But $N^{n-1}\alpha\ne 0$ and $c_k\ne 0$ by assumption, we obtain a contradiction.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Nilpotent Matrix</tag>
        <tag>Nilpotent Operator</tag>
        <tag>Invariant Space</tag>
        <tag>Cyclic Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>Characteristic polynomial of a companion matrix</title>
    <url>/lahk/linear-algebra-exercise-7-1-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.6</strong></p>
<p>Give a direct proof that if $A$ is the companion matrix of the monic polynomial $p$, then $T$ is the characteristic polynomial for $A$.</p>
<a id="more"></a>
<hr>
<p>Solution: Suppose $p=t^{n}+a_{n-1}t^{n-1}+\cdots +a_{0}$, then $$A=\begin{bmatrix} 0 &amp; \cdots &amp; 0&amp; -a_{0} \\ 1 &amp; \cdots &amp; 0 &amp; -a_{1}\\ \vdots &amp;\ddots &amp; \vdots &amp;\vdots \\ 0 &amp;\cdots &amp; 1 &amp; -a_{n-1} \end{bmatrix}.$$ We would like to compute $\mathrm{det}(tI_n-A)$. We proceed by induction. \begin{align*}&amp;\ \mathrm{det}(tI_n-A) = \mathrm{det} \begin{pmatrix} t &amp; 0 &amp; \cdots &amp; 0 &amp; a_0 \\ -1 &amp; t &amp; \cdots &amp; 0 &amp; a_1 \\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; -1 &amp; t+a_{n-1} \end{pmatrix} \\ = &amp;\ t \cdot \mathrm{det} \; \begin{pmatrix} t &amp; 0 &amp; \cdots &amp; 0 &amp; a_1 \\ -1 &amp; t &amp; \cdots &amp; 0 &amp; a_2 \\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; -1 &amp; t+a_{n-1} \end{pmatrix} \\&amp;\ + (-1)^{1+n} a_0 \cdot \mathrm{det} \begin{pmatrix} -1 &amp; t &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -1 &amp; t &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; -1 &amp; \end{pmatrix}.\end{align*} By induction we can replace the determinant on the left by $$a_1+a_2t+\cdots+a_{n-1}t^{n-2}+t^{n-1}$$ and the second matrix’s determinant is the product of its diagonals (since it’s upper-triangular). The product of the diagonals is $(-1)^{n-1}$. Therefore, the determinant is $$t(a_1+a_2t+\cdots+a_{n-1}t^{n-2}+t^{n-1})+(-1)^{n+1}(-1)^{n-1}a_0.$$ Which simplifies to $a_0+a_1t+\cdots+a_{n-1}t^{n-1}+t^n$.</p>
<blockquote>
<p>Please don’t forget the base case for the induction.</p>
</blockquote>
<hr>
<p>Actually, the minimal polynomial of $A$ is also $p$. Which means the operator corresponds to $A$ has a cyclic vector. See more detail <a href="https://math.stackexchange.com/questions/10216/the-characteristic-and-minimal-polynomial-of-a-companion-matrix">here</a>.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Characteristic Polynomial</tag>
        <tag>Minimal Polynomial</tag>
        <tag>Companion Matrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalizable cyclic operator has $n$ distinct characteristic values</title>
    <url>/lahk/linear-algebra-exercise-7-1-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.7</strong></p>
<p>Let $V$ be an $n$-dimensional vector space, and let $T$ be a linear operator on $V$. Suppose that $T$ is diagonalizable.</p>
<p>(a) If $T$ has a cyclic vector, show that has $n$ distinct characteristic values.</p>
<p>(b) If $T$ has $n$ distinct characteristic values, and if $\{\alpha_1,\dots,\alpha_n\}$ is a basis of characteristic vectors for $T$. Show that $\alpha=\alpha_1+\cdots+\alpha_n$ is a cyclic vector for $T$.</p>
<a id="more"></a>
<hr>
<p>Solution:</p>
<p>(a) Since $T$ is diagonalizable, let $p$ be the minimal polynomial of $T$,\[p(x)=(x-z_1)\cdots(x-z_k),\]where $z_1,\dots,z_k$ are all distinct characteristic values for $T$, see Theorem 6 in page 204. Since $T$ has a cyclic vector. Hence $p$ is also the characteristic polynomial for $T$, which has degree $n$. Therefore $k=n$. That is $T$ has $n$ distinct characteristic values.</p>
<p>(b) Let $z_i$ be the characteristic value for $T$ corresponding to $\alpha_i$. Then $T^k\alpha_i=z_i^k\alpha_i$. Thus for any polynomial $g$, we have\[g(T)\alpha=\sum_{i=1}^n g(z_i)\alpha_i.\]Since $z_i$ are all distinct, we can choose\[g_i(x)=\frac{(x-z_1)\cdots(x-z_{i-1})(x-z_{i+1})\cdots(x-z_n)}{(z_i-z_1)\cdots(z_i-z_{i-1})(z_i-z_{i+1})\cdots(z_i-z_n)}.\]Recall from Section 4.3, we have $g_i(z_j)=\delta_{ij}$. Therefore\[g_i(T)\alpha=\alpha_i.\]Hence $Z(\alpha,T)$ contains a basis $\{\alpha_1,\dots,\alpha_n\}$ of $V$. So $\alpha$ is a cyclic vector for $T$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvalue</tag>
        <tag>Minimal Polynomial</tag>
        <tag>Cyclic Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>Operators which commute with a cyclic operator are polynomial in this cyclic operator</title>
    <url>/lahk/linear-algebra-exercise-7-1-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.1 Exercise 7.1.8</strong></p>
<p>Let $T$ be a linear operator on the finite-dimensional vector space $V$. Suppose $T$ has a cyclic vector. Prove that if $U$ is any linear operator which commutes with $T$, then $U$ is a polynomial in $T$.</p>
<a id="more"></a>
<hr>
<p>Solution: Let $\alpha$ be a cyclic vector of $V$ and $\dim V=n$. Then $\alpha,T\alpha,\cdots,T^{n-1}\alpha$ is a basis of $V$. Hence we have\[U\alpha=\sum_{i=0}^{n-1}a_iT^i\alpha,\]for some $a_i\in F$. Since $U$ commutes with $T$, we have\begin{align*}U(T\alpha)&amp;=TU\alpha=T\sum_{i=0}^{n-1}a_iT^i\alpha\\&amp;=\sum_{i=0}^{n-1}a_{i+1}T^{i+1}\alpha=\sum_{i=0}^{n-1}a_iT^i(T\alpha).\end{align*}Similarly, we have\[U(T^j\alpha)=\sum_{i=0}^{n-1}a_iT^i(T^j\alpha),\]for all $j&gt;0$. Since $\alpha,T\alpha,\cdots,T^{n-1}\alpha$ is a basis of $V$, we conclude that\[U=\sum_{i=0}^{n-1}a_iT^i\] is a polynomial in $T$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Invariant Space</tag>
        <tag>Cyclic Vector</tag>
      </tags>
  </entry>
  <entry>
    <title>Semi-simple part of a polynomial in nilpotent operator is a scalar multiple of the identity operator</title>
    <url>/lahk/linear-algebra-exercise-7-5-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.5 Exercise 7.5.1</strong></p>
<p>If $N$ is a nilpotent linear operator on $V$, show that for any polynomial $f$ the semi-simple part of $f(N)$ is a scalar multiple of the identity operator ($\mathbb F$ is a subfield of $\mathbb C$).</p>
<a id="more"></a>
<hr>
<p>Solution: Let $$f(x)=\sum_{k=0}^n a_kx^k,$$where $a_k\in F$. Let $$g(x)=\sum_{k=1}^n a_k x^{k-1}.$$Then $f(x)=a_0+xg(x)$. Hence $f(N)=a_0I+Ng(N)$. Clearly, $a_0I$ is semi-simple.</p>
<p>Note that $N$ is nilpotent, hence $N^m=0$ for some $m&gt;0$. Since $N$ and $g(N)$ commute, we have\[(Ng(N))^m=N^m(g(N))^m=0.\]Hence $Ng(N)$ is nilpotent. It is also clear that $a_0I$ commutes with $Ng(N)$. Therefore, we get the desired decompostion $f(N)=a_0I+Ng(N)$ as in Theorem 13 of page 267, where $a_0I$ is the semi-simple part and $Ng(N)$ is the nilpotent part. We are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Nilpotent Matrix</tag>
        <tag>Nilpotent Operator</tag>
        <tag>Jordan-Chevalley Decomposition</tag>
      </tags>
  </entry>
  <entry>
    <title>Semi-simple operators over a subfield of complex number field are diagonalizable over $\mathbb C$</title>
    <url>/lahk/linear-algebra-exercise-7-5-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.5 Exercise 7.5.2</strong></p>
<p>Let $\mathbb F$ be a subfield of the complex numbers, $V$ a finite-dimensional vector space over $\mathbb F$, and $T$ a semi-simple linear operator on $V$. If $f$ is any polynomial over $\mathbb F$, prove that $f(T)$ is semi-simple.</p>
<a id="more"></a>
<hr>
<p>Solution: Since $\mathbb F$ is a subfield of the complex numbers, by Corollary of page 265, $T$ is diagonalizable over $\mathbb C$. Hence $f(T)$ is also diagonalizable over $\mathbb C$. By Theorem 12 of page 267, $f(T)$ is semi-simple over $\mathbb F$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Diagonalizable Operator</tag>
        <tag>Semi-simple Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>A necessary and sufficient condition of semi-simple operators over a subfield of $\mathbb C$</title>
    <url>/lahk/linear-algebra-exercise-7-5-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 7.5 Exercise 7.5.3</strong></p>
<p>Let $T$ be a linear operator on a finite-dimensional space over a subfield of $\mathbb C$. Prove that $T$ is semi-simple if and only if the following is true: If $f$ is a polynomial and $f(T)$ is nilpotent, then $f(T)=0$.</p>
<a id="more"></a>
<hr>
<p>Solution: “$\Leftarrow$” Consider the decomposition $T=S+N$ in Theorem 13, where $S$ is semi-simple. Moreover, $N$ is equal to $f(T)$ for some polynomial $f$ and is nilpotent. By assumption, we have $N=0$. Hence $T=S$ is semi-simple.</p>
<p>“$\Rightarrow$” Suppose $f$ is a polynomial and $f(T)$ is nilpotent. Since $T$ is semi-simple, by <a href="/hoffman-kunze/linear-algebra-exercise-7-5-2.html">Exercise 7.5.2</a>, $f(T)$ is semi-simple. Hence $f(T)$ is both semi-simple and nilpotent. Hence, both$$f(T)=0+f(T), \quad f(T)=f(T)+0$$are the decompositions of $f(T)$ in the sense of Theorem 13, where the first operator is semi-simple and the second one is nilpotent. By the uniqueness of Theorem 13, we must have $f(T)=0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Nilpotent Operator</tag>
        <tag>Jordan-Chevalley Decomposition</tag>
        <tag>Semi-simple Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Basic Property of Inner Product</title>
    <url>/lahk/linear-algebra-exercise-8-1-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 8.1 Exercise 8.1.1</strong></p>
<p>Let $V$ be a vector space and $(\ | \ )$ an inner product on $V$.</p>
<p>(a) Show that $(0|\beta)=0$ for all $\beta$ in $V$.</p>
<p>(b) Show that if $(\alpha|\beta)=0$ for all $\beta$ in $V$, then $\alpha=0$.</p>
<a id="more"></a>

<hr>
<p>Solution:</p>
<p>(a) This comes from Part (b) of Definition on Page 271. Because $0=0 \cdot \beta$ (here the first $0$ is the zero vector), we have $$(0|\beta)=(0\cdot \beta|\beta)=0(\beta|\beta)=0.$$ (b) Because $(\alpha|\beta)=0$ for all $\beta$ in $V$, it holds particularly for $\beta=\alpha$. Hence we have $$(\alpha|\alpha)=0.$$It follows from Part (d) of Definition on Page 271 that $\alpha=0$ (otherwise $(\alpha|\alpha)&gt;0$).</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
      </tags>
  </entry>
  <entry>
    <title>Inner Product induced by Integral Restriced to Space of Polynomials</title>
    <url>/lahk/linear-algebra-exercise-8-1-11.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 8.1 Exercise 8.1.11</strong></p>
<p>Show that the formula \begin{equation}\label{eq:8.1.11.1}\left(\sum_ja_jx^j|\sum_k b_kx^k\right)=\sum_{j,k}\frac{a_jb_k}{j+k+1}\end{equation}defines an inner product on the space $\mathbf R[x]$ of polynomial over the field $\mathbf R$. Let $W$ be the subspace of polynomials of degree less than or equal to $n$. Restrict the above inner product to $W$, and find the matrix of this inner product on $W$, relative to the ordered basis $\{1,x,x^2,\dots,x^n\}$. (<em>Hint</em>: To show that the formula defines an inner product, observe that $$(f|g)=\int_0^1 f(t)g(t)dt$$and work with the integral.) </p>
<a id="more"></a>

<hr>
<p>Solution: We see similarly from Example 5 that $$(f|g)=\int_0^1 f(t)g(t)dt$$ defines an inner product on the vector space of all continuous real valued functions on the unit interval, $0\leqslant t\leqslant 1$. It is clear that $\mathbf R[x]$ is a subspace to this vector space and a restrict of inner product to subspace is an inner product on subspace. Hence the restriction $$(f|g)=\int_0^1 f(t)g(t)dt$$ defines an inner product on $\mathbf R[x]$. In particular, we can show that under this inner product (by integral), we have \begin{align*}\left(\sum_ja_jx^j|\sum_k b_kx^k\right)=&amp;\ \int_0^1 \left(\sum_ja_jt^j\right)\left(\sum_k b_kt^k\right)dt\\ = &amp;\ \sum_{j,k}\int_0^1 a_jb_kt^jt^kdt\\=&amp;\ \sum_{j,k}\int_0^1 a_jb_kt^{j+k}dt \\ =&amp;\ \sum_{j,k}\frac{a_jb_k}{j+k+1}.\end{align*}This is exactly the formula \eqref{eq:8.1.11.1}. Hence the formula \eqref{eq:8.1.11.1} defines an inner product on $\mathbf R[x]$.</p>
<p>The matrix of this inner product on $W$, relative to the ordered basis $\{1,x,x^2,\dots,x^n\}$, is given by $(\frac{1}{i+j-1})_{i,j=1}^{n+1}$. Indeed, the $(i,j)$ element of this matrix corresponds to the number $(x^{i-1}|x^{j-1})$, which is $\frac{1}{i+j-1}$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Polynomial</tag>
        <tag>Integral</tag>
      </tags>
  </entry>
  <entry>
    <title>Parallelogram Law of Inner Product</title>
    <url>/lahk/linear-algebra-exercise-8-1-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 8.1 Exercise 8.1.9</strong></p>
<p>Let $V$ be a real or complex vector space with an inner product. Show that the quadratic form determined by the inner product satisfies the parallelogram law $$\|\alpha+\beta\|^2+\|\alpha-\beta\|^2=2\|\alpha\|^2+2\|\beta\|^2.$$</p>
<a id="more"></a> 

<hr>

Solution: Because the quadratic form is determined by the inner product, we have $\|v\|=(v|v)$. Hence, we have\begin{align*}\|\alpha+\beta\|^2=&amp;\  (\alpha+\beta|\alpha+\beta)\\=&amp;\ (\alpha|\alpha)+(\alpha|\beta)+(\beta|\alpha)+(\beta|\beta)\end{align*} and \begin{align*}\|\alpha-\beta\|^2=&amp;\  (\alpha-\beta|\alpha-\beta)\\=&amp;\ (\alpha|\alpha)-(\alpha|\beta)-(\beta|\alpha)+(\beta|\beta).\end{align*}Therefore,\begin{align*}&amp;\|\alpha+\beta\|^2+\|\alpha-\beta\|^2\\ =&amp;\ (\alpha|\alpha)+(\alpha|\beta)+(\beta|\alpha)+(\beta|\beta)+(\alpha|\alpha)-(\alpha|\beta)-(\beta|\alpha)+(\beta|\beta)\\=&amp;\ 2(\alpha|\alpha)+2(\beta|\beta)=2\|\alpha\|^2+2\|\beta\|^2.\end{align*}


<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Parallelogram Law</tag>
      </tags>
  </entry>
  <entry>
    <title>Verify if they are sesqui-linear forms</title>
    <url>/lahk/linear-algebra-exercise-9-2-1.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.1</strong></p>
<p>Which of the following functions $f$, defined on vectors $\alpha=(x_1,x_2)$ and $\beta=(y_1,y_2)$ in $\mathbb C^2$, are (sesqui-linear) forms on $\mathbb C^2$? </p>
<p>(a) $f(\alpha,\beta)=1$. </p>
<p>(b) $f(\alpha,\beta)=(x_1-\bar y_1)^2+x_2\bar y_2$. </p>
<p>(c) $f(\alpha,\beta)=(x_1+\bar y_1)^2-(x_1-\bar y_1)^2$. </p>
<p>(d) $f(\alpha,\beta)=x_1\bar y_2-\bar x_2y_1$.</p>
<a id="more"></a>
<hr>
<p>Solution:</p>
<p>(a) No. Since $f(0,\beta)\ne 0$.</p>
<p>(b) No. Since $f((0,0),(1,0))\ne 0$.</p>
<p>(c) Yes. Since $f(\alpha,\beta)=4x_1\bar y_1$.</p>
<p>(d) No. Because of $\bar x_2$ there, it is not linear on $\alpha$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
      </tags>
  </entry>
  <entry>
    <title>Find the matrix of a form with respect to a basis</title>
    <url>/lahk/linear-algebra-exercise-9-2-2.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.2</strong></p>
<p>Let $f$ be the form on $\mathbb R^2$ defined by $$f((x_1,y_1),(x_2,y_2))=x_1y_1+x_2y_2.$$<br>Find the matrix of $f$ in each of the following bases: $$ \{(1,0),(0,1)\}, \{(1,-1),(1,1)\},\ \{(1,2),(3,4)\}. $$</p>
<a id="more"></a>
<hr>
<p>Solution: It is not a form! I think it should be $$\color{red}{f((x_1,y_1),(x_2,y_2))=x_1x_2+y_1y_2}.$$The matrices (obtained by direct computations) are\[\begin{pmatrix}1 &amp; 0\\ 0 &amp; 1\end{pmatrix},\begin{pmatrix}2 &amp; 0\\ 0&amp; 2\end{pmatrix},\begin{pmatrix}5 &amp; 11\\ 11 &amp; 25\end{pmatrix},\]respectively.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
      </tags>
  </entry>
  <entry>
    <title>Check if a form is an inner product</title>
    <url>/lahk/linear-algebra-exercise-9-2-3.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.3</strong></p>
<p>Let $$A=\begin{bmatrix} 1&amp; i\\ -i &amp; 2\end{bmatrix}$$ and let $g$ be the form (on the space of $2\times 1$ complex matrices) defined by $$g(X,Y)=Y^*AX.$$Is $g$ an inner product?</p>
<a id="more"></a>
<hr>
<p>Solution: Because $A=A^*$, we have\[\overline{g(X,Y)}=(Y^*AX)^*=X^*AY=g(Y,X).\]It is also clear that $g$ defines a form. Hence we only need to check that $g(X,X)&gt;0$ if $X\ne 0$.</p>
<p>Let $X=(\alpha,\beta)$, then\begin{align*}g(X,X)&amp;=(\bar\alpha,\bar \beta)\begin{pmatrix}1 &amp; i\\ -i &amp; 2\end{pmatrix}\begin{pmatrix}\alpha\\ \beta\end{pmatrix}\\&amp;=\alpha\bar{\alpha}+2\beta\bar\beta-i(\alpha\bar\beta-\bar\alpha\beta)\\&amp;=(\alpha-i\beta)\overline{(\alpha-i\beta)}+\beta\bar\beta\\&amp;=|\alpha-i\beta|^2+|\beta|^2 &gt; 0.\end{align*}Suppose $g(X,X)=0$, then $\alpha-i\beta=0$ and $\beta=0$. Hence $X=0$. Therefore, we are done.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Inner Product</tag>
        <tag>Form</tag>
      </tags>
  </entry>
  <entry>
    <title>Symmetric sesqui-linear form over $\mathbb C$ is zero</title>
    <url>/lahk/linear-algebra-exercise-9-2-4.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.4</strong></p>
<p>Let $V$ be a complex vector space and let $f$ be a (sesqui-linear) form on $V$ which is symmetric: $$f(\alpha,\beta)=f(\beta,\alpha).$$ What is $f$?</p>
<a id="more"></a>
<hr>
<p>Solution: Since $f$ is a form, we have $f$ is linear on $\alpha$. Since $f(\alpha,\beta)=f(\beta,\alpha)$, we also have $f$ is linear on $\beta$. </p>
<p>Therefore, $f$ is a form which is also a bilinear form. Then we have\[-if(\alpha,\beta)=f(\alpha,i\beta)=f(i\beta,\alpha)=if(\beta,\alpha)=if(\alpha,\beta).\]Thus $f(\alpha,\beta)=0$. That is $f=0$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
      </tags>
  </entry>
  <entry>
    <title>Diagonalize a symmetric matrix associated to a form</title>
    <url>/lahk/linear-algebra-exercise-9-2-5.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.5</strong></p>
<p>Let $f$ be the form on $\mathbb R^2$ given by $$f((x_1,x_2),(y_1,y_2))=x_1y_1+4x_2y_2+2x_1y_2+2x_2y_1.$$Find an ordered basis in which $f$ is represented by a diagonal matrix.</p>
<a id="more"></a>
<hr>
<p>Solution: This is basically the same as diagonalizing symmetric matrix.</p>
<p>The matrix of $f$ in the standard basis is given by $\begin{pmatrix}1 &amp; 2\\2&amp; 4\end{pmatrix}$. Its eigenvalues are zero and 5 because the characteristic polynomial is $$f(\lambda)=(\lambda-1)(\lambda-4)-2\cdot 2=\lambda(\lambda-5).$$ The corresponding eigenvectors (solve the corresponding linear equations) are $(2,-1)^T$ and $(1,2)^T$. Now it is easy to check that the matrix of $f$ in the basis $(2,-1)$ and $(1,2)$ is diagonal $\mathrm{diag}(0,25)$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Eigenvector</tag>
        <tag>Eigenvalue</tag>
        <tag>Symmetric Matrix</tag>
        <tag>Form</tag>
      </tags>
  </entry>
  <entry>
    <title>Form is non-degenerate if and only if the associated linear operator is non-singular</title>
    <url>/lahk/linear-algebra-exercise-9-2-6.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.6</strong></p>
<p>Call the form $f$ (left) <strong>non-degenerate</strong> if $0$ is the only vector $\alpha$ such that $f(\alpha,\beta)=0$ for all $\beta$. Let $f$ be a form on an inner product space $V$. Prove that $f$ is non-degenerate if and only if the associated linear operator $T_f$ (Theorem 1) is non-singular.</p>
<a id="more"></a>
<hr>
<p>Solution: If $f$ is non-degenerate, we show that $T_f$ is non-singular. Suppose $T_f\alpha=0$ for some $\alpha\in V$, then we have $$f(\alpha,\beta)=(T\alpha|\beta)=0$$ for all $\beta$. Since $f$ is non-degenerate, we must have $\alpha=0$. Hence $T_f$ is non-singular.</p>
<p>Conversely, suppose $f(\alpha,\beta)=0$ for all $\beta$, then we have $$f(\alpha,\beta)=(T_f\alpha|\beta)=0,$$for all $\beta$. In particular, we have $0=(T_f\alpha|T_f\alpha)$. Hence $T_f\alpha=0$. But $T_f$ is non-singular, therefore $\alpha=0$. Thus $f$ is non-degenerate.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
        <tag>Non-degenerate</tag>
        <tag>Non-singular</tag>
      </tags>
  </entry>
  <entry>
    <title>Form is left non-degenerate if and only if it is right non-degenerate</title>
    <url>/lahk/linear-algebra-exercise-9-2-7.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.7</strong></p>
<p>Let $f$ be a form on a finite-dimensional vector space $V$. Look at the definition of left non-degeneracy given in <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 6</a>. Define right non-degeneracy and prove that the form $f$ is left non-degenerate if and only if $f$ is right non-degenerate.</p>
<a id="more"></a>
<hr>
<p>Solution: We can always define an inner product on a finite-dimensional vector space $V$. Hence we shall assume that $V$ is a finite-dimensional inner product space.</p>
<p>Call the form $f$ <strong>right non-degenerate</strong> if $0$ is the only vector $\alpha$ such that $f(\beta,\alpha)=0$ for all $\beta$.</p>
<p>Suppose $f$ is left non-degenerate, we show that $f$ is right non-degenerate. Suppose $f(\beta,\alpha)=0$ for all $\beta$. Hence $(T_f\beta|\alpha)=0$ for all $\beta$. Because $f$ is left non-degenerate, $T_f$ is non-singular by <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 9.2.6</a>. Since $V$ is finite-dimensional, we have $T_f$ is invertible. Hence there exists $\beta$ such that $T_f\beta=\alpha$. Therefore, we conclude that $$0=(T_f\beta|\alpha)=(\alpha|\alpha).$$Thus $\alpha=0$, namely $f$ is right non-degenerate.</p>
<p>Similar to <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 9.2.6</a>, one can show that $f$ is right non-generate if and only if $T_f^*$ is non-singular. Then repeat our argument, we can show the other direction.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
        <tag>Non-degenerate</tag>
        <tag>Non-singular</tag>
      </tags>
  </entry>
  <entry>
    <title>Relation between non-degenerate forms and linear functionals</title>
    <url>/lahk/linear-algebra-exercise-9-2-8.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.8</strong></p>
<p>Let $f$ be a non-degenerate form (<a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 9.2.6</a> and <a href="/hoffman-kunze/linear-algebra-exercise-9-2-7.html">Exercise 9.2.7</a>) on a finite-dimensional space $V$. Let $L$ be a linear functional on $V$. Show that there exists one and only one vector $\beta$ in $V$ such that $L(\alpha)=f(\alpha,\beta)$ for all $\alpha$.</p>
<a id="more"></a>
<hr>
<p>Solution: We can always define an inner product on a finite-dimensional vector space $V$. Hence we shall assume that $V$ is a finite-dimensional inner product space.</p>
<p>By Theorem 6 of page 291, there exists a vector $\beta_0$ such that $L(\alpha)=(\alpha|\beta_0)$. On the other hand, we also have $$f(\alpha,\beta)=(T_f\alpha|\beta)=(\alpha|T_f^*\beta).$$Since $f$ is non-degenerate, $T_f$ is non-singular, see <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 9.2.6</a> and <a href="/hoffman-kunze/linear-algebra-exercise-9-2-7.html">Exercise 9.2.7</a>. Because $V$ is finite-dimensional, we conclude that $T_f$ is invertible. So is $T_f^*$. Therefore, there exists a unique $\beta\in V$ such that $T_f^*\beta=\beta_0$. We have\[L(\alpha)=(\alpha|\beta_0)=(\alpha|T_f^*\beta)=f(\alpha,\beta).\]We showed the existence.</p>
<p>Suppose $\beta_1$ and $\beta_2$ are vectors such that $$L(\alpha)=f(\alpha,\beta_1)=f(\alpha,\beta_2).$$Then $f(\alpha,\beta_1-\beta_2)=0$ for all $\alpha$. Since $f$ is non-degenerate, we have $\beta_1-\beta_2=0$, which shows the uniqueness.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Linear Functional</tag>
        <tag>Form</tag>
        <tag>Non-degenerate</tag>
      </tags>
  </entry>
  <entry>
    <title>Non-degenerate form induces adjoint linear operators</title>
    <url>/lahk/linear-algebra-exercise-9-2-9.html</url>
    <content><![CDATA[<p><strong><a href="/hoffman-kunze/solution-linear-algebra-second-edition.html">Solution to Linear Algebra Hoffman &#038; Kunze</a> Chapter 9.2 Exercise 9.2.9</strong></p>
<p>Let $f$ be a non-degenerate form on a finite-dimensional space $V$. Show that each linear operator $S$ has an $^t$adjoint relative to $f$, i.e., an operator $S’$ such that $$f(S\alpha,\beta) = f(\alpha, S’\beta)$$ for all $\alpha$, $\beta$.</p>
<a id="more"></a>
<hr>
<p>Solution: We can always define an inner product on a finite-dimensional vector space $V$. Hence we shall assume that $V$ is a finite-dimensional inner product space.</p>
<p>As we have seen in previous exercises, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">Exercise 9.2.6</a> and <a href="/hoffman-kunze/linear-algebra-exercise-9-2-7.html">Exercise 9.2.7</a>, $T_f^*$ is invertible. We have\[f(S\alpha,\beta)=(T_fS\alpha|\beta)=(\alpha|S^*T_f^*\beta),\]\[f(\alpha,S’\beta)=(T_f\alpha|S’\beta)=(\alpha|T_f^*S’\beta).\]Hence it suffices to choose some $S’$ such that $S^*T_f^*=T_f^*S’$, that is $S’=(T_f^*)^{-1}S^*T_f^*$. Hence we showed the existence of $S’$.</p>
<p>Now we show the uniqueness. Suppose there exists another operator $S^\dagger$ such that $$f(S\alpha,\beta) = f(\alpha, S^\dagger\beta)$$ for all $\alpha$, $\beta$. Then $$f(\alpha, S^\dagger\beta)=f(\alpha, S’\beta),$$we have $$f(\alpha, (S’-S^\dagger)\beta)=0$$for all $\alpha$, $\beta$. Because $f$ is non-degenerate, we must have $(S’-S^\dagger)\beta=0$ for all $\beta$. Thus $S^\dagger=S’$. This shows the uniqueness.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Form</tag>
        <tag>Non-degenerate</tag>
        <tag>Adjoint Operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Solution to Linear Algebra Hoffman &amp; Kunze Second Edition</title>
    <url>/lahk/solution-linear-algebra-second-edition.html</url>
    <content><![CDATA[<p><a href="https://amzn.to/2xIPKU3" target="_blank" rel="noopener noreferrer"><img class="alignleft" src="https://cdn.jsdelivr.net/gh/1000072/static@master/20190712152002.jpg" alt="Linear Algebra 2nd Edition by Kenneth Hoffman and Ray Kunze" width="200" height="250"></a></p>
<a id="more"></a>

<center><a class="btn-beautify button--animated " href="https://amzn.to/2xIPKU3" 
  title="Buy from Amazon"><i class="fab fa-amazon fa-fw fa-lg fa-fw"></i><span>Buy from Amazon</span></a></center> 

<h3 id="Chapter-1-Linear-Equations"><a href="#Chapter-1-Linear-Equations" class="headerlink" title="Chapter 1. Linear Equations"></a>Chapter 1. Linear Equations</h3><ul>
<li>1.1 Fields (no exercises)</li>
<li><input checked="" disabled="" type="checkbox"> 1.2 Systems of Linear Equations<br><a href="/hoffman-kunze/linear-algebra-exercise-1-2-1.html">#1.2.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-2.html">#1.2.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-3.html">#1.2.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-4.html">#1.2.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-5.html">#1.2.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-6.html">#1.2.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-7.html">#1.2.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-2-8.html">#1.2.8</a></li>
<li><input checked="" disabled="" type="checkbox"> 1.3 Matrices and Elementary Row Operations<br><a href="/hoffman-kunze/linear-algebra-exercise-1-3-1.html">#1.3.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-2.html">#1.3.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-3.html">#1.3.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-4.html">#1.3.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-5.html">#1.3.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-6.html">#1.3.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-7.html">#1.3.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-1-3-8.html">#1.3.8</a></li>
<li>1.4 Row-Reduced Echelon Matrices</li>
<li>1.5 Matrix Multiplication</li>
<li>1.6 Invertible Matrices</li>
</ul>
<h3 id="Chapter-2-Vector-Spaces"><a href="#Chapter-2-Vector-Spaces" class="headerlink" title="Chapter 2. Vector Spaces"></a>Chapter 2. Vector Spaces</h3><ul>
<li><input checked="" disabled="" type="checkbox"> 2.1 Vector spaces<br><a href="/hoffman-kunze/linear-algebra-exercise-2-1-1.html">#2.1.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-2.html">#2.1.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-3.html">#2.1.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-4.html">#2.1.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-5.html">#2.1.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-6.html">#2.1.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-1-7.html">#2.1.7</a></li>
<li><input checked="" disabled="" type="checkbox"> 2.2 Subspaces<br><a href="/hoffman-kunze/linear-algebra-exercise-2-2-1.html">#2.2.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-2.html">#2.2.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-3.html">#2.2.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-4.html">#2.2.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-5.html">#2.2.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-6.html">#2.2.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-7.html">#2.2.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-8.html">#2.2.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-2-9.html">#2.2.9</a></li>
<li><input checked="" disabled="" type="checkbox"> 2.3 Bases and Dimension<br><a href="/hoffman-kunze/linear-algebra-exercise-2-3-1.html">#2.3.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-2.html">#2.3.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-3.html">#2.3.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-4.html">#2.3.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-5.html">#2.3.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-6.html">#2.3.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-7.html">#2.3.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-8.html">#2.3.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-9.html">#2.3.9</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-10.html">#2.3.10</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-11.html">#2.3.11</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-12.html">#2.3.12</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-13.html">#2.3.13</a>, <a href="/hoffman-kunze/linear-algebra-exercise-2-3-14.html">#2.3.14</a></li>
<li>2.4 Coordinates</li>
<li>2.5 Summary of Row-equivalence (no exercises)</li>
<li>2.6 Computations Concerning Subspaces</li>
</ul>
<h3 id="Chapter-3-Linear-Transformations"><a href="#Chapter-3-Linear-Transformations" class="headerlink" title="Chapter 3. Linear Transformations"></a>Chapter 3. Linear Transformations</h3><ul>
<li>3.1 Linear Transformations</li>
<li>3.2 The Algebra of Linear Transformations</li>
<li>3.3 Isomorphism</li>
<li>3.4 Representation of Transformations by Matrices</li>
<li>3.5 Linear Functionals</li>
<li>3.6 The Double Dual</li>
<li>3.7 The Transpose of a Linear Transformation</li>
</ul>
<h3 id="Chapter-4-Polynomials"><a href="#Chapter-4-Polynomials" class="headerlink" title="Chapter 4. Polynomials"></a>Chapter 4. Polynomials</h3><ul>
<li>4.1 Algebras (no exercises)</li>
<li><input checked="" disabled="" type="checkbox"> 4.2 The Algebra of Polynomials<br><a href="/hoffman-kunze/linear-algebra-exercise-4-2-1.html">#4.2.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-2.html">#4.2.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-3.html">#4.2.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-4.html">#4.2.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-5.html">#4.2.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-6.html">#4.2.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-7.html">#4.2.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-8.html">#4.2.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-2-9.html">#4.2.9</a></li>
<li>4.3 Lagrange Interpolation</li>
<li>4.4 Polynomial Ideals</li>
<li><input checked="" disabled="" type="checkbox"> 4.5 The Prime Factorization of a Polynomial<br><a href="/hoffman-kunze/linear-algebra-exercise-4-5-1.html">#4.5.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-2.html">#4.5.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-3.html">#4.5.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-4.html">#4.5.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-5.html">#4.5.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-6.html">#4.5.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-7.html">#4.5.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-4-5-8.html">#4.5.8</a></li>
</ul>
<h3 id="Chapter-5-Determinants"><a href="#Chapter-5-Determinants" class="headerlink" title="Chapter 5. Determinants"></a>Chapter 5. Determinants</h3><ul>
<li>5.1 Commutative Rings (no exercises)</li>
<li>5.2 Determinant Functions</li>
<li>5.3 Permutations and the Uniqueness of Determinants</li>
<li>5.4 Additional Properties of Determinants</li>
<li>5.5 Modules (no exercises)</li>
<li>5.6 Multilinear Functions (no exercises)</li>
<li>5.7 The Grassman Ring (no exercises)</li>
</ul>
<h3 id="Chapter-6-Elementary-Canonical-Forms"><a href="#Chapter-6-Elementary-Canonical-Forms" class="headerlink" title="Chapter 6. Elementary Canonical Forms"></a>Chapter 6. Elementary Canonical Forms</h3><ul>
<li>6.1 Introduction (no exercises)</li>
<li><input checked="" disabled="" type="checkbox"> 6.2 Characteristic Values<br><a href="/hoffman-kunze/linear-algebra-exercise-6-2-1.html">#6.2.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-2.html">#6.2.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-3.html">#6.2.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-4.html">#6.2.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-5.html">#6.2.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-6.html">#6.2.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-7.html">#6.2.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-8.html">#6.2.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-9.html">#6.2.9</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-10.html">#6.2.10</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-11.html">#6.2.11</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-12.html">#6.2.12</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-13.html">#6.2.13</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-14.html">#6.2.14</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-2-15.html">#6.2.15</a></li>
<li>6.3 Annihilating Polynomials<br><a href="/hoffman-kunze/linear-algebra-exercise-6-3-1.html">#6.3.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-3-2.html">#6.3.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-3-3.html">#6.3.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-3-4.html">#6.3.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-3-5.html">#6.3.5</a></li>
<li><input checked="" disabled="" type="checkbox"> 6.4 Invariant Subspaces<br><a href="/hoffman-kunze/linear-algebra-exercise-6-4-1.html">#6.4.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-2.html">#6.4.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-3.html">#6.4.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-4.html">#6.4.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-5.html">#6.4.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-6.html">#6.4.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-7.html">#6.4.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-8.html">#6.4.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-9.html">#6.4.9</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-10.html">#6.4.10</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-11.html">#6.4.11</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-12.html">#6.4.12</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-4-13.html">#6.4.13</a></li>
<li><input checked="" disabled="" type="checkbox"> 6.5 Simultaneous Triangulation; Simultaneous Diagonalization<br><a href="/hoffman-kunze/linear-algebra-exercise-6-5-1.html">#6.5.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-5-2.html">#6.5.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-5-3.html">#6.5.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-5-4.html">#6.5.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-5-5.html">#6.5.5</a></li>
<li><input checked="" disabled="" type="checkbox"> 6.6 Direct-Sum Decompositions<br><a href="/hoffman-kunze/linear-algebra-exercise-6-6-1.html">#6.6.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-2.html">#6.6.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-3.html">#6.6.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-4.html">#6.6.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-5.html">#6.6.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-6.html">#6.6.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-7.html">#6.6.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-8.html">#6.6.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-9.html">#6.6.9</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-10.html">#6.6.10</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-6-11.html">#6.6.11</a></li>
<li>6.7 Invariant Direct Sums</li>
<li>6.8 The Primary Decomposition Theorem<br><a href="/hoffman-kunze/linear-algebra-exercise-6-8-3.html">#6.8.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-5.html">#6.8.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-7.html">#6.8.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-9.html">#6.8.9</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-11.html">#6.8.11</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-13.html">#6.8.13</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-14.html">#6.8.14</a>, <a href="/hoffman-kunze/linear-algebra-exercise-6-8-15.html">#6.8.15</a></li>
</ul>
<h3 id="Chapter-7-The-Rational-and-Jordan-Forms"><a href="#Chapter-7-The-Rational-and-Jordan-Forms" class="headerlink" title="Chapter 7. The Rational and Jordan Forms"></a>Chapter 7. The Rational and Jordan Forms</h3><ul>
<li><input checked="" disabled="" type="checkbox"> 7.1 Cyclic Subspaces and Annihilators<br><a href="/hoffman-kunze/linear-algebra-exercise-7-1-1.html">#7.1.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-2.html">#7.1.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-3.html">#7.1.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-4.html">#7.1.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-5.html">#7.1.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-6.html">#7.1.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-7.html">#7.1.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-1-8.html">#7.1.8</a></li>
<li>7.2 Cyclic Decompositions and the Rational Form</li>
<li>7.3 The Jordan Form</li>
<li>7.4 Computation of Invariant Factors</li>
<li><input checked="" disabled="" type="checkbox"> 7.5 Summary; Semi-simple Operators<br><a href="/hoffman-kunze/linear-algebra-exercise-7-5-1.html">#7.5.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-5-2.html">#7.5.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-7-5-3.html">#7.5.3</a></li>
</ul>
<h3 id="Chapter-8-Inner-Product-Spaces"><a href="#Chapter-8-Inner-Product-Spaces" class="headerlink" title="Chapter 8. Inner Product Spaces"></a>Chapter 8. Inner Product Spaces</h3><ul>
<li>8.1 Inner Products<br><a href="/hoffman-kunze/linear-algebra-exercise-8-1-1.html">#8.1.1</a>, #8.1.2, #8.1.3, #8.1.4, #8.1.5, #8.1.6, #8.1.7, #8.1.8, <a href="/hoffman-kunze/linear-algebra-exercise-8-1-9.html">#8.1.9</a>, 8.1.10, <a href="/hoffman-kunze/linear-algebra-exercise-8-1-11.html">#8.1.11</a>, 8.1.12</li>
<li>8.2 Inner Product Spaces</li>
<li>8.3 Linear Functionals and Adjoints</li>
<li>8.4 Unitary Operators</li>
<li>8.5 Normal Operators</li>
</ul>
<h3 id="Chapter-9-Operators-on-Inner-Product-Spaces"><a href="#Chapter-9-Operators-on-Inner-Product-Spaces" class="headerlink" title="Chapter 9. Operators on Inner Product Spaces"></a>Chapter 9. Operators on Inner Product Spaces</h3><ul>
<li>9.1 Introduction (no exercises)</li>
<li><input checked="" disabled="" type="checkbox"> 9.2 Forms on Inner Product Spaces<br><a href="/hoffman-kunze/linear-algebra-exercise-9-2-1.html">#9.2.1</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-2.html">#9.2.2</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-3.html">#9.2.3</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-4.html">#9.2.4</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-5.html">#9.2.5</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-6.html">#9.2.6</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-7.html">#9.2.7</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-8.html">#9.2.8</a>, <a href="/hoffman-kunze/linear-algebra-exercise-9-2-9.html">#9.2.9</a></li>
<li>9.3 Positive Forms</li>
<li>9.4 More on Forms (no exercises)</li>
<li>9.5 Spectral Theory</li>
<li>9.6 Further Properties of Normal Operators (no exercises)</li>
</ul>
<h3 id="Chapter-10-Bilinear-Forms"><a href="#Chapter-10-Bilinear-Forms" class="headerlink" title="Chapter 10. Bilinear Forms"></a>Chapter 10. Bilinear Forms</h3><ul>
<li>10.1 Bilinear Forms</li>
<li>10.2 Symmetric Bilinear Forms</li>
<li>10.3 Skew-Symmetric Bilinear Forms</li>
<li>10.4 Groups Preserveing Bilinear Forms</li>
</ul>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Linear Algebra</category>
        <category>Linear Algebra Hoffman-Kunze</category>
      </categories>
      <tags>
        <tag>Solution Manual</tag>
        <tag>Solution Content</tag>
      </tags>
  </entry>
  <entry>
    <title>Solving homogeneous linear differential equations with constant coefficients</title>
    <url>/ode/homogeneous-linear-constant-coefficients.html</url>
    <content><![CDATA[<p>In the article, we discuss how to solve homogeneous linear differential equations with constant coefficients.</p>
<a id="more"></a>

<h3 id="First-order"><a href="#First-order" class="headerlink" title="First order"></a>First order</h3><p>We start with the first order homogeneous linear differential equations. In this case, the differential equations have the following form<br>$$<br>\frac{dy}{dx}+ky=0\quad\text{or}\quad \frac{dy}{dx}=\alpha y.<br>$$ For our purpose, we use the second form, then this is a separable equation. Hence we can solve it using separation of variables. Clearly, $y=0$ is a trivial solution to this equation. Now suppose $y$ is nontrivial, that is not identically zero. Then we have<br>$$<br>\frac{dy}{y}=\alpha dx.<br>$$ Taking the integral for both sides, we have<br>$$<br>\int \frac{dy}{y}=\int \alpha dx\Longrightarrow \ln|y|=\alpha x+c_1.<br>$$ Therefore, we have<br>$$<br>|y|=e^{c_1}e^{\alpha x}\Longrightarrow y=\pm e^{c_1}e^{\alpha x}.<br>$$ Note that $e^{c_1}$ is always positive, hence $\pm e^{c_1}$ can take any positive or negative values. Recall that $y=0=0e^{\alpha x}$ is also a solution. Hence the general solution in this case can be written compactly as $y=ce^{\alpha x}$.</p>
<div class="note info flat"><p>The general solution of the first order homogeneous linear differential equation $\dfrac{dy}{dx}=\alpha y$ is $y=ce^{\alpha x}$, where $c$ is an arbtrary real (or complex) number.</p>
</div>

<hr>
<h3 id="Second-order"><a href="#Second-order" class="headerlink" title="Second order"></a>Second order</h3><p>Then we come to our main topic, solving homogeneous linear differential equations with constant coefficients. In general, we consider the second order homogeneous linear differential equations of the form<br>\begin{equation}\label{2nd-order-ode}<br>a\frac{d^2y}{dx^2}+b\frac{dy}{dx}+cy=0,<br>\end{equation} where $a,b,c$ are real numbers. One may guess that the solution is similar to the first order case, that is an exponential function. Let use first check for what value $m$, the function $y=e^{mx}$ is a solution of the equation \eqref{2nd-order-ode}. By Chain Rule, we have<br>$$<br>y’=me^{mx},\quad y^{\prime \prime}=m^2e^{mx}.<br>$$ Substituting into \eqref{2nd-order-ode}, we obtain<br>$$<br>0=a\frac{d^2y}{dx^2}+b\frac{dy}{dx}+cy=am^2e^{mx}+bme^{mx}+ce^{mx}=(am^2+bm+c)e^{mx}.<br>$$ Since $e^{mx}$ is never zero, we must have<br>\begin{equation}\label{aux-equ}<br>am^2+bm+c=0.<br>\end{equation} The equation \eqref{aux-equ} is usually called the <em>auxiliary equation</em> of the equation \eqref{2nd-order-ode}. If we can solve \eqref{aux-equ} for $m$, we obtain a solution to \eqref{2nd-order-ode}. This is a quadratic equation with single variable which one can solve it using the quadratic formula<br>\begin{equation}\label{quadratic}<br>m=\frac{-b+\sqrt{b^2-4ac}}{2a}.<br>\end{equation} Note that $\Delta=b^2-4ac$ is called the <em>discriminant</em> of \eqref{quadratic}. In general we have three cases depending on the value of the discriminant or the roots of \eqref{aux-equ}.</p>
<hr>
<h4 id="Two-distinct-real-roots"><a href="#Two-distinct-real-roots" class="headerlink" title="Two distinct real roots"></a>Two distinct real roots</h4><p>If \eqref{aux-equ} has two distinct real roots $\alpha,\beta$ (equivalently it means $\Delta&gt;0$), then we obtain two solutions of \eqref{2nd-order-ode}. Moreover, it is clear that they are linearly independent since we can compute their Wronskian<br>$$<br>W(e^{\alpha x},e^{\beta x})=e^{\alpha x}(e^{\beta x})’-(e^{\alpha x})’e^{\beta x}=(\beta-\alpha)e^{(\alpha+\beta)x}\ne 0.<br>$$ Hence we obtain a fundamental set of solutions of \eqref{2nd-order-ode},<br>$$<br>y_1=e^{\alpha x},\quad y_2=e^{\beta x}.<br>$$ In addition, all solutions of \eqref{2nd-order-ode} are linear combinations of $y_1$ and $y_2$, that is </p>
<div class="note info flat"><p>If the auxiliary equation \eqref{aux-equ} of \eqref{2nd-order-ode} has two distinct real roots, then the general solution of \eqref{2nd-order-ode} is<br>$$<br>y=c_1e^{\alpha x}+c_2e^{\beta x}.<br>$$</p>
</div>

<div class="note default flat"><p><strong>Example 1.</strong> Find the general solution of $\dfrac{d^2y}{dx^2}+5\dfrac{dy}{dx}+6y=0$.</p>
</div>

<p>Solution: The auxiliary equation is $m^2+5m+6=0$. Factoring it, we have<br>$$<br>(m+2)(m+3)=0.<br>$$ Hence it has two solutions $m=-2,-3$. Therefore, the general solution is $y=c_1 e^{-2x}+c_2 e^{-3x}$.</p>
<hr>
<h4 id="A-double-root"><a href="#A-double-root" class="headerlink" title="A double root"></a>A double root</h4><p>If \eqref{aux-equ} has a double real root $\alpha=-\dfrac{b}{2a}$ (equivalently it means $\Delta=0$), then we obtain just one solution $y_1=e^{\alpha x}$ of \eqref{2nd-order-ode} using this method. In order to obtain a fundamental set of solutions of \eqref{2nd-order-ode}, we need one more solution. Recall that if we know a solution for a second order linear differential equation, we are able to get a new solution using the method of reduction of order. Let us recall this procedure. Suppose the other solution is given by $y_2(x)=u(x)y_1(x)$, then we have<br>$$<br>y_2’(x)=u’(x)y_1(x)+u(x)y_1’(x),<br>$$ $$<br>y_2^{\prime\prime}(x)=u^{\prime\prime}(x)y_1(x)+2u’(x)y_1’(x)+y_1^{\prime\prime}(x),<br>$$ \begin{equation}\label{proof-double}<br>2ay_1’(x)+by_1(x)=2a\alpha e^{\alpha x}+be^{\alpha x}=(2a\alpha +b)e^{\alpha x}=0.<br>\end{equation} If $y_2(x)$ is a solution of \eqref{2nd-order-ode}, we must have<br>$$<br>ay_2^{\prime\prime}(x)+by_2’(x)+cy_2(x)=0,<br>$$ that is<br>\begin{align*}<br>&amp; a(u^{\prime\prime}(x)y_1(x)+2u’(x)y_1’(x)+u(x)y_1^{\prime\prime}(x))+b(u’(x)y_1(x)+u(x)y_1’(x))+cu(x)y_1(x)\\<br>=&amp; au^{\prime\prime}(x)y_1(x)+u’(x)(2ay_1’(x)+by_1(x))+u(x)(ay_1^{\prime\prime}(x)+by_1’(x)+cy(x))\\<br>=&amp; au^{\prime\prime}(x)y_1(x)+u’(x)\cdot 0+u(x)\cdot 0=au^{\prime\prime}(x)y_1(x),<br>\end{align*} here we used \eqref{proof-double} and $y_1(x)$ is a solution of \eqref{2nd-order-ode}. Hence we only need to take a function $u(x)$ such that $u’’(x)=0$. A good chocie which would give a new solution is $u(x)=x$ ($u(x)=c$ is no good since $y_2(x)$ and $y_1(x)$ will be linearly dependent). Thus $y_2(x)=xe^{\alpha x}$ is a new solution of \eqref{2nd-order-ode}. It suffices to check that $y_1(x)=e^{\alpha x}$ and $y_2(x)=xe^{\alpha x}$ are linearly independent. This can be done using Wronskian as well (it can also be done directly since $e^{\alpha x}$ is never zero),<br>$$<br>W(e^{\alpha x},xe^{\alpha x})=e^{\alpha x}(xe^{\alpha x})’-(e^{\alpha x})’xe^{\alpha x}=e^{2\alpha x}\ne 0.<br>$$ Therefore, we have</p>
<div class="note info flat"><p>If the auxiliary equation \eqref{aux-equ} of \eqref{2nd-order-ode} has a double real root, then the general solution of \eqref{2nd-order-ode} is<br>$$<br>y=c_1e^{\alpha x}+c_2xe^{\alpha x}=(c_1+c_2x)e^{\alpha x}.<br>$$</p>
</div>

<div class="note default flat"><p><strong>Example 2.</strong> Find the general solution of $\dfrac{d^2y}{dx^2}+6\dfrac{dy}{dx}+9y=0$.</p>
</div>

<p>Solution: The auxiliary equation is $m^2+6m+9=0$. Factoring it, we have<br>$$<br>(m+3)^2=0.<br>$$ Hence it has a double root $m=-3$. Therefore, the general solution is $y=c_1 e^{-3x}+c_2 xe^{-3x}$.</p>
<hr>
<h4 id="Two-complex-roots"><a href="#Two-complex-roots" class="headerlink" title="Two complex roots"></a>Two complex roots</h4><p>If \eqref{aux-equ} has two complex roots, then they must be complex conjugate to each other, namely these two roots have the form $\alpha +\beta i$, where $\alpha,\beta$ are real numbers. Then we obtain two solutions<br>$$<br>\tilde y_1(x)=e^{(\alpha+\beta i)x},\quad \tilde y_2(x)=e^{(\alpha-\beta i)x}.<br>$$<br>Usin Euler’s identity $e^{\theta i}=\cos\theta +i\sin\theta$ for $\theta\in \mathbb R$, we have<br>$$<br>\tilde y_1(x)=e^{(\alpha+\beta i)x}=e^{\alpha x}e^{i\beta x}=e^{\alpha x}(\cos(\beta x)+i\sin (\beta x)),<br>$$ $$<br>\tilde y_2(x)=e^{(\alpha-\beta i)x}=e^{\alpha x}e^{-i\beta x}=e^{\alpha x}(\cos(-\beta x)+i\sin (-\beta x))=e^{\alpha x}(\cos(\beta x)-i\sin (\beta x)).<br>$$ However, they are complex solution which are not good. We need to find real solutions. To do that, we try to get new real solutions by taking complex linear combinations of those two solutions. Explicitly, we consider<br>$$<br>y_1(x)=\frac{\tilde  y_1(x)+\tilde y_2(x)}{2}=e^{\alpha x}\cos(\beta x),<br>$$ $$<br>y_2(x)=\frac{\tilde  y_1(x)-\tilde y_2(x)}{2i}=e^{\alpha x}\sin(\beta x).<br>$$ Then $y_1(x)$ and $y_2(x)$ are solutions of \eqref{2nd-order-ode}. Moreover, they are linearly independent as the Wronskian is nonzero,<br>$$<br>W(e^{\alpha x}\cos(\beta x),e^{\alpha x}\sin(\beta x))=e^{2\alpha x}\ne 0.<br>$$ Therefore, we obtain the following</p>
<div class="note info flat"><p>If the auxiliary equation \eqref{aux-equ} of \eqref{2nd-order-ode} has complex solutions $\alpha\pm\beta i$, then the general solution of \eqref{2nd-order-ode} is<br>$$<br>y=c_1e^{\alpha x}\cos(\beta x)+c_2e^{\alpha x}\sin(\beta x)=(c_1\cos(\beta x)+c_2\sin(\beta x))e^{\alpha x}.<br>$$</p>
</div>

<div class="note default flat"><p><strong>Example 3.</strong> Find the general solution of $\dfrac{d^2y}{dx^2}+4\dfrac{dy}{dx}+13y=0$.</p>
</div>

<p>Solution: The auxiliary equation is $m^2+4m+13=0$. Solving it using the quadratic formula \eqref{quadratic}, we have<br>$$<br>m=-2\pm 3i<br>$$ Hence it has two complex roots $\alpha\pm\beta i$, where $\alpha =-2$ and $\beta =3$. Therefore, the general solution is $y=(c_1\cos 3x+c_2\sin 3x) e^{2x}$.</p>
<hr>
<h3 id="Higher-orders"><a href="#Higher-orders" class="headerlink" title="Higher orders"></a>Higher orders</h3><p>Let us consider higher order case<br>\begin{equation}\label{higher-ode}<br>a_n\frac{d^ny}{dx^n}+a_{n-1}\frac{d^{n-1}y}{dx^{n-1}}+\cdots+a_1\frac{dy}{dx}+a_0y=0,<br>\end{equation} where $a_n,a_{n-1},\dots,a_1,a_0$ are real numbers. Then we consider the corresponding <em>auxiliary equation</em><br>\begin{equation}\label{higher-aux}<br>a_nm^n+a_{n-1}m^{n-1}+\cdots+a_1m+a_0=0.<br>\end{equation} The rule to get the auxiliary equation is that the $n$-th derivative of $y$ becomes $m^n$. Note that $y$ is considered as the 0-th derivative and hence corresponds to 1.</p>
<p>We give the result without a proof.</p>
<p>Suppose \eqref{higher-aux} has a real root $\alpha$ of multiplicity $k_{\alpha}$, then we obtain $k_{\alpha}$ solutions of \eqref{higher-ode}<br>\begin{equation}\label{higher-solution-1}<br>e^{\alpha x},\ xe^{\alpha x},\dots, \ x^{k_{\alpha}-1}e^{\alpha x}.<br>\end{equation} Suppose \eqref{higher-aux} has a complex root $\alpha+\beta i$ of multiplicity $k_{\alpha,\beta}$, then $\alpha-\beta i$ is also a root of multiplicity $k_{\alpha,\beta}$. We obtain $2k_{\alpha,\beta}$ solutions of \eqref{higher-ode}<br>\begin{equation}\label{higher-solution-2}<br>e^{\alpha x}\cos(\beta x),\ xe^{\alpha x}\cos(\beta x),\dots, \ x^{k_{\alpha,\beta}-1}e^{\alpha x}\cos(\beta x),<br>\end{equation} \begin{equation}\label{higher-solution-3}<br>e^{\alpha x}\sin(\beta x),\ xe^{\alpha x}\sin(\beta x),\dots, \ x^{k_{\alpha,\beta}-1}e^{\alpha x}\sin(\beta x).<br>\end{equation} Then the general solution of \eqref{higher-ode} is obtained by taking linear combinations of all such solutions in \eqref{higher-solution-1}, \eqref{higher-solution-2}, \eqref{higher-solution-3} with all possible roots of the auxiliary equation \eqref{higher-aux}.</p>
<div class="note default flat"><p><strong>Example 4.</strong> Find the general solution of $\dfrac{d^4y}{dx^4}+2\dfrac{d^2y}{dx^2}+y=0$.</p>
</div>

<p>Solution: The auxiliary equation is $m^4+2m^2+1=0$. Solving it by noticing that $m^4+2m^2+1=(m^2+1)$, we have<br>$$<br>m=\pm i,\pm i.<br>$$ Hence the auxiliary equation has two complex roots $\pm i$ each with multiplicity 2. Therefore, the general solution is $y=(c_1+c_2 x)\cos x+(c_3+c_4 x)\sin x$.</p>
<hr>
<h3 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h3><script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Differential equation";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "159d3ae0cb7130e1e6397488c386dfdd";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Tutorial</category>
        <category>Differential Equation</category>
      </categories>
      <tags>
        <tag>Linear Differential Equation</tag>
        <tag>Auxiliary Equation</tag>
      </tags>
  </entry>
  <entry>
    <title>An introduction to Laplace Transform</title>
    <url>/ode/laplace-transform.html</url>
    <content><![CDATA[<p>In the article, we discuss basics of Laplace transform. The Laplace transform, named after its inventor Pierre-Simon Laplace, is an integral transform that converts a function of a real variable $t$ (often time) to a function of a complex variable (we focus on real $s$) $s$ (complex frequency). The transform has many applications in science and engineering because it is a tool for solving differential equations.</p>
<a id="more"></a>
<hr>
<h3 id="Definition-of-Laplace-Transform"><a href="#Definition-of-Laplace-Transform" class="headerlink" title="Definition of Laplace Transform"></a>Definition of Laplace Transform</h3><p>Recall that for a function $f(t)$ defined on $[0,\infty)$, we say that the integeral $\displaystyle\int_0^\infty f(t)dt$ <em>converges</em> if the limit exists<br>$$<br>\lim_{a\to 0}\int_0^{a}f(t)dt.<br>$$ Otherwise, we say it <em>diverges</em>. In this case, such an integral is not well-defined.</p>
<div class="note info flat"><p><strong>Definition.</strong> Give a function $f(t)$ defined on $[0,\infty)$, the <em>Laplace transform</em> maps $f(t)$ to a new function $F(s)$ by the formula,<br>\begin{equation}\label{Laplace}<br>\mathcal L\{f(t)\}=\int_0^\infty e^{-st}f(t)dt,<br>\end{equation} if the integral converges.</p>
</div>

<p>We remark that the function $K(s,t)=e^{-st}$ used here is called a <em>kernel</em> of an integral transform. </p>
<hr>
<h3 id="Formulas-of-Laplace-Transform"><a href="#Formulas-of-Laplace-Transform" class="headerlink" title="Formulas of Laplace Transform"></a>Formulas of Laplace Transform</h3><p>In this section, we compute the Laplace transform of some basic functions such as polynomials, trigonometric functions, and exponentials.</p>
<div class="note default flat"><p><strong>Example 1.</strong> Compute $\mathcal L\{1\}$.</p>
</div>

<p>Solution: By \eqref{Laplace}, we have<br>$$<br>\mathcal L\{1\}=\int_0^\infty e^{-st}dt.<br>$$ If $s=0$, it is clear that such integral diverges. Now suppose $s\ne 0$, then we have<br>$$<br>\mathcal L\{1\}=\int_0^\infty e^{-st}dt=\frac{e^{-st}}{-s}\Big|_{0}^{\infty}.<br>$$ This integral converges only when the limit $\lim_{t\to \infty} e^{-st}$. That means we must have $s&gt;0$. Moreover, if $s&gt;0$, then $\lim_{t\to \infty} e^{-st}=0$. Therefore,<br>$$<br>\mathcal L\{1\}=\frac{e^{-st}}{-s}\Big|_{0}^{\infty}=0-\frac{e^{-s\cdot 0}}{s}=\frac{1}{s}.<br>$$ We conclude the $L\{1\}= \dfrac{1}{s}$ for $s\in (0,\infty)$.</p>
<div class="note default flat"><p><strong>Example 2.</strong> Compute $\mathcal L\{t\}$.</p>
</div>

<p>Solution: By \eqref{Laplace}, we have<br>$$<br>\mathcal L\{t\}=\int_0^\infty e^{-st}tdt.<br>$$ We shall use integration by parts, that is the formula<br>$$<br>\int f’(t)g(t)dt=f(t)g(t)-\int f(t)g’(t)dt.<br>$$ Taking $f(t)=\dfrac{e^{-st}}{-s}$ (then $f’(t)=e^{-st}$) and $g(t)=t$, we have<br>\begin{align*}<br>\int_0^\infty e^{-st}tdt=&amp;\int_0^\infty \left(\dfrac{e^{-st}}{-s}\right)’tdt= \dfrac{e^{-st}t}{-s}\Big|_{0}^{\infty}-\int_0^\infty \dfrac{e^{-st}}{-s}(t)’dt\\<br>=&amp; (0-0)+\frac{1}{s}\int_0^\infty e^{-st}dt=\frac{1}{s}\cdot\frac{1}{s}=\frac{1}{s^2}.<br>\end{align*} Here we used the fact that $\lim_{t\to \infty} e^{-st}t=0$ (you can show it using L’Hôpital’s rule) if $s&gt;0$ and $\displaystyle\int_0^\infty e^{-st}dt=\frac{1}{s}$ from Example 1. Again, this answer is only for $s\in(0,\infty)$.</p>
<div class="note default flat"><p><strong>Exercise.</strong> Compute $\mathcal L\{t^2\}$.</p>
</div>

<p>In general, using integration by parts, we can show that<br>$$<br>\mathcal L\{t^n\}=\frac{n}{s}\mathcal L\{t^{n-1}\}<br>$$ and hence obtain that $\mathcal L\{t^n\}=\dfrac{n!}{s^{n+1}}$ for $n\ge 0$ by induction on $n$.</p>
<div class="note info flat"><p>We have $\mathcal L\{t^n\}=\dfrac{n!}{s^{n+1}}$ for $s&gt;0$.</p>
</div>

<div class="note default flat"><p><strong>Example 3.</strong> Compute $\mathcal L\{e^{3t}\}$.</p>
</div>

<p>Solution: By \eqref{Laplace}, we have<br>$$<br>\mathcal L\{e^{3t}\}=\int_0^\infty e^{-st}e^{3t}dt=\int_0^\infty e^{-(s-3)t}dt=\frac{1}{s-3}.<br>$$ This integeral converges when $s&gt;3$. This follows exactly the same as Example 1.</p>
<p>In general, we have</p>
<div class="note info flat"><p>$\mathcal L\{e^{\alpha t}\}=\dfrac{1}{s-\alpha}$ for $s&gt;\alpha$.</p>
</div>

<div class="note default flat"><p><strong>Example 4.</strong> Compute the Laplace transform of cosine function $\mathcal L\{\cos(\alpha t)\}$, where $\alpha$ is a real constant.</p>
</div>

<p>Solution: We shall use integration by parts twice to compute it. By \eqref{Laplace}, we have<br>\begin{align*}<br>\mathcal L\{\cos(\alpha t)\}=&amp;\ \int_0^\infty e^{-st}\cos(\alpha t)dt =\int_0^\infty \left(\dfrac{e^{-st}}{-s}\right)’\cos(\alpha t)dt\\<br>=&amp;\ \left(\dfrac{e^{-st}}{-s}\right)\cos(\alpha t)\Big|_0^\infty-\int_0^\infty \left(\dfrac{e^{-st}}{-s}\right)(-\alpha)\sin(\alpha t)dt\\<br>=&amp;\ \frac{1}{s}-\frac{\alpha}{s}\int_0^\infty e^{-st}\sin(\alpha t)dt\ \left(= {\color{red}\frac{1}{s}-\frac{\alpha}{s}\mathcal L\{\sin(\alpha t)\}}\right)\\<br>=&amp;\ \frac{1}{s}-\frac{\alpha}{s}\left(\int_0^\infty \left(\dfrac{e^{-st}}{-s}\right)’\sin(\alpha t)dt \right)\\<br>=&amp;\ \frac{1}{s}-\frac{\alpha}{s}\left(\dfrac{e^{-st}}{-s}\sin(\alpha t)\Big|_0^\infty-\int_0^\infty \left(\dfrac{e^{-st}}{-s}\right)\alpha\cos(\alpha t)dt \right)\\<br>=&amp;\ \frac{1}{s}-\frac{\alpha}{s}\left(\frac{\alpha}{s}\int_0^\infty e^{-st}\cos(\alpha t)dt \right)\\<br>=&amp;\ \frac{1}{s}-\frac{\alpha^2}{s^2}\int_0^\infty e^{-st}\cos(\alpha t)dt=\frac{1}{s}-\frac{\alpha^2}{s^2}\mathcal L\{\cos(\alpha t)\}.<br>\end{align*} Hence we obtain that<br>$$<br>\mathcal L\{\cos(\alpha t)\}=\frac{1}{s}-\frac{\alpha^2}{s^2}\mathcal L\{\cos(\alpha t)\}.<br>$$ Solving for $\mathcal L\{\cos(\alpha t)\}$, we finally get that<br>\begin{equation}\label{eq:L-cos}<br>\mathcal L\{\cos(\alpha t)\}=\frac{s}{s^2+\alpha^2}.<br>\end{equation} Recall that in the meanwhile, the following equation is also observed (formulas in red color)<br>$$<br>\mathcal L\{\cos(\alpha t)\}=\frac{1}{s}-\frac{\alpha}{s}\mathcal L\{\sin(\alpha t)\}.<br>$$ Combining this with \eqref{eq:L-cos}, we get the formula for Laplace transform of sine function $\sin(\alpha t)$,<br>\begin{equation}\label{eq:L-sin}<br>\mathcal L\{\sin(\alpha t)\}=\frac{\alpha}{s^2+\alpha^2}.<br>\end{equation}</p>
<p>We summarise all the formulas we obtained.</p>
<div class="note info flat"><ol>
<li>$\mathcal L\{t^n\}=\dfrac{n!}{s^{n+1}}$.</li>
<li>$\mathcal L\{e^{\alpha t}\}=\dfrac{1}{s-\alpha}$.</li>
<li>$\mathcal L\{\sin(\alpha t)\}=\dfrac{\alpha}{s^2+\alpha^2}$.</li>
<li>$\mathcal L\{\cos(\alpha t)\}=\dfrac{s}{s^2+\alpha^2}$.</li>
</ol>
</div>


<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_default_search_phrase = "Differential equation";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "159d3ae0cb7130e1e6397488c386dfdd";
amzn_assoc_search_bar = "true";
amzn_assoc_search_bar_position = "top";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_rows = "2";
</script>
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Tutorial</category>
        <category>Differential Equation</category>
      </categories>
      <tags>
        <tag>Laplace Transform</tag>
        <tag>Integration by Parts</tag>
      </tags>
  </entry>
  <entry>
    <title>Two subsets generate the whole finite group</title>
    <url>/problems/0001-group-theory.html</url>
    <content><![CDATA[<div class="note info flat"><p>Problem 1</p>
</div>

<p>Let $G$ be a finite group. Let $A$ and $B$ be two non-empty subsets of $G$ such that $|A|+|B|&gt;|G|$. Here $|S|$ denotes the cardinality of the set $S$, that is the number of elements in the set $S$. Define </p>
<p>$$<br>AB=\{ab\ |\ a\in A,\ b\in B\}.<br>$$</p>
<p>Prove that $G=AB$.</p>
<a id="more"></a>

<hr>
<p><strong>Solution</strong></p>
<p>If $G=AB$, then it means that for any $g\in G$, we can find $a\in A$ and $b\in B$ such that $g=ab$. Note that this is equivalent to $a^{-1}g=b$. Hence we only need to show that $A^{-1}g\cap B\ne \emptyset$. Below is the proof.</p>
<hr>
<p>Let $g$ be an arbitrary element in $G$. Now we fix $g$. Define </p>
<p>$$<br>A^{-1}g=\{a^{-1}g\ |\ a\in A\}.<br>$$</p>
<p>Then we have $|A^{-1}g|=|A|$ (they clearly have the same number of elements). Hence</p>
<p>$$<br>|A^{-1}g|+|B|=|A|+|B|&gt;|G|.<br>$$</p>
<p>Therefore, we must have $A^{-1}g\cap B\ne \emptyset$. Let $b\in A^{-1}g\cap B$, then $b\in B$. Moreover, since $b\in A^{-1}g$, there exists $a\in A$ such that $b=a^{-1}g$. Thus $g=ab\in AB$. As $g$ is chosen arbitrarily at the beginning. We conclude that $G=AB$.</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Problems</category>
        <category>Abstract Algebra</category>
      </categories>
      <tags>
        <tag>Finite Group</tag>
        <tag>Cardinality</tag>
      </tags>
  </entry>
  <entry>
    <title>In a unit ring $1-ab$ is invertible if and only if $1-ba$ is invertible</title>
    <url>/problems/0002-ring-theory.html</url>
    <content><![CDATA[<div class="note info flat"><p>Problem 2</p>
</div>

<p>Let $a$ and $b$ be two elements in a unit ring $R$. Prove that $1-ab$ is invertible if and only if $1-ba$ is invertible.</p>
<a id="more"></a>

<hr>
<p><strong>Solution</strong></p>
<p>By symmetry, it suffices to show that if $1-ab$ is invertible, then so is $1-ba$. (To obtain the “only if” part, you just need to interchange $a$ and $b$ and repeat the “if” part.)</p>
<p>Let $c$ be the inverse of $1-ab$, we have $(1-ab)c=1$ that is $c=1+abc$. Now we check that $1+bca$ is the inverse of $1-ba$ by direct computations,</p>
<p>\begin{align*}<br>(1-ba)(1+bca)=&amp;\ 1+bca-ba-babca \\<br>=&amp;\ 1+b(c-1-abc)a \\<br>=&amp;\ 1+b\cdot 0\cdot a = 1.<br>\end{align*}</p>
<p>Here we used that $c=1+abc$. </p>
<p>Similarly, using $c=1+cab$ (comes from $c(1-ab)=1$), one shows that</p>
<p>$$(1+bca)(1-ba)=1.$$</p>
<p>Hence $1-ba$ is invertible.</p>
<hr>
<p>You may wonder how we know that the inverse of $1-ba$ is given by such a specific element. The idea comes from the following.</p>
<div class="note warning flat"><p>This is not a proof, because you <em>cannot</em> do infinite sum in a ring! </p>
</div>

<p>We have the well-known Taylor’s expansion,</p>
<p>$$<br>(1-x)^{-1}=1+x+x^2+x^3+\cdots.<br>$$</p>
<p>Hence we have</p>
<p>$$<br>(1-ab)^{-1}=1+ab+abab+ababab+\cdots,<br>$$</p>
<p>and hence</p>
<p>\begin{align*}<br>(1-ba)^{-1}=&amp;\ 1+ba+baba+bababa+babababa+\cdots \\<br>=&amp;\ 1+b(1+ab+abab+ababab+\cdots)a \\<br>=&amp;\ 1+b(1-ab)^{-1}a.<br>\end{align*}</p>
<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Problems</category>
        <category>Abstract Algebra</category>
      </categories>
      <tags>
        <tag>Invertibility</tag>
        <tag>Ring</tag>
        <tag>Unit</tag>
      </tags>
  </entry>
  <entry>
    <title>Exist a linear combination of two relatively prime polynomials having no multiple roots</title>
    <url>/problems/0003-linear-algebra.html</url>
    <content><![CDATA[<div class="note info flat"><p>Problem 3</p>
</div>

<p>Let $f(x)$ and $g(x)$ be two relatively prime polynomials in $x$. Prove that there must exists a (real or complex) number $s$ such that $f(x)+sg(x)$ has no multiple root.</p>
<a id="more"></a>

<hr>
<p><strong>Solution</strong></p>
<p>We argue it by contradiction. Suppose $f(x)+sg(x)$ has a multiple root (maybe complex) for every number $s$. Let $x_s$ be one of the multiple root of $f(x)+sg(x)$ (note that $x_s$ may change as $s$ varies), then we have</p>
<p>$$<br>f(x_s)+sg(x_s)=0,<br>$$</p>
<p>$$<br>f’(x_s)+sg’(x_s)=0.<br>$$</p>
<p>This implies that the vector $(1,s)^T$ is a solution to the system of homogeneous equations with the coefficient matrix </p>
<p>$$<br>\begin{bmatrix} f(x_s) &amp; g(x_s)\\ f’(x_s) &amp; g’(x_s)\end{bmatrix}.<br>$$ </p>
<p>Hence its determinant must be zero, that is </p>
<p>$$<br>f(x_s)g’(x_s)-f’(x_s)g(x_s)=0.<br>$$</p>
<p>Let $h(x)$ be the polynomial $f(x)g’(x)-f’(x)g(x)$ (this is indeed the Wronskian of $f(x)$ and $g(x)$). Then $h(x)$ is not zero since otherwise we have $f(x)|f’(x)g(x)$ while $f(x)$ and $g(x)$ are relatively prime and $f(x)$ does divide $f’(x)$.</p>
<p>Denote by $K$ the set of solutions of $h(x)$. Since $h(x)$ is non-zero, $K$ is a finite set. By our observation above, we have $x_s\in K$ for every $s$. Because $K$ is finite, there exists an element $\alpha\in K$ which corresponds to $x_s$ for infinitely many $s$. That implies $f(\alpha)+sg(\alpha)=0$ for infinitely many $s$ which holds only when $f(\alpha)=g(\alpha)=0$, contradicting with the fact that $f(x)$ and $g(x)$ are relatively prime (i.e. no common root). This completes the proof.</p>
<div class="note default flat"><p>In general, Wronskian is the tool to check if functions are linearly independent. Wronksian is nonzero if and only if they are linearly independent. Clearly, in this case, $f(x)$ and $g(x)$ are linearly independent and hence the Wronskian $h(x)$ can not be zero. </p>
</div>

<script type="text/javascript">
amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "search";
amzn_assoc_ad_type = "smart";
amzn_assoc_marketplace = "amazon";
amzn_assoc_region = "US";
amzn_assoc_title = "Shop Related Products";
amzn_assoc_default_search_phrase = "Linear Algebra";
amzn_assoc_default_category = "All";
amzn_assoc_linkid = "5d941cdffc23d9a550f0004271073955";
</script><br />
<script src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US"></script>]]></content>
      <categories>
        <category>Problems</category>
        <category>Linear Algebra</category>
      </categories>
      <tags>
        <tag>Polynomial</tag>
        <tag>Root</tag>
      </tags>
  </entry>
</search>
