<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Clanlu Math</title><meta name="keywords" content="Linear Algebra, Abstract Algebra, Probability, Convex Optimization, Machine Learning"><meta name="author" content="Clanlu"><meta name="copyright" content="Clanlu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="We discuss challenging math problems in Linear Algebra, Abstract Algebra, Probability Theory, and Convex Optimization related to Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Clanlu Math">
<meta property="og:url" content="http://clanlu.com/index.html">
<meta property="og:site_name" content="Clanlu Math">
<meta property="og:description" content="We discuss challenging math problems in Linear Algebra, Abstract Algebra, Probability Theory, and Convex Optimization related to Machine Learning">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://clanlu.com/null">
<meta property="article:author" content="Clanlu">
<meta property="article:tag" content="Linear Algebra, Abstract Algebra, Probability, Convex Optimization, Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://clanlu.com/null"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://clanlu.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-02-20 01:30:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/null" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">74</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">74</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Clanlu Math</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/mml-solution-manual.html" title="Mathematics for Machine learning Solution Manual">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mathematics for Machine learning Solution Manual"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-solution-manual.html" title="Mathematics for Machine learning Solution Manual">Mathematics for Machine learning Solution Manual</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-01-22T03:50:49.000Z" title="Created 2021-01-21 22:50:49">2021-01-21</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="content">Mathematics for Machine Learning by Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong


ISBN:9781108569323, 1108569323




Chapter 2 Linear Algebra#2.1, #2.2, #2.3, #2.4, #2.5, #2.6, #2.7, #2.8, #2.9, #2.10, #2.11, #2.12, #2.13, #2.14, #2.15, #2.16, #2.17, #2.18, #2.19, #2.20
Chapter 3 Analytic Geometry#3.1, #3.2, #3.3, #3.4, #3.5, #3.6, #3.7, #3.8, #3.9, #3.10
Chapter 4 Matrix Decompositions#4.1, #4.2, #4.3, #4.4, #4.5, #4.6, #4.7, #4.8, #4.9, #4.10, #4.11, #4.12
Chapter 5 Vector Calculus#5 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/iala-solution-manual.html" title="Solution Manual to Introduction to Applied Linear Algebra">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Solution Manual to Introduction to Applied Linear Algebra"></a></div><div class="recent-post-info"><a class="article-title" href="/iala-solution-manual.html" title="Solution Manual to Introduction to Applied Linear Algebra">Solution Manual to Introduction to Applied Linear Algebra</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-01T02:05:52.804Z" title="Created 2021-01-31 21:05:52">2021-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="content">Below is the official solution manual of Introduction to Applied Linear Algebra (Vectors, Matrices, and Least Squares) by Stephen Boyd, Lieven Vandenberghe




Solution Manual to Introduction to Applied Linear Algebra via Google Drive
https://drive.google.com/file/d/1wBJMfbWsPL5lq6T6SA8m3iQeCVrbRkiQ/view?usp=sharing

amzn_assoc_placement = "adunit0";
amzn_assoc_search_bar = "true";
amzn_assoc_tracking_id = "linearalgeb0e-20";
amzn_assoc_search_bar_position = "bottom";
amzn_assoc_ad_mode = "searc ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/mml-exercise-6-5.html" title="A time series model and Gaussian noise variable">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A time series model and Gaussian noise variable"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-5.html" title="A time series model and Gaussian noise variable">A time series model and Gaussian noise variable</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T15:31:44.773Z" title="Created 2021-02-12 10:31:44">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.5




Solution: 
Part a
$\mathbf{x}_{t+1}$ is obtained from $\mathbf{x}_{t}$ by a linear transformation, $\mathbf{A}\mathbf{x}_{t}$ and adding a Gaussian random variabme $\mathbf{w}$. Initial distribution for $\mathbf{x}_{0}$ is a Gaussian distribution, a linear transformation of a Gaussian random variable is also a Gaussian random variable, whareas a sum of Gaussian random variables is a Gaussian random variable. Thus, the joint  ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/mml-exercise-6-13.html" title="Probability Integral Transformation and uniform distribution">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Probability Integral Transformation and uniform distribution"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-13.html" title="Probability Integral Transformation and uniform distribution">Probability Integral Transformation and uniform distribution</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T15:24:14.906Z" title="Created 2021-02-12 10:24:14">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.13




Solution: 
Cdf is related to pdf as
$$ F_x(x) = \int_{-\infty}^xdx’ f_x(x’),\quad \frac{d}{dx} F_x(x) = f_x(x), $$
and changes in the interval $[0,1]$.
The pdf of variable $y=F_x(x)$ then can be defined as
$$ f_y(y) = f_x(x) \left|\frac{dx}{dy}\right| = \frac{f_x(x)}{\left|\frac{dy}{dx}\right|} = \frac{f_x(x)}{\left|\frac{dF_x(x)}{dx}\right|} = \frac{f_x(x)}{f_x(x)} = 1, $$
i.e. $y$ is uniformly distributed in interval $[0, ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/mml-exercise-6-12.html" title="Manipulation of Gaussian Random Variables">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Manipulation of Gaussian Random Variables"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-12.html" title="Manipulation of Gaussian Random Variables">Manipulation of Gaussian Random Variables</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T15:13:57.393Z" title="Created 2021-02-12 10:13:57">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.12




Solution: 
Part a
If $\mathbf{x}$ is fixed, then $\mathbf{y}$ has the same distribution as $\mathbf{w}$, but with the mean shifter by $\mathbf{A}\mathbf{x} + \mathbf{b}$, that is
$$ p(\mathbf{y}|\mathbf{x}) = \mathcal{N}(\mathbf{y}|\mathbf{A}\mathbf{x} + \mathbf{b}, \mathbf{Q}). $$

Part b
Let us consider random variable $\mathbf{u} = \mathbf{A}\mathbf{x}$, it is distributed according to
$$ p(\mathbf{u}) = \mathcal{N}(\math ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/mml-exercise-6-11.html" title="Computation involving iterated expectations and conditional probability">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Computation involving iterated expectations and conditional probability"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-11.html" title="Computation involving iterated expectations and conditional probability">Computation involving iterated expectations and conditional probability</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T15:09:11.152Z" title="Created 2021-02-12 10:09:11">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.11




Solution: 
The expectation value and the conditional expectation value are given by
$$ \mathbb{E}_X[x] = \int x p(x) dx,\\ \mathbb{E}_Y[f(y)] = \int f(y) p(y) dy,\\ \mathbb{E}_X[x|y] = \int x p(x|y) dx $$
We then have
\begin{align*}\mathbb{E}_Y\left[\mathbb{E}_X[x|y]\right] =&amp;\ \int \mathbb{E}_X[x|y] p(y) dy = \int \left[\int xp(x|y)dx\right]p(y) dy \\=&amp;\ \int \int xp(x|y)p(y)dx dy = \int\int xp(x,y)dxdy\\ =&amp;\ \ ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/mml-exercise-6-10.html" title="Express the Gaussian distributions as an exponential family distribution">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Express the Gaussian distributions as an exponential family distribution"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-10.html" title="Express the Gaussian distributions as an exponential family distribution">Express the Gaussian distributions as an exponential family distribution</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T14:45:53.328Z" title="Created 2021-02-12 09:45:53">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.10




Solution: 
Part a
The two normal distributions are given by
$$ \mathcal{N}(\mathbf{x}|\mathbf{a}, \mathbf{A}) = (2\pi)^{-\frac{D}{2}}|\mathbf{A}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{a})^T\mathbf{A}^{-1}(\mathbf{x} - \mathbf{a})\right],$$$$\mathcal{N}(\mathbf{x}|\mathbf{b}, \mathbf{B}) = (2\pi)^{-\frac{D}{2}}|\mathbf{B}|^{-\frac{1}{2}} \exp\left[-\frac{1}{2}(\mathbf{x} - \mathbf{b})^T\mathbf{B}^{-1}(\m ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/mml-exercise-6-9.html" title="Express the Binomial and Beta distributions as an exponential family distribution">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Express the Binomial and Beta distributions as an exponential family distribution"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-9.html" title="Express the Binomial and Beta distributions as an exponential family distribution">Express the Binomial and Beta distributions as an exponential family distribution</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T05:18:45.828Z" title="Created 2021-02-12 00:18:45">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.9




Solution: 
The binomial distribution can be transformed as
\begin{align*} p(x|N,\mu) =&amp;\ {N\choose x} \mu^x (1-\mu)^{N-x} = {N \choose x} e^{x\log\mu + (N-x)\log(1-\mu)}\\ =&amp;\ {N \choose x}e^{x\log\left(\frac{\mu}{1-\mu}\right) +N\log(1-\mu)} = h(x)e^{x\theta - A(\theta)}\end{align*}
where
$$ h(x) = {N \choose x},\\ \theta = \log\left(\frac{\mu}{1-\mu}\right),$$ 
$$ A(\theta) = -N\log(1-\mu) = N\log(1+e^\theta), $$
i ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/mml-exercise-6-8.html" title="Express the Bernoulli distribution in the natural parameter form of the exponential family">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Express the Bernoulli distribution in the natural parameter form of the exponential family"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-8.html" title="Express the Bernoulli distribution in the natural parameter form of the exponential family">Express the Bernoulli distribution in the natural parameter form of the exponential family</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-12T05:12:50.463Z" title="Created 2021-02-12 00:12:50">2021-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.8




Solution: 
Bernoulli distribution is given by
$$ p(x|\mu) = \mu^x (1-\mu)^{1-x}. $$
We can use relation
$$ a^x = e^{x\log a} $$
to write the Bernoulli distribution as
$$ p(x|\mu) = e^{x\log\mu + (1-x)\log(1-\mu)}= e^{x\log\left(\frac{\mu}{1-\mu}\right) + \log(1-\mu)} = h(x)e^{\theta x - A(\theta)}, $$
where the last equation is the definition of a single-parameter distribution from the exponential family, in which
$$ h(x) =  ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/mml-exercise-6-7.html" title="A identity that can be used to show Cauchy-Schwarz inequality">     <img class="post_bg" src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A identity that can be used to show Cauchy-Schwarz inequality"></a></div><div class="recent-post-info"><a class="article-title" href="/mml-exercise-6-7.html" title="A identity that can be used to show Cauchy-Schwarz inequality">A identity that can be used to show Cauchy-Schwarz inequality</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-02-11T05:23:10.346Z" title="Created 2021-02-11 00:23:10">2021-02-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/Machine-Learning/Statistics/">Statistics</a></span></div><div class="content">Solution to Mathematics for Machine learning Chapter 6 Exercise 6.7




Solution: 
Let is expand the square in the left-hand side of (6.45)
$$ \frac{1}{N^2}\sum_{i,j=1}^N(x_i - x_j)^2 = \frac{1}{N^2}\sum_{i,j=1}^N(x_i^2 - 2x_i x_j + x_j^2) = \frac{1}{N^2}\sum_{i,j=1}^N x_i^2 - 2\frac{1}{N^2}\sum_{i,j=1}^N x_i x_j + \frac{1}{N^2}\sum_{i,j=1}^Nx_j^2 $$
We see that the first and the last term differ only by the summation index, i.e. they are identical: $$ \frac{1}{N^2}\sum_{i,j=1}^N x_i^2 + \frac{1 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/null" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Clanlu</div><div class="author-info__description">We discuss challenging math problems in Linear Algebra, Abstract Algebra, Probability Theory, and Convex Optimization related to Machine Learning</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">74</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">74</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/mml-exercise-6-5.html" title="A time series model and Gaussian noise variable"><img src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A time series model and Gaussian noise variable"/></a><div class="content"><a class="title" href="/mml-exercise-6-5.html" title="A time series model and Gaussian noise variable">A time series model and Gaussian noise variable</a><time datetime="2021-02-12T15:31:44.773Z" title="Created 2021-02-12 10:31:44">2021-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mml-exercise-6-13.html" title="Probability Integral Transformation and uniform distribution"><img src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Probability Integral Transformation and uniform distribution"/></a><div class="content"><a class="title" href="/mml-exercise-6-13.html" title="Probability Integral Transformation and uniform distribution">Probability Integral Transformation and uniform distribution</a><time datetime="2021-02-12T15:24:14.906Z" title="Created 2021-02-12 10:24:14">2021-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mml-exercise-6-12.html" title="Manipulation of Gaussian Random Variables"><img src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Manipulation of Gaussian Random Variables"/></a><div class="content"><a class="title" href="/mml-exercise-6-12.html" title="Manipulation of Gaussian Random Variables">Manipulation of Gaussian Random Variables</a><time datetime="2021-02-12T15:13:57.393Z" title="Created 2021-02-12 10:13:57">2021-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mml-exercise-6-11.html" title="Computation involving iterated expectations and conditional probability"><img src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Computation involving iterated expectations and conditional probability"/></a><div class="content"><a class="title" href="/mml-exercise-6-11.html" title="Computation involving iterated expectations and conditional probability">Computation involving iterated expectations and conditional probability</a><time datetime="2021-02-12T15:09:11.152Z" title="Created 2021-02-12 10:09:11">2021-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/mml-exercise-6-10.html" title="Express the Gaussian distributions as an exponential family distribution"><img src="https://i.loli.net/2020/08/31/v6Cp1Lb2a79cmf3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Express the Gaussian distributions as an exponential family distribution"/></a><div class="content"><a class="title" href="/mml-exercise-6-10.html" title="Express the Gaussian distributions as an exponential family distribution">Express the Gaussian distributions as an exponential family distribution</a><time datetime="2021-02-12T14:45:53.328Z" title="Created 2021-02-12 09:45:53">2021-02-12</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Abstract-Algebra/"><span class="card-category-list-name">Abstract Algebra</span><span class="card-category-list-count">2</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Abstract-Algebra/Group/"><span class="card-category-list-name">Group</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Abstract-Algebra/Ring/"><span class="card-category-list-name">Ring</span><span class="card-category-list-count">1</span></a></li></ul></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Linear-Algebra/"><span class="card-category-list-name">Linear Algebra</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Machine-Learning/"><span class="card-category-list-name">Machine Learning</span><span class="card-category-list-count">71</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Machine-Learning/Calculus/"><span class="card-category-list-name">Calculus</span><span class="card-category-list-count">14</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Machine-Learning/Linear-Algebra/"><span class="card-category-list-name">Linear Algebra</span><span class="card-category-list-count">42</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Machine-Learning/Statistics/"><span class="card-category-list-name">Statistics</span><span class="card-category-list-count">13</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Abelian-Group/" style="font-size: 1.16em; color: #999b9e">Abelian Group</a> <a href="/tags/Angle/" style="font-size: 1.1em; color: #999">Angle</a> <a href="/tags/Approximation/" style="font-size: 1.1em; color: #999">Approximation</a> <a href="/tags/Automorphism/" style="font-size: 1.16em; color: #999b9e">Automorphism</a> <a href="/tags/Basic-Identity/" style="font-size: 1.1em; color: #999">Basic Identity</a> <a href="/tags/Basis/" style="font-size: 1.33em; color: #99a2af">Basis</a> <a href="/tags/Bayes%E2%80%99-Theorem/" style="font-size: 1.1em; color: #999">Bayes’ Theorem</a> <a href="/tags/Bernoulli-Distribution/" style="font-size: 1.21em; color: #999ea4">Bernoulli Distribution</a> <a href="/tags/Beta-Distribution/" style="font-size: 1.1em; color: #999">Beta Distribution</a> <a href="/tags/Calculus/" style="font-size: 1.1em; color: #999">Calculus</a> <a href="/tags/Cardinality/" style="font-size: 1.1em; color: #999">Cardinality</a> <a href="/tags/Cauchy-Schwarz-Inequality/" style="font-size: 1.1em; color: #999">Cauchy-Schwarz Inequality</a> <a href="/tags/Cauchy-Schwarz-inequality/" style="font-size: 1.1em; color: #999">Cauchy-Schwarz inequality</a> <a href="/tags/Chain-Rule/" style="font-size: 1.21em; color: #999ea4">Chain Rule</a> <a href="/tags/Convex-Function/" style="font-size: 1.1em; color: #999">Convex Function</a> <a href="/tags/Convex-Set/" style="font-size: 1.1em; color: #999">Convex Set</a> <a href="/tags/Derivative/" style="font-size: 1.44em; color: #99a7ba">Derivative</a> <a href="/tags/Determinant/" style="font-size: 1.27em; color: #99a0a9">Determinant</a> <a href="/tags/Diagonalisability/" style="font-size: 1.21em; color: #999ea4">Diagonalisability</a> <a href="/tags/Difference/" style="font-size: 1.16em; color: #999b9e">Difference</a> <a href="/tags/Distance/" style="font-size: 1.1em; color: #999">Distance</a> <a href="/tags/Distribution/" style="font-size: 1.39em; color: #99a4b4">Distribution</a> <a href="/tags/Eigenvalue/" style="font-size: 1.5em; color: #99a9bf">Eigenvalue</a> <a href="/tags/Eigenvector/" style="font-size: 1.5em; color: #99a9bf">Eigenvector</a> <a href="/tags/Euclidean-Space/" style="font-size: 1.16em; color: #999b9e">Euclidean Space</a> <a href="/tags/Expectation/" style="font-size: 1.16em; color: #999b9e">Expectation</a> <a href="/tags/Extreme-Value/" style="font-size: 1.1em; color: #999">Extreme Value</a> <a href="/tags/Finite-Group/" style="font-size: 1.1em; color: #999">Finite Group</a> <a href="/tags/Function/" style="font-size: 1.16em; color: #999b9e">Function</a> <a href="/tags/Gaussian-Distribution/" style="font-size: 1.21em; color: #999ea4">Gaussian Distribution</a> <a href="/tags/Gaussian-Elimination/" style="font-size: 1.1em; color: #999">Gaussian Elimination</a> <a href="/tags/Gaussian-elimination/" style="font-size: 1.21em; color: #999ea4">Gaussian elimination</a> <a href="/tags/Gram-Schmidt/" style="font-size: 1.1em; color: #999">Gram-Schmidt</a> <a href="/tags/Group/" style="font-size: 1.21em; color: #999ea4">Group</a> <a href="/tags/Image/" style="font-size: 1.1em; color: #999">Image</a> <a href="/tags/Inner-Product/" style="font-size: 1.39em; color: #99a4b4">Inner Product</a> <a href="/tags/Intersection/" style="font-size: 1.16em; color: #999b9e">Intersection</a> <a href="/tags/Invertibility/" style="font-size: 1.16em; color: #999b9e">Invertibility</a> <a href="/tags/Jacobian/" style="font-size: 1.1em; color: #999">Jacobian</a> <a href="/tags/Kernel/" style="font-size: 1.1em; color: #999">Kernel</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">February 2021</span><span class="card-archive-list-count">20</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">January 2021</span><span class="card-archive-list-count">54</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">74</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-02-20T06:30:19.748Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Clanlu</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>